
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>norse.torch.functional.lsnn module &#8212; norse 0.0.4 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="norse.torch.functional.regularization module" href="norse.torch.functional.regularization.html" />
    <link rel="prev" title="norse.torch.functional.logical module" href="norse.torch.functional.logical.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="module-norse.torch.functional.lsnn">
<span id="norse-torch-functional-lsnn-module"></span><h1>norse.torch.functional.lsnn module<a class="headerlink" href="#module-norse.torch.functional.lsnn" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="norse.torch.functional.lsnn.LSNNFeedForwardState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lsnn.</code><code class="sig-name descname">LSNNFeedForwardState</code><a class="reference internal" href="../_modules/norse/torch/functional/lsnn.html#LSNNFeedForwardState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Integration state kept for a lsnn module</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>b</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – threshold adaptation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LSNNFeedForwardState(v, i, b)</p>
<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNFeedForwardState.b">
<code class="sig-name descname">b</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNFeedForwardState.b" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNFeedForwardState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNFeedForwardState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNFeedForwardState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNFeedForwardState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.lsnn.LSNNParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lsnn.</code><code class="sig-name descname">LSNNParameters</code><a class="reference internal" href="../_modules/norse/torch/functional/lsnn.html#LSNNParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of an LSNN neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – inverse synaptic time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{syn}\)</span>)</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – inverse membrane time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{mem}\)</span>)</p></li>
<li><p><strong>tau_adapt_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – inverse adaptation time
constant (<span class="math notranslate nohighlight">\(1/\tau_b\)</span>)</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – leak potential</p></li>
<li><p><strong>v_th</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – threshold potential</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – reset potential</p></li>
<li><p><strong>beta</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – adaptation constant</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LSNNParameters(tau_syn_inv, tau_mem_inv, tau_adapt_inv, v_leak, v_th, v_reset, beta, method, alpha)</p>
<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.alpha">
<code class="sig-name descname">alpha</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 8</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.beta">
<code class="sig-name descname">beta</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.beta" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.method">
<code class="sig-name descname">method</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.tau_adapt_inv">
<code class="sig-name descname">tau_adapt_inv</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.tau_adapt_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.tau_mem_inv">
<code class="sig-name descname">tau_mem_inv</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.tau_syn_inv">
<code class="sig-name descname">tau_syn_inv</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.v_leak">
<code class="sig-name descname">v_leak</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.v_reset">
<code class="sig-name descname">v_reset</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.v_th">
<code class="sig-name descname">v_th</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.v_th" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.lsnn.LSNNState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lsnn.</code><code class="sig-name descname">LSNNState</code><a class="reference internal" href="../_modules/norse/torch/functional/lsnn.html#LSNNState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of an LSNN neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>b</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – threshold adaptation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LSNNState(z, v, i, b)</p>
<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNState.b">
<code class="sig-name descname">b</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNState.b" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNState.z">
<code class="sig-name descname">z</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lsnn.ada_lif_step">
<code class="sig-prename descclassname">norse.torch.functional.lsnn.</code><code class="sig-name descname">ada_lif_step</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">recurrent_weights</em>, <em class="sig-param">p=LSNNParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">tau_adapt_inv=tensor(0.0014)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">beta=tensor(1.8000)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=100.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lsnn.html#ada_lif_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lsnn.ada_lif_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Euler integration step for LIF Neuron with adaptation. More specifically
it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + b + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{b} &amp;= -1/\tau_{b} b
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\\text{rec}} \\
    b &amp;= b + \beta z
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the recurrent
and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_tensor</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><em>LSNNState</em></a>) – current state of the lsnn unit</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – synaptic weights for input spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lsnn.LSNNParameters" title="norse.torch.functional.lsnn.LSNNParameters"><em>LSNNParameters</em></a>) – parameters of the lsnn unit</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lsnn.lsnn_feed_forward_step">
<code class="sig-prename descclassname">norse.torch.functional.lsnn.</code><code class="sig-name descname">lsnn_feed_forward_step</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state</em>, <em class="sig-param">p=LSNNParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">tau_adapt_inv=tensor(0.0014)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">beta=tensor(1.8000)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=100.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lsnn.html#lsnn_feed_forward_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lsnn.lsnn_feed_forward_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Euler integration step for LIF Neuron with threshold adaptation.
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{b} &amp;= -1/\tau_{b} b
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}} + b)\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + \text{input} \\
    b &amp;= b + \beta z
\end{align*}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_tensor</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lsnn.LSNNFeedForwardState" title="norse.torch.functional.lsnn.LSNNFeedForwardState"><em>LSNNFeedForwardState</em></a>) – current state of the lsnn unit</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lsnn.LSNNParameters" title="norse.torch.functional.lsnn.LSNNParameters"><em>LSNNParameters</em></a>) – parameters of the lsnn unit</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lsnn.LSNNFeedForwardState" title="norse.torch.functional.lsnn.LSNNFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lsnn.lsnn_step">
<code class="sig-prename descclassname">norse.torch.functional.lsnn.</code><code class="sig-name descname">lsnn_step</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">recurrent_weights</em>, <em class="sig-param">p=LSNNParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">tau_adapt_inv=tensor(0.0014)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">beta=tensor(1.8000)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=100.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lsnn.html#lsnn_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lsnn.lsnn_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Euler integration step for LIF Neuron with threshold adaptation
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{b} &amp;= -1/\tau_{b} b
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}} + b)\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}} \\
    b &amp;= b + \beta z
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the recurrent
and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_tensor</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><em>LSNNState</em></a>) – current state of the lsnn unit</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – synaptic weights for input spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lsnn.LSNNParameters" title="norse.torch.functional.lsnn.LSNNParameters"><em>LSNNParameters</em></a>) – parameters of the lsnn unit</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+91256aa ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/logo.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">A library to do deep learning with spiking neural networks.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=norse&repo=norse&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Usage Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../about.html">1. About Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installing.html">2. Installing Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hardware.html">3. Hardware acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spiking.html">4. Introduction to spiking neural networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../learning.html">5. Learning with spikes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../working.html">6. Working with Norse</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">1. Beginner tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experiments.html">2. Running Experiments</a></li>
</ul>
<p class="caption"><span class="caption-text">API Docs</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="norse.benchmark.html">norse.benchmark package</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.task.html">norse.task package</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="norse.torch.html">norse.torch package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="norse.torch.functional.html">norse.torch.functional package</a></li>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.models.html">norse.torch.models package</a></li>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.module.html">norse.torch.module package</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="norse.torch.html">norse.torch package</a><ul>
  <li><a href="norse.torch.functional.html">norse.torch.functional package</a><ul>
      <li>Previous: <a href="norse.torch.functional.logical.html" title="previous chapter">norse.torch.functional.logical module</a></li>
      <li>Next: <a href="norse.torch.functional.regularization.html" title="next chapter">norse.torch.functional.regularization module</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Norse.ai.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.4.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/auto_api/norse.torch.functional.lsnn.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>