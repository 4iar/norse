
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>norse.torch.functional.encode module &#8212; norse 0.0.6 documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="norse.torch.functional.heaviside module" href="norse.torch.functional.heaviside.html" />
    <link rel="prev" title="norse.torch.functional.decode module" href="norse.torch.functional.decode.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="module-norse.torch.functional.encode">
<span id="norse-torch-functional-encode-module"></span><h1>norse.torch.functional.encode module<a class="headerlink" href="#module-norse.torch.functional.encode" title="Permalink to this headline">¶</a></h1>
<p>Stateless encoding functionality for Norse, offering different ways to convert numerical
inputs to the spiking domain. Note that some functions, like <cite>population_encode</cite> does not return spikes,
but rather numerical values that will have to be converted into spikes via, for instance, the poisson encoder.</p>
<dl class="py function">
<dt id="norse.torch.functional.encode.constant_current_lif_encode">
<code class="sig-prename descclassname"><span class="pre">norse.torch.functional.encode.</span></code><code class="sig-name descname"><span class="pre">constant_current_lif_encode</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_current</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.))</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/encode.html#constant_current_lif_encode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.functional.encode.constant_current_lif_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes input currents as fixed (constant) voltage currents, and simulates the spikes that
occur during a number of timesteps/iterations (seq_length).</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq_length</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># Simulate two iterations</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">constant_current_lif_encode</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">)</span>
<span class="go"> # State in terms of membrane voltage</span>
<span class="go">(tensor([[0.2000, 0.4000, 0.8000, 0.0000],</span>
<span class="go">         [0.3800, 0.7600, 0.0000, 0.0000]]),</span>
<span class="go"> # Spikes for each iteration</span>
<span class="go"> tensor([[0., 0., 0., 1.],</span>
<span class="go">         [0., 0., 1., 1.]]))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_current</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><em>torch.Tensor</em></a>) – The input tensor, representing LIF current</p></li>
<li><p><strong>seq_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of iterations to simulate</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.LIFParameters" title="norse.torch.functional.LIFParameters"><em>LIFParameters</em></a>) – Initial neuron parameters.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time delta between simulation steps</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor with an extra dimension of size <cite>seq_length</cite> containing spikes (1) or no spikes (0).</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="norse.torch.functional.encode.euclidean_distance">
<code class="sig-prename descclassname"><span class="pre">norse.torch.functional.encode.</span></code><code class="sig-name descname"><span class="pre">euclidean_distance</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">y</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/encode.html#euclidean_distance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.functional.encode.euclidean_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Simple euclidean distance metric.</p>
</dd></dl>

<dl class="py function">
<dt id="norse.torch.functional.encode.gaussian_rbf">
<code class="sig-prename descclassname"><span class="pre">norse.torch.functional.encode.</span></code><code class="sig-name descname"><span class="pre">gaussian_rbf</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/encode.html#gaussian_rbf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.functional.encode.gaussian_rbf" title="Permalink to this definition">¶</a></dt>
<dd><p>A <a class="reference external" href="https://en.wikipedia.org/wiki/Radial_basis_function_kernel">gaussian radial basis kernel</a>
that calculates the radial basis given a distance value (distance between <span class="math notranslate nohighlight">\(x\)</span> and a data
value <span class="math notranslate nohighlight">\(x'\)</span>, or <span class="math notranslate nohighlight">\(\|\mathbf{x} - \mathbf{x'}\|^2\)</span> below).</p>
<div class="math notranslate nohighlight">
\[K(\mathbf{x}, \mathbf{x'}) = \exp\left(- \frac{\|\mathbf{x} - \mathbf{x'}\|^2}{2\sigma^2}\right)\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tensor</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><em>torch.Tensor</em></a>) – The tensor containing distance values to convert to radial bases</p></li>
<li><p><strong>sigma</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – The spread of the gaussian distribution. Defaults to 1.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="norse.torch.functional.encode.poisson_encode">
<code class="sig-prename descclassname"><span class="pre">norse.torch.functional.encode.</span></code><code class="sig-name descname"><span class="pre">poisson_encode</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/encode.html#poisson_encode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.functional.encode.poisson_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes a tensor of input values, which are assumed to be in the
range [0,1] into a tensor of one dimension higher of binary values,
which represent input spikes.</p>
<p>See for example <a class="reference external" href="https://www.cns.nyu.edu/~david/handouts/poisson.pdf">https://www.cns.nyu.edu/~david/handouts/poisson.pdf</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_values</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><em>torch.Tensor</em></a>) – Input data tensor with values assumed to be in the interval [0,1].</p></li>
<li><p><strong>sequence_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of time steps in the resulting spike train.</p></li>
<li><p><strong>f_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Maximal frequency (in Hertz) which will be emitted.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration time step (should coincide with the integration time step used in the model)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor with an extra dimension of size <cite>seq_length</cite> containing spikes (1) or no spikes (0).</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="norse.torch.functional.encode.population_encode">
<code class="sig-prename descclassname"><span class="pre">norse.torch.functional.encode.</span></code><code class="sig-name descname"><span class="pre">population_encode</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">input_values</span></em>, <em class="sig-param"><span class="pre">out_features</span></em>, <em class="sig-param"><span class="pre">scale=None</span></em>, <em class="sig-param"><span class="pre">kernel=&lt;function</span> <span class="pre">gaussian_rbf&gt;</span></em>, <em class="sig-param"><span class="pre">distance_function=&lt;function</span> <span class="pre">euclidean_distance&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/encode.html#population_encode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.functional.encode.population_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes a set of input values into population codes, such that each singular input value is represented by
a list of numbers (typically calculated by a radial basis kernel), whose length is equal to the out_features.</p>
<p>Population encoding can be visualised by imagining a number of neurons in a list, whose activity increases
if a number gets close to its “receptive field”.</p>
<div class="figure align-default" id="id1">
<img alt="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/PopulationCode.svg/1920px-PopulationCode.svg.png" src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/PopulationCode.svg/1920px-PopulationCode.svg.png" />
<p class="caption"><span class="caption-text">Gaussian curves representing different neuron “receptive fields”. Image credit: <a class="reference external" href="https://commons.wikimedia.org/wiki/File:PopulationCode.svg">Andrew K. Richardson</a>.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out_features</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pop_encoded</span> <span class="o">=</span> <span class="n">population_encode</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>
<span class="go">tensor([[1.0000, 0.8825, 0.6065],</span>
<span class="go">        [0.8825, 1.0000, 0.8825],</span>
<span class="go">        [0.6065, 0.8825, 1.0000]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spikes</span> <span class="o">=</span> <span class="n">poisson_encode</span><span class="p">(</span><span class="n">pop_encoded</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span> <span class="c1"># Convert to spikes</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_values</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><em>torch.Tensor</em></a>) – The input data as numerical values to be encoded to population codes</p></li>
<li><p><strong>out_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of output <em>per</em> input value</p></li>
<li><p><strong>scale</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><em>torch.Tensor</em></a>) – The scaling factor for the kernels. Defaults to the maximum value of the input.
Can also be set for each individual sample.</p></li>
<li><p><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></a>[[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]) – A function that takes two inputs and returns a tensor. The two inputs represent the center value
(which changes for each index in the output tensor) and the actual data value to encode respectively.z
Defaults to gaussian radial basis kernel function.</p></li>
<li><p><strong>distance_function</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></a>[[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]) – A function that calculates the distance between two numbers. Defaults to euclidean.</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor with an extra dimension of size <cite>seq_length</cite> containing population encoded values of the input stimulus.
Note: An extra step is required to convert the values to spikes, see above.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="norse.torch.functional.encode.signed_poisson_encode">
<code class="sig-prename descclassname"><span class="pre">norse.torch.functional.encode.</span></code><code class="sig-name descname"><span class="pre">signed_poisson_encode</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_values</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/encode.html#signed_poisson_encode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.functional.encode.signed_poisson_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes a tensor of input values, which are assumed to be in the
range [-1,1] into a tensor of one dimension higher of binary values,
which represent input spikes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_values</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><em>torch.Tensor</em></a>) – Input data tensor with values assumed to be in the interval [-1,1].</p></li>
<li><p><strong>sequence_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of time steps in the resulting spike train.</p></li>
<li><p><strong>f_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Maximal frequency (in Hertz) which will be emitted.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration time step (should coincide with the integration time step used in the model)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor with an extra dimension of size <cite>seq_length</cite> containing spikes (1) or no spikes (0).</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="norse.torch.functional.encode.spike_latency_encode">
<code class="sig-prename descclassname"><span class="pre">norse.torch.functional.encode.</span></code><code class="sig-name descname"><span class="pre">spike_latency_encode</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_spikes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/encode.html#spike_latency_encode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.functional.encode.spike_latency_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>For all neurons, remove all but the first spike. This encoding basically measures the time it takes for a
neuron to spike <em>first</em>. Assuming that the inputs are constant, this makes sense in that strong inputs spikes
fast.</p>
<p>See <a class="reference external" href="https://doi.org/10.1162/08997660152002852">R. Van Rullen &amp; S. J. Thorpe (2001): Rate Coding Versus Temporal Order Coding: What the Retinal Ganglion Cells Tell the Visual Cortex</a>.</p>
<p>Spikes are identified by their unique position within each sequence.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">spike_latency_encode</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="go">tensor([[0, 1, 1],</span>
<span class="go">        [1, 0, 0]])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_spikes</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><em>torch.Tensor</em></a>) – A tensor of input spikes, assumed to be at least 2D (sequences, …)</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A tensor where the first spike (1) is retained in the sequence</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="norse.torch.functional.encode.spike_latency_lif_encode">
<code class="sig-prename descclassname"><span class="pre">norse.torch.functional.encode.</span></code><code class="sig-name descname"><span class="pre">spike_latency_lif_encode</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_current</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.))</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/encode.html#spike_latency_lif_encode"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.functional.encode.spike_latency_lif_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes an input value by the time the first spike occurs.
Similar to the ConstantCurrentLIFEncoder, but the LIF can be
thought to have an infinite refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_current</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><em>torch.Tensor</em></a>) – Input current to encode (needs to be positive).</p></li>
<li><p><strong>sequence_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of time steps in the resulting spike train.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.LIFParameters" title="norse.torch.functional.LIFParameters"><em>LIFParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration time step (should coincide with the integration time step used in the model)</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.9.0a0+c89db19 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/logo.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">A library to do deep learning with spiking neural networks.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=norse&repo=norse&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<p class="caption"><span class="caption-text">First steps</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../index.html">∇ Home</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../index.html#getting-started">Getting started</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#installing-norse">Installing Norse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#running-tasks">Running Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#advanced-uses-and-opimizations">Advanced uses and opimizations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#about-norse">About Norse</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html#table-of-contents">Table of contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../index.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../started.html">1. Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installing.html">2. Installing Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasks.html">3. Running Tasks</a></li>
</ul>
<p class="caption"><span class="caption-text">Usage docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../about.html">1. About Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hardware.html">2. Hardware acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spiking.html">3. Introduction to spikes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../learning.html">4. Learning with spikes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../papers.html">5. Papers citing Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../working.html">6. Working with Norse</a></li>
</ul>
<p class="caption"><span class="caption-text">API Docs</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="norse.benchmark.html">norse.benchmark package</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.task.html">norse.task package</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="norse.torch.html">norse.torch package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="norse.torch.functional.html">norse.torch.functional package</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.test.html">norse.torch.functional.test package</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.coba_lif.html">norse.torch.functional.coba_lif module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.correlation_sensor.html">norse.torch.functional.correlation_sensor module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.decode.html">norse.torch.functional.decode module</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">norse.torch.functional.encode module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.heaviside.html">norse.torch.functional.heaviside module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.leaky_integrator.html">norse.torch.functional.leaky_integrator module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.lif.html">norse.torch.functional.lif module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.lif_adex.html">norse.torch.functional.lif_adex module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.lif_correlation.html">norse.torch.functional.lif_correlation module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.lif_ex.html">norse.torch.functional.lif_ex module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.lif_mc.html">norse.torch.functional.lif_mc module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.lif_mc_refrac.html">norse.torch.functional.lif_mc_refrac module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.lif_refrac.html">norse.torch.functional.lif_refrac module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.lift.html">norse.torch.functional.lift module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.logical.html">norse.torch.functional.logical module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.lsnn.html">norse.torch.functional.lsnn module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.regularization.html">norse.torch.functional.regularization module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.stdp.html">norse.torch.functional.stdp module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.stdp_sensor.html">norse.torch.functional.stdp_sensor module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.superspike.html">norse.torch.functional.superspike module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.threshold.html">norse.torch.functional.threshold module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.functional.tsodyks_makram.html">norse.torch.functional.tsodyks_makram module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.models.html">norse.torch.models package</a></li>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.module.html">norse.torch.module package</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="norse.torch.html">norse.torch package</a><ul>
  <li><a href="norse.torch.functional.html">norse.torch.functional package</a><ul>
      <li>Previous: <a href="norse.torch.functional.decode.html" title="previous chapter">norse.torch.functional.decode module</a></li>
      <li>Next: <a href="norse.torch.functional.heaviside.html" title="next chapter">norse.torch.functional.heaviside module</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Norse.ai.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.5.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/auto_api/norse.torch.functional.encode.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>