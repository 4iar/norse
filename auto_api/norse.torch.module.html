
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>norse.torch.module package &#8212; norse 0.0.4 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="norse.torch.module.test package" href="norse.torch.module.test.html" />
    <link rel="prev" title="norse.torch.models.vgg module" href="norse.torch.models.vgg.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="module-norse.torch.module">
<span id="norse-torch-module-package"></span><h1>norse.torch.module package<a class="headerlink" href="#module-norse.torch.module" title="Permalink to this headline">¶</a></h1>
<p>Modules for spiking neural network, adhering to the <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> interface.</p>
<dl class="class">
<dt id="norse.torch.module.CobaLIFCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">CobaLIFCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=CobaLIFParameters(tau_syn_exc_inv=tensor(0.2000)</em>, <em class="sig-param">tau_syn_inh_inv=tensor(0.2000)</em>, <em class="sig-param">c_m_inv=tensor(5.)</em>, <em class="sig-param">g_l=tensor(0.2500)</em>, <em class="sig-param">e_rev_I=tensor(-100)</em>, <em class="sig-param">e_rev_E=tensor(60)</em>, <em class="sig-param">v_rest=tensor(-20)</em>, <em class="sig-param">v_reset=tensor(-70)</em>, <em class="sig-param">v_thresh=tensor(-10)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=100.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/coba_lif.html#CobaLIFCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.CobaLIFCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module that computes a single euler-integration step of a conductance based
LIF neuron-model. More specifically it implements one integration step of
the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/c_{\text{mem}} (g_l (v_{\text{leak}} - v)               + g_e (E_{\text{rev_e}} - v) + g_i (E_{\text{rev_i}} - v)) \\
    \dot{g_e} &amp;= -1/\tau_{\text{syn}} g_e \\
    \dot{g_i} &amp;= -1/\tau_{\text{syn}} g_i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    g_e &amp;= g_e + \text{relu}(w_{\text{input}}) z_{\text{in}} \\
    g_e &amp;= g_e + \text{relu}(w_{\text{rec}}) z_{\text{rec}} \\
    g_i &amp;= g_i + \text{relu}(-w_{\text{input}}) z_{\text{in}} \\
    g_i &amp;= g_i + \text{relu}(-w_{\text{rec}}) z_{\text{rec}} \\
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the recurrent
and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">CobaLIFCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.CobaLIFCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/coba_lif.html#CobaLIFCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.CobaLIFCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.coba_lif.html#norse.torch.functional.coba_lif.CobaLIFState" title="norse.torch.functional.coba_lif.CobaLIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">CobaLIFState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.CobaLIFCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.CobaLIFState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">CobaLIFState</code><a class="reference internal" href="../_modules/norse/torch/functional/coba_lif.html#CobaLIFState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.CobaLIFState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a conductance based LIF neuron.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>g_e</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – excitatory input conductance</p></li>
<li><p><strong>g_i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inhibitory input conductance</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of CobaLIFState(z, v, g_e, g_i)</p>
<dl class="attribute">
<dt id="norse.torch.module.CobaLIFState.g_e">
<code class="sig-name descname">g_e</code><a class="headerlink" href="#norse.torch.module.CobaLIFState.g_e" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFState.g_i">
<code class="sig-name descname">g_i</code><a class="headerlink" href="#norse.torch.module.CobaLIFState.g_i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.module.CobaLIFState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFState.z">
<code class="sig-name descname">z</code><a class="headerlink" href="#norse.torch.module.CobaLIFState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.CobaLIFParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">CobaLIFParameters</code><a class="reference internal" href="../_modules/norse/torch/functional/coba_lif.html#CobaLIFParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.CobaLIFParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of conductance based LIF neuron.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau_syn_exc_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse excitatory synaptic input
time constant</p></li>
<li><p><strong>tau_syn_inh_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse inhibitory synaptic input
time constant</p></li>
<li><p><strong>c_m_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse membrane capacitance</p></li>
<li><p><strong>g_l</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – leak conductance</p></li>
<li><p><strong>e_rev_I</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inhibitory reversal potential</p></li>
<li><p><strong>e_rev_E</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – excitatory reversal potential</p></li>
<li><p><strong>v_rest</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – rest membrane potential</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – reset membrane potential</p></li>
<li><p><strong>v_thresh</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – threshold membrane potential</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – method to determine the spike threshold
(relevant for surrogate gradients)</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – hyper parameter to use in surrogate gradient computation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of CobaLIFParameters(tau_syn_exc_inv, tau_syn_inh_inv, c_m_inv, g_l, e_rev_I, e_rev_E, v_rest, v_reset, v_thresh, method, alpha)</p>
<dl class="attribute">
<dt id="norse.torch.module.CobaLIFParameters.alpha">
<code class="sig-name descname">alpha</code><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 10</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFParameters.c_m_inv">
<code class="sig-name descname">c_m_inv</code><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.c_m_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFParameters.e_rev_E">
<code class="sig-name descname">e_rev_E</code><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.e_rev_E" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFParameters.e_rev_I">
<code class="sig-name descname">e_rev_I</code><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.e_rev_I" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFParameters.g_l">
<code class="sig-name descname">g_l</code><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.g_l" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFParameters.method">
<code class="sig-name descname">method</code><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 9</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFParameters.tau_syn_exc_inv">
<code class="sig-name descname">tau_syn_exc_inv</code><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.tau_syn_exc_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFParameters.tau_syn_inh_inv">
<code class="sig-name descname">tau_syn_inh_inv</code><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.tau_syn_inh_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFParameters.v_reset">
<code class="sig-name descname">v_reset</code><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFParameters.v_rest">
<code class="sig-name descname">v_rest</code><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.v_rest" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.CobaLIFParameters.v_thresh">
<code class="sig-name descname">v_thresh</code><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.v_thresh" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 8</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.ConstantCurrentLIFEncoder">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">ConstantCurrentLIFEncoder</code><span class="sig-paren">(</span><em class="sig-param">seq_length</em>, <em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=tensor(0.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#ConstantCurrentLIFEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.ConstantCurrentLIFEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encodes input currents as fixed (constant) voltage currents, and simulates the spikes that
occur during a number of timesteps/iterations (seq_length).</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq_length</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># Simulate two iterations</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">constant_current_lif_encode</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">)</span>
<span class="go">(tensor([[0.2000, 0.4000, 0.8000, 0.0000],   # State in terms of membrane voltage</span>
<span class="go">        [0.3800, 0.7600, 0.0000, 0.0000]]),</span>
<span class="go">tensor([[0., 0., 0., 1.],                   # Spikes for each iteration</span>
<span class="go">        [0., 0., 1., 1.]]))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seq_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of iterations to simulate</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – Initial neuron parameters.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time delta between simulation steps</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="norse.torch.module.ConstantCurrentLIFEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_currents</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#ConstantCurrentLIFEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.ConstantCurrentLIFEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.ConstantCurrentLIFEncoder.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.ConstantCurrentLIFEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.PoissonEncoder">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">PoissonEncoder</code><span class="sig-paren">(</span><em class="sig-param">seq_length</em>, <em class="sig-param">f_max=100</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#PoissonEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.PoissonEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encodes a tensor of input values, which are assumed to be in the
range [0,1] (if not signed, [-1,1] if signed)
into a tensor of one dimension higher of binary values,
which represent input spikes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_values</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – Input data tensor with values assumed to be in the interval [0,1].</p></li>
<li><p><strong>sequence_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of time steps in the resulting spike train.</p></li>
<li><p><strong>f_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Maximal frequency (in Hertz) which will be emitted.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration time step (should coincide with the integration time step used in the model)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="norse.torch.module.PoissonEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#PoissonEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.PoissonEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.PoissonEncoder.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.PoissonEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.PopulationEncoder">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">PopulationEncoder</code><span class="sig-paren">(</span><em class="sig-param">out_features</em>, <em class="sig-param">scale=None</em>, <em class="sig-param">kernel=&lt;function gaussian_rbf&gt;</em>, <em class="sig-param">distance_function=&lt;function euclidean_distance&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#PopulationEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.PopulationEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encodes a set of input values into population codes, such that each singular input value is represented by
a list of numbers (typically calculated by a radial basis kernel), whose length is equal to the out_features.</p>
<p>Population encoding can be visualised by imagining a number of neurons in a list, whose activity increases
if a number gets close to its “receptive field”.</p>
<div class="figure align-default" id="id1">
<img alt="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/PopulationCode.svg/1920px-PopulationCode.svg.png" src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/PopulationCode.svg/1920px-PopulationCode.svg.png" />
<p class="caption"><span class="caption-text">Gaussian curves representing different neuron “receptive fields”. Image credit: <a class="reference external" href="https://com">Andrew K. Richardson</a>.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p>super(PopulationEncoder, self).__init__()mons.wikimedia.org/wiki/<a class="reference external" href="File:PopulationCode.svg">File:PopulationCode.svg</a></p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out_features</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">PopulationEncoder</span><span class="p">(</span><span class="n">out_features</span><span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="go">tensor([[1.0000, 0.8825, 0.6065],</span>
<span class="go">        [0.8825, 1.0000, 0.8825],</span>
<span class="go">        [0.6065, 0.8825, 1.0000]])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of output <em>per</em> input value</p></li>
<li><p><strong>scale</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – The scaling factor for the kernels. Defaults to the maximum value of the input.
Can also be set for each individual sample.</p></li>
<li><p><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></a>[[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]) – A function that takes two inputs and returns a tensor. The two inputs represent the center value
(which changes for each index in the output tensor) and the actual data value to encode respectively.z
Defaults to gaussian radial basis kernel function.</p></li>
<li><p><strong>distance_function</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></a>[[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]) – A function that calculates the distance between two numbers. Defaults to euclidean.</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="norse.torch.module.PopulationEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#PopulationEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.PopulationEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.PopulationEncoder.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.PopulationEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.SignedPoissonEncoder">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">SignedPoissonEncoder</code><span class="sig-paren">(</span><em class="sig-param">seq_length</em>, <em class="sig-param">f_max=100</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#SignedPoissonEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.SignedPoissonEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encodes a tensor of input values, which are assumed to be in the
range [-1,1] (if not signed, [-1,1] if signed)
into a tensor of one dimension higher of binary values,
which represent input spikes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of time steps in the resulting spike train.</p></li>
<li><p><strong>f_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Maximal frequency (in Hertz) which will be emitted.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration time step (should coincide with the integration time step used in the model)</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="norse.torch.module.SignedPoissonEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#SignedPoissonEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.SignedPoissonEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.SignedPoissonEncoder.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.SignedPoissonEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.SpikeLatencyEncoder">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">SpikeLatencyEncoder</code><a class="reference internal" href="../_modules/norse/torch/module/encode.html#SpikeLatencyEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.SpikeLatencyEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>For all neurons, remove all but the first spike. This encoding basically measures the time it takes for a
neuron to spike <em>first</em>. Assuming that the inputs are constant, this makes sense in that strong inputs spikes
fast.</p>
<p>See <a class="reference external" href="https://doi.org/10.1162/08997660152002852">R. Van Rullen &amp; S. J. Thorpe (2001): Rate Coding Versus Temporal Order Coding: What the Retinal Ganglion Cells Tell the Visual Cortex</a>.</p>
<p>Spikes are identified by their unique position in the input array.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="go">                ConstantCurrentLIFEncoder()</span>
<span class="go">                SpikeLatencyEncoder()</span>
<span class="go">                )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoder</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="go">tensor([[0, 1, 1],</span>
<span class="go">        [1, 0, 0]])</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.SpikeLatencyEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_spikes</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#SpikeLatencyEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.SpikeLatencyEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.SpikeLatencyEncoder.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.SpikeLatencyEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.SpikeLatencyLIFEncoder">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">SpikeLatencyLIFEncoder</code><span class="sig-paren">(</span><em class="sig-param">seq_length</em>, <em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=tensor(0.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#SpikeLatencyLIFEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.SpikeLatencyLIFEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encodes an input value by the time the first spike occurs.
Similar to the ConstantCurrentLIFEncoder, but the LIF can be
thought to have an infinite refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of time steps in the resulting spike train.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration time step (should coincide with the integration time step used in the model)</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.SpikeLatencyLIFEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_current</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#SpikeLatencyLIFEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.SpikeLatencyLIFEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.SpikeLatencyLIFEncoder.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.SpikeLatencyLIFEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LICell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LICell</code><span class="sig-paren">(</span><em class="sig-param">input_features</em>, <em class="sig-param">output_features</em>, <em class="sig-param">p=LIParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.</em>, <em class="sig-param">requires_grad=True)</em>, <em class="sig-param">v_reset=tensor(0.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/leaky_integrator.html#LICell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LICell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Cell for a leaky-integrator.
More specifically it implements a discretized version of the ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[i = i + w i_{\text{in}}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – </p></li>
<li><p><strong>output_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Output feature dimension</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.leaky_integrator.html#norse.torch.functional.leaky_integrator.LIParameters" title="norse.torch.functional.leaky_integrator.LIParameters"><em>LIParameters</em></a>) – parameters of the leaky integrator</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – integration timestep to use</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LICell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/leaky_integrator.html#LICell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LICell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.leaky_integrator.html#norse.torch.functional.leaky_integrator.LIState" title="norse.torch.functional.leaky_integrator.LIState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LICell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LICell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFeedForwardCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFeedForwardCell</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">p=LIParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.</em>, <em class="sig-param">requires_grad=True)</em>, <em class="sig-param">v_reset=tensor(0.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/leaky_integrator.html#LIFeedForwardCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFeedForwardCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Cell for a leaky-integrator.
More specifically it implements a discretized version of the ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[i = i + w i_{\text{in}}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> – Shape of the preprocessed input spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.leaky_integrator.html#norse.torch.functional.leaky_integrator.LIParameters" title="norse.torch.functional.leaky_integrator.LIParameters"><em>LIParameters</em></a>) – parameters of the leaky integrator</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – integration timestep to use</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFeedForwardCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/leaky_integrator.html#LIFeedForwardCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFeedForwardCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.leaky_integrator.html#norse.torch.functional.leaky_integrator.LIState" title="norse.torch.functional.leaky_integrator.LIState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFeedForwardCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFeedForwardCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIParameters</code><a class="reference internal" href="../_modules/norse/torch/functional/leaky_integrator.html#LIParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of a leaky integrator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse synaptic time constant</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse membrane time constant</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – leak potential</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – reset potential</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIParameters(tau_syn_inv, tau_mem_inv, v_leak, v_reset)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIParameters.tau_mem_inv">
<code class="sig-name descname">tau_mem_inv</code><a class="headerlink" href="#norse.torch.module.LIParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIParameters.tau_syn_inv">
<code class="sig-name descname">tau_syn_inv</code><a class="headerlink" href="#norse.torch.module.LIParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIParameters.v_leak">
<code class="sig-name descname">v_leak</code><a class="headerlink" href="#norse.torch.module.LIParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIParameters.v_reset">
<code class="sig-name descname">v_reset</code><a class="headerlink" href="#norse.torch.module.LIParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIState</code><a class="reference internal" href="../_modules/norse/torch/functional/leaky_integrator.html#LIState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a leaky-integrator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane voltage</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – input current</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIState(v, i)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.module.LIState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.module.LIState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=tensor(0.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module that computes a single euler-integration step of a
LIF neuron-model with recurrence.
More specifically it implements one integration step
of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \
    i &amp;= i + w_{\text{input}} z_{\text{in}} \
    i &amp;= i + w_{\text{rec}} z_{\text{rec}}
\end{align*}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">LIFCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFCell.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFCell.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFCell.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should reimplement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.LIFCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFLayer">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFLayer</code><span class="sig-paren">(</span><em class="sig-param">*cell_args</em>, <em class="sig-param">**kw_args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A neuron layer that wraps a recurrent LIFCell in time such
that the layer keeps track of temporal sequences of spikes.
After application, the layer returns a tuple containing</p>
<blockquote>
<div><p>(spikes from all timesteps, state from the last timestep).</p>
</div></blockquote>
<p>Example:
&gt;&gt;&gt; data = torch.zeros(10, 5, 2) # 10 timesteps, 5 batches, 2 neurons
&gt;&gt;&gt; l = LIFLayer(2, 4)
&gt;&gt;&gt; l(data) # Returns tuple of (Tensor(10, 5, 4), LIFState)</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFLayer.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFLayer.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFFeedForwardCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFFeedForwardCell</code><span class="sig-paren">(</span><em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=tensor(0.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFFeedForwardCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFFeedForwardCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module that computes a single euler-integration step of a LIF neuron.
It takes as input the input current as generated by an arbitrary torch
module or function. More specifically it implements one integration step
of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[i = i + i_{\text{in}}\]</div>
<p>where <span class="math notranslate nohighlight">\(i_{\text{in}}\)</span> is meant to be the result of applying
an arbitrary pytorch module (such as a convolution) to input spikes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">LIFFeedForwardCell</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFFeedForwardCell.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFFeedForwardCell.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFFeedForwardCell.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should reimplement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.LIFFeedForwardCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFFeedForwardCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFFeedForwardCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFFeedForwardCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFFeedForwardCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFFeedForwardState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFFeedForwardState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif.html#LIFFeedForwardState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a feed forward LIF neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFFeedForwardState(v, i)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFFeedForwardState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.module.LIFFeedForwardState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFFeedForwardState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.module.LIFFeedForwardState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFParameters</code><a class="reference internal" href="../_modules/norse/torch/functional/lif.html#LIFParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parametrization of a LIF neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse synaptic time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{syn}\)</span>) in 1/ms</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse membrane time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{mem}\)</span>) in 1/ms</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – leak potential in mV</p></li>
<li><p><strong>v_th</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – threshold potential in mV</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – reset potential in mV</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – method to determine the spike threshold
(relevant for surrogate gradients)</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – hyper parameter to use in surrogate gradient computation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFParameters(tau_syn_inv, tau_mem_inv, v_leak, v_th, v_reset, method, alpha)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFParameters.alpha">
<code class="sig-name descname">alpha</code><a class="headerlink" href="#norse.torch.module.LIFParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFParameters.method">
<code class="sig-name descname">method</code><a class="headerlink" href="#norse.torch.module.LIFParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFParameters.tau_mem_inv">
<code class="sig-name descname">tau_mem_inv</code><a class="headerlink" href="#norse.torch.module.LIFParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFParameters.tau_syn_inv">
<code class="sig-name descname">tau_syn_inv</code><a class="headerlink" href="#norse.torch.module.LIFParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFParameters.v_leak">
<code class="sig-name descname">v_leak</code><a class="headerlink" href="#norse.torch.module.LIFParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFParameters.v_reset">
<code class="sig-name descname">v_reset</code><a class="headerlink" href="#norse.torch.module.LIFParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFParameters.v_th">
<code class="sig-name descname">v_th</code><a class="headerlink" href="#norse.torch.module.LIFParameters.v_th" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif.html#LIFState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIF neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFState(z, v, i)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.module.LIFState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.module.LIFState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFState.z">
<code class="sig-name descname">z</code><a class="headerlink" href="#norse.torch.module.LIFState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFAdExCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFAdExCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFAdExParameters(adaptation_current=tensor(4)</em>, <em class="sig-param">adaptation_spike=tensor(0.0200)</em>, <em class="sig-param">delta_T=tensor(0.5000)</em>, <em class="sig-param">tau_ada_inv=tensor(2.)</em>, <em class="sig-param">tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFAdExCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Computes a single euler-integration step of a recurrent adaptive exponential
LIF neuron-model adapted from
<a class="reference external" href="http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model">http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model</a>.
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} \left(v_{\text{leak}} - v + i + \Delta_T exp\left({{v - v_{\text{th}}} \over {\Delta_T}}\right)\right) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{a} &amp;= 1/\tau_{\text{ada}} \left( a_{current} (V - v_{\text{leak}}) - a \right)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif_ex.html#norse.torch.functional.lif_ex.LIFExParameters" title="norse.torch.functional.lif_ex.LIFExParameters"><em>LIFExParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif_ex</span> <span class="o">=</span> <span class="n">LIFAdExCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif_ex</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFAdExCell.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExCell.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFAdExCell.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should reimplement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.LIFAdExCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFAdExCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_adex.html#norse.torch.functional.lif_adex.LIFAdExState" title="norse.torch.functional.lif_adex.LIFAdExState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFAdExState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFAdExCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFAdExFeedForwardCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFAdExFeedForwardCell</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">p=LIFAdExParameters(adaptation_current=tensor(4)</em>, <em class="sig-param">adaptation_spike=tensor(0.0200)</em>, <em class="sig-param">delta_T=tensor(0.5000)</em>, <em class="sig-param">tau_ada_inv=tensor(2.)</em>, <em class="sig-param">tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExFeedForwardCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFAdExFeedForwardCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Computes a single euler-integration step of a feed-forward exponential
LIF neuron-model adapted from
<a class="reference external" href="http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model">http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model</a>.
It takes as input the input current as generated by an arbitrary torch
module or function. More specifically it implements one integration step
of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} \left(v_{\text{leak}} - v + i + \Delta_T exp\left({{v - v_{\text{th}}} \over {\Delta_T}}\right)\right) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{a} &amp;= 1/\tau_{\text{ada}} \left( a_{current} (V - v_{\text{leak}}) - a \right)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[i = i + i_{\text{in}}\]</div>
<p>where <span class="math notranslate nohighlight">\(i_{\text{in}}\)</span> is meant to be the result of applying
an arbitrary pytorch module (such as a convolution) to input spikes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> – Shape of the feedforward state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif_ex.html#norse.torch.functional.lif_ex.LIFExParameters" title="norse.torch.functional.lif_ex.LIFExParameters"><em>LIFExParameters</em></a>) – Parameters of the LIFEx neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif_ex</span> <span class="o">=</span> <span class="n">LIFExFeedForwardCell</span><span class="p">((</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif_ex</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFAdExFeedForwardCell.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExFeedForwardCell.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFAdExFeedForwardCell.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should reimplement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.LIFAdExFeedForwardCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExFeedForwardCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFAdExFeedForwardCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_adex.html#norse.torch.functional.lif_adex.LIFAdExFeedForwardState" title="norse.torch.functional.lif_adex.LIFAdExFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFAdExFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExFeedForwardCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFAdExFeedForwardCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFAdExFeedForwardState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFAdExFeedForwardState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#LIFAdExFeedForwardState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFAdExFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a feed forward LIFAdEx neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>a</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential adaptation factor</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFAdExFeedForwardState(v, i, a)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFAdExFeedForwardState.a">
<code class="sig-name descname">a</code><a class="headerlink" href="#norse.torch.module.LIFAdExFeedForwardState.a" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExFeedForwardState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.module.LIFAdExFeedForwardState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExFeedForwardState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.module.LIFAdExFeedForwardState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFAdExParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFAdExParameters</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#LIFAdExParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFAdExParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parametrization of an Adaptive Exponential Leaky Integrate and Fire neuron</p>
<p>Default values from <a class="reference external" href="https://github.com/NeuralEnsemble/PyNN/blob/d8056fa956998b031a1c3689a528473ed2bc0265/pyNN/standardmodels/cells.py#L416">https://github.com/NeuralEnsemble/PyNN/blob/d8056fa956998b031a1c3689a528473ed2bc0265/pyNN/standardmodels/cells.py#L416</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>adaptation_current</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – adaptation coupling parameter in nS</p></li>
<li><p><strong>adaptation_spike</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – spike triggered adaptation parameter in nA</p></li>
<li><p><strong>delta_T</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – sharpness or speed of the exponential growth in mV</p></li>
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse adaptation time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{ada}\)</span>) in 1/ms</p></li>
<li><p><strong>tau_syn_inv</strong> – inverse synaptic time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{syn}\)</span>) in 1/ms</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse membrane time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{mem}\)</span>) in 1/ms</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – leak potential in mV</p></li>
<li><p><strong>v_th</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – threshold potential in mV</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – reset potential in mV</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – method to determine the spike threshold
(relevant for surrogate gradients)</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – hyper parameter to use in surrogate gradient computation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFAdExParameters(adaptation_current, adaptation_spike, delta_T, tau_ada_inv, tau_syn_inv, tau_mem_inv, v_leak, v_th, v_reset, method, alpha)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFAdExParameters.adaptation_current">
<code class="sig-name descname">adaptation_current</code><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.adaptation_current" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExParameters.adaptation_spike">
<code class="sig-name descname">adaptation_spike</code><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.adaptation_spike" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExParameters.alpha">
<code class="sig-name descname">alpha</code><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 10</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExParameters.delta_T">
<code class="sig-name descname">delta_T</code><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.delta_T" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExParameters.method">
<code class="sig-name descname">method</code><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 9</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExParameters.tau_ada_inv">
<code class="sig-name descname">tau_ada_inv</code><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.tau_ada_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExParameters.tau_mem_inv">
<code class="sig-name descname">tau_mem_inv</code><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExParameters.tau_syn_inv">
<code class="sig-name descname">tau_syn_inv</code><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExParameters.v_leak">
<code class="sig-name descname">v_leak</code><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExParameters.v_reset">
<code class="sig-name descname">v_reset</code><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 8</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExParameters.v_th">
<code class="sig-name descname">v_th</code><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.v_th" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFAdExState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFAdExState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#LIFAdExState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFAdExState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIFAdEx neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>a</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential adaptation factor</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFAdExState(z, v, i, a)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFAdExState.a">
<code class="sig-name descname">a</code><a class="headerlink" href="#norse.torch.module.LIFAdExState.a" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.module.LIFAdExState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.module.LIFAdExState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExState.z">
<code class="sig-name descname">z</code><a class="headerlink" href="#norse.torch.module.LIFAdExState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFAdExLayer">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFAdExLayer</code><span class="sig-paren">(</span><em class="sig-param">*cell_args</em>, <em class="sig-param">**kw_args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFAdExLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A neuron layer that wraps a recurrent LIFAdExCell in time such
that the layer keeps track of temporal sequences of spikes.
After application, the layer returns a tuple containing</p>
<blockquote>
<div><p>(spikes from all timesteps, state from the last timestep).</p>
</div></blockquote>
<p>Example:
&gt;&gt;&gt; data = torch.zeros(10, 5, 2) # 10 timesteps, 5 batches, 2 neurons
&gt;&gt;&gt; l = LIFAdExLayer(2, 4)
&gt;&gt;&gt; l(data) # Returns tuple of (Tensor(10, 5, 4), LIFExState)</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFAdExLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFAdExLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_adex.html#norse.torch.functional.lif_adex.LIFAdExState" title="norse.torch.functional.lif_adex.LIFAdExState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFAdExState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFAdExLayer.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFAdExLayer.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFAdExCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFAdExParameters(adaptation_current=tensor(4)</em>, <em class="sig-param">adaptation_spike=tensor(0.0200)</em>, <em class="sig-param">delta_T=tensor(0.5000)</em>, <em class="sig-param">tau_ada_inv=tensor(2.)</em>, <em class="sig-param">tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExCell"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Computes a single euler-integration step of a recurrent adaptive exponential
LIF neuron-model adapted from
<a class="reference external" href="http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model">http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model</a>.
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} \left(v_{\text{leak}} - v + i + \Delta_T exp\left({{v - v_{\text{th}}} \over {\Delta_T}}\right)\right) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{a} &amp;= 1/\tau_{\text{ada}} \left( a_{current} (V - v_{\text{leak}}) - a \right)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif_ex.html#norse.torch.functional.lif_ex.LIFExParameters" title="norse.torch.functional.lif_ex.LIFExParameters"><em>LIFExParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif_ex</span> <span class="o">=</span> <span class="n">LIFAdExCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif_ex</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt>
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExCell.extra_repr"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should reimplement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExCell.forward"><span class="viewcode-link">[source]</span></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_adex.html#norse.torch.functional.lif_adex.LIFAdExState" title="norse.torch.functional.lif_adex.LIFAdExState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFAdExState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">training</code><em class="property"> = None</em></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFAdExFeedForwardCell</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">p=LIFAdExParameters(adaptation_current=tensor(4)</em>, <em class="sig-param">adaptation_spike=tensor(0.0200)</em>, <em class="sig-param">delta_T=tensor(0.5000)</em>, <em class="sig-param">tau_ada_inv=tensor(2.)</em>, <em class="sig-param">tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExFeedForwardCell"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Computes a single euler-integration step of a feed-forward exponential
LIF neuron-model adapted from
<a class="reference external" href="http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model">http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model</a>.
It takes as input the input current as generated by an arbitrary torch
module or function. More specifically it implements one integration step
of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} \left(v_{\text{leak}} - v + i + \Delta_T exp\left({{v - v_{\text{th}}} \over {\Delta_T}}\right)\right) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{a} &amp;= 1/\tau_{\text{ada}} \left( a_{current} (V - v_{\text{leak}}) - a \right)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[i = i + i_{\text{in}}\]</div>
<p>where <span class="math notranslate nohighlight">\(i_{\text{in}}\)</span> is meant to be the result of applying
an arbitrary pytorch module (such as a convolution) to input spikes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> – Shape of the feedforward state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif_ex.html#norse.torch.functional.lif_ex.LIFExParameters" title="norse.torch.functional.lif_ex.LIFExParameters"><em>LIFExParameters</em></a>) – Parameters of the LIFEx neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif_ex</span> <span class="o">=</span> <span class="n">LIFExFeedForwardCell</span><span class="p">((</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif_ex</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt>
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExFeedForwardCell.extra_repr"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should reimplement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt>
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExFeedForwardCell.forward"><span class="viewcode-link">[source]</span></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_adex.html#norse.torch.functional.lif_adex.LIFAdExFeedForwardState" title="norse.torch.functional.lif_adex.LIFAdExFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFAdExFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">training</code><em class="property"> = None</em></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFAdExFeedForwardState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#LIFAdExFeedForwardState"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a feed forward LIFAdEx neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>a</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential adaptation factor</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFAdExFeedForwardState(v, i, a)</p>
<dl class="attribute">
<dt>
<code class="sig-name descname">a</code></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">i</code></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">v</code></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFAdExParameters</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#LIFAdExParameters"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parametrization of an Adaptive Exponential Leaky Integrate and Fire neuron</p>
<p>Default values from <a class="reference external" href="https://github.com/NeuralEnsemble/PyNN/blob/d8056fa956998b031a1c3689a528473ed2bc0265/pyNN/standardmodels/cells.py#L416">https://github.com/NeuralEnsemble/PyNN/blob/d8056fa956998b031a1c3689a528473ed2bc0265/pyNN/standardmodels/cells.py#L416</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>adaptation_current</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – adaptation coupling parameter in nS</p></li>
<li><p><strong>adaptation_spike</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – spike triggered adaptation parameter in nA</p></li>
<li><p><strong>delta_T</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – sharpness or speed of the exponential growth in mV</p></li>
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse adaptation time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{ada}\)</span>) in 1/ms</p></li>
<li><p><strong>tau_syn_inv</strong> – inverse synaptic time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{syn}\)</span>) in 1/ms</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse membrane time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{mem}\)</span>) in 1/ms</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – leak potential in mV</p></li>
<li><p><strong>v_th</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – threshold potential in mV</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – reset potential in mV</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – method to determine the spike threshold
(relevant for surrogate gradients)</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – hyper parameter to use in surrogate gradient computation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFAdExParameters(adaptation_current, adaptation_spike, delta_T, tau_ada_inv, tau_syn_inv, tau_mem_inv, v_leak, v_th, v_reset, method, alpha)</p>
<dl class="attribute">
<dt>
<code class="sig-name descname">adaptation_current</code></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">adaptation_spike</code></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">alpha</code></dt>
<dd><p>Alias for field number 10</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">delta_T</code></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">method</code></dt>
<dd><p>Alias for field number 9</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">tau_ada_inv</code></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">tau_mem_inv</code></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">tau_syn_inv</code></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">v_leak</code></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">v_reset</code></dt>
<dd><p>Alias for field number 8</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">v_th</code></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFAdExState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#LIFAdExState"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIFAdEx neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>a</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential adaptation factor</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFAdExState(z, v, i, a)</p>
<dl class="attribute">
<dt>
<code class="sig-name descname">a</code></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">i</code></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">v</code></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">z</code></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFCorrelation">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFCorrelation</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFCorrelationParameters(lif_parameters=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=tensor(0.))</em>, <em class="sig-param">input_correlation_parameters=CorrelationSensorParameters(eta_p=tensor(1.)</em>, <em class="sig-param">eta_m=tensor(1.)</em>, <em class="sig-param">tau_ac_inv=tensor(10.)</em>, <em class="sig-param">tau_c_inv=tensor(10.))</em>, <em class="sig-param">recurrent_correlation_parameters=CorrelationSensorParameters(eta_p=tensor(1.)</em>, <em class="sig-param">eta_m=tensor(1.)</em>, <em class="sig-param">tau_ac_inv=tensor(10.)</em>, <em class="sig-param">tau_c_inv=tensor(10.)))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_correlation.html#LIFCorrelation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFCorrelation" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFCorrelation.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">recurrent_weights</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_correlation.html#LIFCorrelation.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFCorrelation.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_correlation.html#norse.torch.functional.lif_correlation.LIFCorrelationState" title="norse.torch.functional.lif_correlation.LIFCorrelationState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFCorrelationState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFCorrelation.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFCorrelation.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFCorrelationParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFCorrelationParameters</code><span class="sig-paren">(</span><em class="sig-param">lif_parameters</em>, <em class="sig-param">input_correlation_parameters</em>, <em class="sig-param">recurrent_correlation_parameters</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_correlation.html#LIFCorrelationParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFCorrelationParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Create new instance of LIFCorrelationParameters(lif_parameters, input_correlation_parameters, recurrent_correlation_parameters)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFCorrelationParameters.input_correlation_parameters">
<code class="sig-name descname">input_correlation_parameters</code><a class="headerlink" href="#norse.torch.module.LIFCorrelationParameters.input_correlation_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFCorrelationParameters.lif_parameters">
<code class="sig-name descname">lif_parameters</code><a class="headerlink" href="#norse.torch.module.LIFCorrelationParameters.lif_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFCorrelationParameters.recurrent_correlation_parameters">
<code class="sig-name descname">recurrent_correlation_parameters</code><a class="headerlink" href="#norse.torch.module.LIFCorrelationParameters.recurrent_correlation_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFCorrelationState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFCorrelationState</code><span class="sig-paren">(</span><em class="sig-param">lif_state</em>, <em class="sig-param">input_correlation_state</em>, <em class="sig-param">recurrent_correlation_state</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_correlation.html#LIFCorrelationState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFCorrelationState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Create new instance of LIFCorrelationState(lif_state, input_correlation_state, recurrent_correlation_state)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFCorrelationState.input_correlation_state">
<code class="sig-name descname">input_correlation_state</code><a class="headerlink" href="#norse.torch.module.LIFCorrelationState.input_correlation_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFCorrelationState.lif_state">
<code class="sig-name descname">lif_state</code><a class="headerlink" href="#norse.torch.module.LIFCorrelationState.lif_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFCorrelationState.recurrent_correlation_state">
<code class="sig-name descname">recurrent_correlation_state</code><a class="headerlink" href="#norse.torch.module.LIFCorrelationState.recurrent_correlation_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFExCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFExCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFExParameters(delta_T=tensor(0.5000)</em>, <em class="sig-param">tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFExCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Computes a single euler-integration step of a recurrent
exponential LIF neuron-model adapted from
<a class="reference external" href="https://neuronaldynamics.epfl.ch/online/Ch5.S2.html">https://neuronaldynamics.epfl.ch/online/Ch5.S2.html</a>.
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} \left(v_{\text{leak}} - v + i + \Delta_T exp\left({{v - v_{\text{th}}} \over {\Delta_T}}\right)\right) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\begin{align*}
    v &amp;= (1-z) v + z v_{\\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif_ex.html#norse.torch.functional.lif_ex.LIFExParameters" title="norse.torch.functional.lif_ex.LIFExParameters"><em>LIFExParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif_ex</span> <span class="o">=</span> <span class="n">LIFExCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif_ex</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFExCell.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExCell.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFExCell.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should reimplement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.LIFExCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFExCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_ex.html#norse.torch.functional.lif_ex.LIFExState" title="norse.torch.functional.lif_ex.LIFExState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFExState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFExCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFExCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFExFeedForwardCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFExFeedForwardCell</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">p=LIFExParameters(delta_T=tensor(0.5000)</em>, <em class="sig-param">tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExFeedForwardCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFExFeedForwardCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Computes a single euler-integration step of a feed-forward exponential
LIF neuron-model adapted from
<a class="reference external" href="https://neuronaldynamics.epfl.ch/online/Ch5.S2.html">https://neuronaldynamics.epfl.ch/online/Ch5.S2.html</a>.
It takes as input the input current as generated by an arbitrary torch
module or function. More specifically it implements one integration step
of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} \left(v_{\text{leak}} - v + i + \Delta_T exp\left({{v - v_{\text{th}}} \over {\Delta_T}}\right)\right) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[i = i + i_{\text{in}}\]</div>
<p>where <span class="math notranslate nohighlight">\(i_{\text{in}}\)</span> is meant to be the result of applying
an arbitrary pytorch module (such as a convolution) to input spikes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> – Shape of the feedforward state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif_ex.html#norse.torch.functional.lif_ex.LIFExParameters" title="norse.torch.functional.lif_ex.LIFExParameters"><em>LIFExParameters</em></a>) – Parameters of the LIFEx neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif_ex</span> <span class="o">=</span> <span class="n">LIFExFeedForwardCell</span><span class="p">((</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif_ex</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFExFeedForwardCell.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExFeedForwardCell.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFExFeedForwardCell.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should reimplement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.LIFExFeedForwardCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExFeedForwardCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFExFeedForwardCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_ex.html#norse.torch.functional.lif_ex.LIFExFeedForwardState" title="norse.torch.functional.lif_ex.LIFExFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFExFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFExFeedForwardCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFExFeedForwardCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFExFeedForwardState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFExFeedForwardState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_ex.html#LIFExFeedForwardState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFExFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a feed forward LIFEx neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFExFeedForwardState(v, i)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFExFeedForwardState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.module.LIFExFeedForwardState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFExFeedForwardState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.module.LIFExFeedForwardState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFExLayer">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFExLayer</code><span class="sig-paren">(</span><em class="sig-param">*cell_args</em>, <em class="sig-param">**kw_args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFExLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A neuron layer that wraps a recurrent LIFExCell in time such
that the layer keeps track of temporal sequences of spikes.
After application, the layer returns a tuple containing</p>
<blockquote>
<div><p>(spikes from all timesteps, state from the last timestep).</p>
</div></blockquote>
<p>Example:
&gt;&gt;&gt; data = torch.zeros(10, 5, 2) # 10 timesteps, 5 batches, 2 neurons
&gt;&gt;&gt; l = LIFExLayer(2, 4)
&gt;&gt;&gt; l(data) # Returns tuple of (Tensor(10, 5, 4), LIFExState)</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFExLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFExLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_ex.html#norse.torch.functional.lif_ex.LIFExState" title="norse.torch.functional.lif_ex.LIFExState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFExState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFExLayer.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFExLayer.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFExParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFExParameters</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_ex.html#LIFExParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFExParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parametrization of an Exponential Leaky Integrate and Fire neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>delta_T</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – sharpness or speed of the exponential growth in mV</p></li>
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse synaptic time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{syn}\)</span>) in 1/ms</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse membrane time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{mem}\)</span>) in 1/ms</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – leak potential in mV</p></li>
<li><p><strong>v_th</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – threshold potential in mV</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – reset potential in mV</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – method to determine the spike threshold
(relevant for surrogate gradients)</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – hyper parameter to use in surrogate gradient computation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFExParameters(delta_T, tau_syn_inv, tau_mem_inv, v_leak, v_th, v_reset, method, alpha)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFExParameters.alpha">
<code class="sig-name descname">alpha</code><a class="headerlink" href="#norse.torch.module.LIFExParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFExParameters.delta_T">
<code class="sig-name descname">delta_T</code><a class="headerlink" href="#norse.torch.module.LIFExParameters.delta_T" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFExParameters.method">
<code class="sig-name descname">method</code><a class="headerlink" href="#norse.torch.module.LIFExParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFExParameters.tau_mem_inv">
<code class="sig-name descname">tau_mem_inv</code><a class="headerlink" href="#norse.torch.module.LIFExParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFExParameters.tau_syn_inv">
<code class="sig-name descname">tau_syn_inv</code><a class="headerlink" href="#norse.torch.module.LIFExParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFExParameters.v_leak">
<code class="sig-name descname">v_leak</code><a class="headerlink" href="#norse.torch.module.LIFExParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFExParameters.v_reset">
<code class="sig-name descname">v_reset</code><a class="headerlink" href="#norse.torch.module.LIFExParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFExParameters.v_th">
<code class="sig-name descname">v_th</code><a class="headerlink" href="#norse.torch.module.LIFExParameters.v_th" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFExState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFExState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_ex.html#LIFExState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFExState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIFEx neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFExState(z, v, i)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFExState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.module.LIFExState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFExState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.module.LIFExState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFExState.z">
<code class="sig-name descname">z</code><a class="headerlink" href="#norse.torch.module.LIFExState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFMCCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFMCCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=tensor(0.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_mc.html#LIFMCCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFMCCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Computes a single euler-integration step of a LIF multi-compartment
neuron-model.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\begin{align*}
    \\dot{v} &amp;= 1/\\tau_{\\text{mem}} (v_{\\text{leak}} \
    - g_{\\text{coupling}} v + i) \\\\
    \\dot{i} &amp;= -1/\\tau_{\\text{syn}} i
\\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[\begin{split}z = \Theta(v - v_{\\text{th}})\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\begin{align*}
    v &amp;= (1-z) v + z v_{\\text{reset}} \\\\
    i &amp;= i + w_{\\text{input}} z_{\\text{in}} \\\\
    i &amp;= i + w_{\\text{rec}} z_{\\text{rec}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><em>LIFState</em></a>) – current state of the neuron</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic weights for incoming spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>g_coupling</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – conductances between the neuron compartments</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – neuron parameters</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFMCCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_mc.html#LIFMCCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFMCCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFMCCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFMCCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFMCRefracCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFMCRefracCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=tensor(0.))</em>, <em class="sig-param">rho_reset=tensor(5.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_mc_refrac.html#LIFMCRefracCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFMCRefracCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFMCRefracCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_mc_refrac.html#LIFMCRefracCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFMCRefracCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_refrac.html#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFMCRefracCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFMCRefracCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFRefracParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFRefracParameters</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_refrac.html#LIFRefracParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFRefracParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of a LIF neuron with absolute refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lif</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – parameters of the LIF neuron integration</p></li>
<li><p><strong>rho</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – refractory state (count towards zero)</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFRefracParameters(lif, rho_reset)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFRefracParameters.lif">
<code class="sig-name descname">lif</code><a class="headerlink" href="#norse.torch.module.LIFRefracParameters.lif" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFRefracParameters.rho_reset">
<code class="sig-name descname">rho_reset</code><a class="headerlink" href="#norse.torch.module.LIFRefracParameters.rho_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFRefracState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFRefracState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_refrac.html#LIFRefracState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFRefracState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIF neuron with absolute refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lif</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><em>LIFState</em></a>) – state of the LIF neuron integration</p></li>
<li><p><strong>rho</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – refractory state (count towards zero)</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFRefracState(lif, rho)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFRefracState.lif">
<code class="sig-name descname">lif</code><a class="headerlink" href="#norse.torch.module.LIFRefracState.lif" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFRefracState.rho">
<code class="sig-name descname">rho</code><a class="headerlink" href="#norse.torch.module.LIFRefracState.rho" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFMCRefracCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=tensor(0.))</em>, <em class="sig-param">rho_reset=tensor(5.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_mc_refrac.html#LIFMCRefracCell"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt>
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_mc_refrac.html#LIFMCRefracCell.forward"><span class="viewcode-link">[source]</span></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_refrac.html#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">training</code><em class="property"> = None</em></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFRefracParameters</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_refrac.html#LIFRefracParameters"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of a LIF neuron with absolute refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lif</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – parameters of the LIF neuron integration</p></li>
<li><p><strong>rho</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – refractory state (count towards zero)</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFRefracParameters(lif, rho_reset)</p>
<dl class="attribute">
<dt>
<code class="sig-name descname">lif</code></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">rho_reset</code></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFRefracState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_refrac.html#LIFRefracState"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIF neuron with absolute refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lif</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><em>LIFState</em></a>) – state of the LIF neuron integration</p></li>
<li><p><strong>rho</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – refractory state (count towards zero)</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFRefracState(lif, rho)</p>
<dl class="attribute">
<dt>
<code class="sig-name descname">lif</code></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">rho</code></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFRefracCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFRefracCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=tensor(0.))</em>, <em class="sig-param">rho_reset=tensor(5.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_refrac.html#LIFRefracCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFRefracCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module that computes a single euler-integration step of a LIF
neuron-model with absolute refractory period. More specifically it
implements one integration step of the following ODE.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (1-\Theta(\rho))             (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{\rho} &amp;= -1/\tau_{\text{refrac}} \Theta(\rho)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    z &amp;= \Theta(v - v_{\text{th}}) \\
    z_r &amp;= \Theta(-\rho)
\end{align*}\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}} \\
    \rho &amp;= \rho + z_r \rho_{\text{reset}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="norse.torch.functional.lif_refrac.html#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><em>LIFRefracState</em></a>) – state at the current time step</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic weights for incoming spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif_refrac.html#norse.torch.functional.lif_refrac.LIFRefracParameters" title="norse.torch.functional.lif_refrac.LIFRefracParameters"><em>LIFRefracParameters</em></a>) – parameters of the lif neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">LIFRefracCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFRefracCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_refrac.html#LIFRefracCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFRefracCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_refrac.html#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFRefracCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFRefracCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFRefracFeedForwardCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFRefracFeedForwardCell</code><span class="sig-paren">(</span><em class="sig-param">p=LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=tensor(0.))</em>, <em class="sig-param">rho_reset=tensor(5.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_refrac.html#LIFRefracFeedForwardCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFRefracFeedForwardCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module that computes a single euler-integration step of a
LIF neuron-model with absolute refractory period. More specifically
it implements one integration step of the following ODE.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (1-\Theta(\rho))             (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{\rho} &amp;= -1/\tau_{\text{refrac}} \Theta(\rho)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    z &amp;= \Theta(v - v_{\text{th}}) \\
    z_r &amp;= \Theta(-\rho)
\end{align*}\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    \rho &amp;= \rho + z_r \rho_{\text{reset}}
\end{align*}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> – Shape of the processed spike input</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lif_refrac.html#norse.torch.functional.lif_refrac.LIFRefracParameters" title="norse.torch.functional.lif_refrac.LIFRefracParameters"><em>LIFRefracParameters</em></a>) – parameters of the lif neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">LIFRefracFeedForwardCell</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LIFRefracFeedForwardCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_refrac.html#LIFRefracFeedForwardCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFRefracFeedForwardCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_refrac.html#norse.torch.functional.lif_refrac.LIFRefracFeedForwardState" title="norse.torch.functional.lif_refrac.LIFRefracFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFRefracFeedForwardCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LIFRefracFeedForwardCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LIFRefracFeedForwardState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFRefracFeedForwardState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_refrac.html#LIFRefracFeedForwardState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LIFRefracFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a feed forward LIF neuron with absolute refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lif</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><em>LIFFeedForwardState</em></a>) – state of the feed forward LIF
neuron integration</p></li>
<li><p><strong>rho</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – refractory state (count towards zero)</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFRefracFeedForwardState(lif, rho)</p>
<dl class="attribute">
<dt id="norse.torch.module.LIFRefracFeedForwardState.lif">
<code class="sig-name descname">lif</code><a class="headerlink" href="#norse.torch.module.LIFRefracFeedForwardState.lif" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LIFRefracFeedForwardState.rho">
<code class="sig-name descname">rho</code><a class="headerlink" href="#norse.torch.module.LIFRefracFeedForwardState.rho" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFRefracParameters</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_refrac.html#LIFRefracParameters"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of a LIF neuron with absolute refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lif</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – parameters of the LIF neuron integration</p></li>
<li><p><strong>rho</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – refractory state (count towards zero)</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFRefracParameters(lif, rho_reset)</p>
<dl class="attribute">
<dt>
<code class="sig-name descname">lif</code></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">rho_reset</code></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt>
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LIFRefracState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_refrac.html#LIFRefracState"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIF neuron with absolute refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lif</strong> (<a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><em>LIFState</em></a>) – state of the LIF neuron integration</p></li>
<li><p><strong>rho</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – refractory state (count towards zero)</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFRefracState(lif, rho)</p>
<dl class="attribute">
<dt>
<code class="sig-name descname">lif</code></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt>
<code class="sig-name descname">rho</code></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.Lift">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">Lift</code><span class="sig-paren">(</span><em class="sig-param">module</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lift.html#Lift"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.Lift" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="simple">
<dt>Lift applies a given torch.nn.Module over</dt><dd><p>a temporal sequence. In other words this module
applies the given torch.nn.Module N times, where N
is the outer dimension in the provided tensor.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>module</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) – Module to apply</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq_length</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">in_channels</span> <span class="o">=</span> <span class="mi">64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out_channels</span> <span class="o">=</span> <span class="mi">32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv2d</span> <span class="o">=</span> <span class="n">Lift</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">Lift</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">LIFFeedForwardLayer</span><span class="p">(),</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.Lift.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lift.html#Lift.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.Lift.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply the module over the input along the 0-th (time) dimension
and accumulate the outputs in an output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]]) – Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the input is a tuple of two tensors, the second tuple entry will be ignored.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.Lift.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.Lift.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LSNNCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LSNNCell</code><span class="sig-paren">(</span><em class="sig-param">input_features</em>, <em class="sig-param">output_features</em>, <em class="sig-param">p=LSNNParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">tau_adapt_inv=tensor(0.0014)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">beta=tensor(1.8000)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=100.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNNCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LSNNCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module that computes a single euler-integration step of a LSNN
neuron-model. More specifically it implements one integration step of
the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\begin{align*}
    \dot{v} &amp;= 1/\\tau_{\\text{mem}} (v_{\\text{leak}} - v + i) \\\\
    \dot{i} &amp;= -1/\\tau_{\\text{syn}} i \\\\
    \dot{b} &amp;= -1/\\tau_{b} b
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[\begin{split}z = \Theta(v - v_{\\text{th}} + b)\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\begin{align*}
    v &amp;= (1-z) v + z v_{\\text{reset}} \\\\
    i &amp;= i + w_{\\text{input}} z_{\\text{in}} \\\\
    i &amp;= i + w_{\\text{rec}} z_{\\text{rec}} \\\\
    b &amp;= b + \\beta z
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="norse.torch.functional.lsnn.html#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><em>LSNNState</em></a>) – current state of the lsnn unit</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic weights for input spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lsnn.html#norse.torch.functional.lsnn.LSNNParameters" title="norse.torch.functional.lsnn.LSNNParameters"><em>LSNNParameters</em></a>) – parameters of the lsnn unit</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LSNNCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNNCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LSNNCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lsnn.html#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LSNNCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LSNNFeedForwardCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LSNNFeedForwardCell</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">p=LSNNParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">tau_adapt_inv=tensor(0.0014)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">beta=tensor(1.8000)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=100.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNNFeedForwardCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LSNNFeedForwardCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Euler integration cell for LIF Neuron with threshold adaptation.
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\\text{syn}} i \\
    \dot{b} &amp;= -1/\tau_{b} b
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}} + b)\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + \text{input} \\
    b &amp;= b + \beta z
\end{align*}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="norse.torch.functional.lsnn.html#norse.torch.functional.lsnn.LSNNFeedForwardState" title="norse.torch.functional.lsnn.LSNNFeedForwardState"><em>LSNNFeedForwardState</em></a>) – current state of the lsnn unit</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.lsnn.html#norse.torch.functional.lsnn.LSNNParameters" title="norse.torch.functional.lsnn.LSNNParameters"><em>LSNNParameters</em></a>) – parameters of the lsnn unit</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LSNNFeedForwardCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNNFeedForwardCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LSNNFeedForwardCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lsnn.html#norse.torch.functional.lsnn.LSNNFeedForwardState" title="norse.torch.functional.lsnn.LSNNFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNFeedForwardCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LSNNFeedForwardCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LSNNFeedForwardState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LSNNFeedForwardState</code><a class="reference internal" href="../_modules/norse/torch/functional/lsnn.html#LSNNFeedForwardState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LSNNFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Integration state kept for a lsnn module</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>b</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – threshold adaptation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LSNNFeedForwardState(v, i, b)</p>
<dl class="attribute">
<dt id="norse.torch.module.LSNNFeedForwardState.b">
<code class="sig-name descname">b</code><a class="headerlink" href="#norse.torch.module.LSNNFeedForwardState.b" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNFeedForwardState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.module.LSNNFeedForwardState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNFeedForwardState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.module.LSNNFeedForwardState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LSNNParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LSNNParameters</code><a class="reference internal" href="../_modules/norse/torch/functional/lsnn.html#LSNNParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LSNNParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of an LSNN neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse synaptic time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{syn}\)</span>)</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse membrane time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{mem}\)</span>)</p></li>
<li><p><strong>tau_adapt_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – inverse adaptation time
constant (<span class="math notranslate nohighlight">\(1/\tau_b\)</span>)</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – leak potential</p></li>
<li><p><strong>v_th</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – threshold potential</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – reset potential</p></li>
<li><p><strong>beta</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – adaptation constant</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LSNNParameters(tau_syn_inv, tau_mem_inv, tau_adapt_inv, v_leak, v_th, v_reset, beta, method, alpha)</p>
<dl class="attribute">
<dt id="norse.torch.module.LSNNParameters.alpha">
<code class="sig-name descname">alpha</code><a class="headerlink" href="#norse.torch.module.LSNNParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 8</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNParameters.beta">
<code class="sig-name descname">beta</code><a class="headerlink" href="#norse.torch.module.LSNNParameters.beta" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNParameters.method">
<code class="sig-name descname">method</code><a class="headerlink" href="#norse.torch.module.LSNNParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNParameters.tau_adapt_inv">
<code class="sig-name descname">tau_adapt_inv</code><a class="headerlink" href="#norse.torch.module.LSNNParameters.tau_adapt_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNParameters.tau_mem_inv">
<code class="sig-name descname">tau_mem_inv</code><a class="headerlink" href="#norse.torch.module.LSNNParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNParameters.tau_syn_inv">
<code class="sig-name descname">tau_syn_inv</code><a class="headerlink" href="#norse.torch.module.LSNNParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNParameters.v_leak">
<code class="sig-name descname">v_leak</code><a class="headerlink" href="#norse.torch.module.LSNNParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNParameters.v_reset">
<code class="sig-name descname">v_reset</code><a class="headerlink" href="#norse.torch.module.LSNNParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNParameters.v_th">
<code class="sig-name descname">v_th</code><a class="headerlink" href="#norse.torch.module.LSNNParameters.v_th" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LSNNLayer">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LSNNLayer</code><span class="sig-paren">(</span><em class="sig-param">cell</em>, <em class="sig-param">*cell_args</em>, <em class="sig-param">**cell_kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNNLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LSNNLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl>
<dt>A Long short-term memory neuron module adapted from</dt><dd><p><a class="reference external" href="https://arxiv.org/abs/1803.09574">https://arxiv.org/abs/1803.09574</a></p>
</dd>
<dt>Usage:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">norse.torch.module</span> <span class="kn">import</span> <span class="n">LSNNLayer</span><span class="p">,</span> <span class="n">LSNNCell</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">layer</span> <span class="o">=</span> <span class="n">LSNNLayer</span><span class="p">(</span><span class="n">LSNNCell</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>    <span class="o">//</span> <span class="n">LSNNCell</span> <span class="n">of</span> <span class="n">shape</span> <span class="mi">2</span> <span class="o">-&gt;</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>          <span class="o">//</span> <span class="n">Arbitrary</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cell</strong> (<a class="reference external" href="https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.nn.Module</em></a>) – the underling neuron module, uninitialized</p></li>
<li><p><strong>*cell_args</strong> – variable length input arguments for the underlying cell
constructor</p></li>
<li><p><strong>**cell_kwargs</strong> – variable length key-value arguments for the underlying cell constructor</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.LSNNLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNNLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LSNNLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes one step in the LSNN layer by simulating the layer for a number of timesteps.
Since the layer is recurrent, each simulation state (LSNNState) is used as the input for the next step.</p>
<p>The function expects inputs in the shape (simulation time steps, batch size, …).</p>
<p>Parameters:
input_tensor (torch.Tensor): Input tensor with timesteps in the first dimension
state (Optional[LSNNState]): The input LSNN state. Defaults to None on the first timestep</p>
<p>Returns:
A tuple of 1) spikes from each timestep and 2) the LSNNState from the last timestep.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lsnn.html#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNLayer.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.LSNNLayer.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.LSNNState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">LSNNState</code><a class="reference internal" href="../_modules/norse/torch/functional/lsnn.html#LSNNState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.LSNNState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of an LSNN neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>b</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><em>torch.Tensor</em></a>) – threshold adaptation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LSNNState(z, v, i, b)</p>
<dl class="attribute">
<dt id="norse.torch.module.LSNNState.b">
<code class="sig-name descname">b</code><a class="headerlink" href="#norse.torch.module.LSNNState.b" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.module.LSNNState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.module.LSNNState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.LSNNState.z">
<code class="sig-name descname">z</code><a class="headerlink" href="#norse.torch.module.LSNNState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.RegularizationCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">RegularizationCell</code><span class="sig-paren">(</span><em class="sig-param">accumulator=&lt;function spike_accumulator&gt;</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/regularization.html#RegularizationCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.RegularizationCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A regularisation cell that accumulates some state (for instance number of spikes)
for each forward step, which can later be applied to a loss term.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">norse.torch.module</span> <span class="kn">import</span> <span class="n">lif</span><span class="p">,</span> <span class="n">regularization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cell</span> <span class="o">=</span> <span class="n">lif</span><span class="o">.</span><span class="n">LIFCell</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="c1"># 2 -&gt; 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span> <span class="o">=</span> <span class="n">regularization</span><span class="o">.</span><span class="n">RegularizationCell</span><span class="p">()</span> <span class="c1"># Defaults to spike counting</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Batch size of 5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">cell</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span><span class="p">,</span> <span class="n">regularization_term</span> <span class="o">=</span> <span class="n">r</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="o">...</span> <span class="o">+</span> <span class="mf">1e-3</span> <span class="o">*</span> <span class="n">regularization_term</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>accumulator</strong> (<em>Accumulator</em>) – The accumulator that aggregates some data (such as spikes) that can later
be included in an error term.</p></li>
<li><p><strong>state</strong> (<em>Optional</em><em>[</em><em>T</em><em>]</em>) – The regularization state to be aggregated to of any type T. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.RegularizationCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">s</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/regularization.html#RegularizationCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.RegularizationCell.forward" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.RegularizationCell.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.RegularizationCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.SequentialState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.</code><code class="sig-name descname">SequentialState</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/sequential.html#SequentialState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.SequentialState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.container.Sequential</span></code></p>
<p>A sequential model that works exactly like PyTorch’s <code class="docutils literal notranslate"><span class="pre">Sequential</span></code> with the
addition that it handles neuron states.</p>
<p>Example:
&gt;&gt;&gt; import torch
&gt;&gt;&gt; from norse.torch.module.lift import LIFT
&gt;&gt;&gt; from norse.torch.module.sequential import SequentialState
&gt;&gt;&gt; from norse.torch.module.lif import LIFLayer
&gt;&gt;&gt; data = torch.ones(1, 16, 8, 4)     # Single timestep
&gt;&gt;&gt; model = SequentialState(
&gt;&gt;&gt;   Lift(torch.nn.Conv2d(16, 8, 3)), # (1, 8, 6, 2)
&gt;&gt;&gt;   torch.nn.Flatten(2),             # (1, 8, 12)
&gt;&gt;&gt;   LIFLayer(12, 6),                 # (1, 8, 6)
&gt;&gt;&gt;   LIFLayer(6, 1)                   # (1, 8, 1)
&gt;&gt;&gt; )
&gt;&gt;&gt; model(data)</p>
<p>Example with recurrent layers:
&gt;&gt;&gt; import torch
&gt;&gt;&gt; from norse.torch.module.lift import Lift
&gt;&gt;&gt; from norse.torch.module.sequential import SequentialState
&gt;&gt;&gt; from norse.torch.module.lif import LIFCell, LIFLayer
&gt;&gt;&gt; from norse.torch.module.lsnn import LSNNCell, LSNNLayer
&gt;&gt;&gt; data = torch.ones(1, 16, 8, 4)     # Single timestep
&gt;&gt;&gt; model = SequentialState(
&gt;&gt;&gt;   Lift(torch.nn.Conv2d(16, 8, 3)), # (1, 8, 6, 2)
&gt;&gt;&gt;   torch.nn.Flatten(2),             # (1, 8, 12)
&gt;&gt;&gt;   LSNNLayer(LSNNCell, 12, 6),      # (1, 8, 6)
&gt;&gt;&gt;   torch.nn.RNN(6, 4, 2),           # (1, 6, 4) with 2 recurrent layers
&gt;&gt;&gt;   LIFLayer(LIFCell,4, 1)           # (1, 4, 1)
&gt;&gt;&gt; )
&gt;&gt;&gt; model(data)</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="method">
<dt id="norse.torch.module.SequentialState.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/sequential.html#SequentialState.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.SequentialState.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Feeds the input to the modules with the given state-list.
If the state is None, the initial state is set to None for each of the modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_tensor</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+3142764 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>) – The input tensor too feed into the first module</p></li>
<li><p><strong>state</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a>]) – Either a list of states for each module or None. If None, the modules
will initialise their own default state</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple of (output tensor, state list)</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.module.SequentialState.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#norse.torch.module.SequentialState.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.test.html">norse.torch.module.test package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.module.test.html#submodules">Submodules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_coba.html">norse.torch.module.test.test_coba module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_encode.html">norse.torch.module.test.test_encode module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_leaky_integrator.html">norse.torch.module.test.test_leaky_integrator module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_li.html">norse.torch.module.test.test_li module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif.html">norse.torch.module.test.test_lif module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif_adex.html">norse.torch.module.test.test_lif_adex module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif_correlation.html">norse.torch.module.test.test_lif_correlation module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif_ex.html">norse.torch.module.test.test_lif_ex module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif_mc.html">norse.torch.module.test.test_lif_mc module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif_mc_refrac.html">norse.torch.module.test.test_lif_mc_refrac module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif_refrac.html">norse.torch.module.test.test_lif_refrac module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lift.html">norse.torch.module.test.test_lift module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lsnn.html">norse.torch.module.test.test_lsnn module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_regularization.html">norse.torch.module.test.test_regularization module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_sequential.html">norse.torch.module.test.test_sequential module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_training.html">norse.torch.module.test.test_training module</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.coba_lif.html">norse.torch.module.coba_lif module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.encode.html">norse.torch.module.encode module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.leaky_integrator.html">norse.torch.module.leaky_integrator module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif.html">norse.torch.module.lif module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif_adex.html">norse.torch.module.lif_adex module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif_correlation.html">norse.torch.module.lif_correlation module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif_ex.html">norse.torch.module.lif_ex module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif_mc.html">norse.torch.module.lif_mc module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif_mc_refrac.html">norse.torch.module.lif_mc_refrac module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif_refrac.html">norse.torch.module.lif_refrac module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lift.html">norse.torch.module.lift module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lsnn.html">norse.torch.module.lsnn module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.regularization.html">norse.torch.module.regularization module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.sequential.html">norse.torch.module.sequential module</a></li>
</ul>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/logo.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">A library to do deep learning with spiking neural networks.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=norse&repo=norse&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Usage Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../about.html">1. About Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installing.html">2. Installing Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hardware.html">3. Hardware acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spiking.html">4. Introduction to spiking neural networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../learning.html">5. Learning with spikes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../working.html">6. Working with Norse</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">1. Beginner tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experiments.html">2. Running Experiments</a></li>
</ul>
<p class="caption"><span class="caption-text">API Docs</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="norse.benchmark.html">norse.benchmark package</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.task.html">norse.task package</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="norse.torch.html">norse.torch package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="norse.torch.functional.html">norse.torch.functional package</a></li>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.models.html">norse.torch.models package</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">norse.torch.module package</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="norse.torch.html">norse.torch package</a><ul>
      <li>Previous: <a href="norse.torch.models.vgg.html" title="previous chapter">norse.torch.models.vgg module</a></li>
      <li>Next: <a href="norse.torch.module.test.html" title="next chapter">norse.torch.module.test package</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Norse.ai.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.4.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/auto_api/norse.torch.module.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>