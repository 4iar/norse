
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>norse.torch.module package &#8212; norse 0.0.6 documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/alabaster.css" />
    <link rel="stylesheet" type="text/css" href="../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="norse.torch.module.test package" href="norse.torch.module.test.html" />
    <link rel="prev" title="norse.torch.models.vgg module" href="norse.torch.models.vgg.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="module-norse.torch.module">
<span id="norse-torch-module-package"></span><h1>norse.torch.module package<a class="headerlink" href="#module-norse.torch.module" title="Permalink to this headline">¶</a></h1>
<p>Modules for spiking neural network, adhering to the <code class="docutils literal notranslate"><span class="pre">torch.nn.Module</span></code> interface.</p>
<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">CobaLIFCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">CobaLIFParameters(tau_syn_exc_inv=tensor(0.2000),</span> <span class="pre">tau_syn_inh_inv=tensor(0.2000),</span> <span class="pre">c_m_inv=tensor(5.),</span> <span class="pre">g_l=tensor(0.2500),</span> <span class="pre">e_rev_I=tensor(-</span> <span class="pre">100),</span> <span class="pre">e_rev_E=tensor(60),</span> <span class="pre">v_rest=tensor(-</span> <span class="pre">20),</span> <span class="pre">v_reset=tensor(-</span> <span class="pre">70),</span> <span class="pre">v_thresh=tensor(-</span> <span class="pre">10),</span> <span class="pre">method='super',</span> <span class="pre">alpha=100.0)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/coba_lif.html#CobaLIFCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.CobaLIFCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module that computes a single euler-integration step of a conductance based
LIF neuron-model. More specifically it implements one integration step of
the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/c_{\text{mem}} (g_l (v_{\text{leak}} - v)               + g_e (E_{\text{rev_e}} - v) + g_i (E_{\text{rev_i}} - v)) \\
    \dot{g_e} &amp;= -1/\tau_{\text{syn}} g_e \\
    \dot{g_i} &amp;= -1/\tau_{\text{syn}} g_i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    g_e &amp;= g_e + \text{relu}(w_{\text{input}}) z_{\text{in}} \\
    g_e &amp;= g_e + \text{relu}(w_{\text{rec}}) z_{\text{rec}} \\
    g_i &amp;= g_i + \text{relu}(-w_{\text{input}}) z_{\text{in}} \\
    g_i &amp;= g_i + \text{relu}(-w_{\text{rec}}) z_{\text{rec}} \\
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the recurrent
and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFParameters" title="norse.torch.module.LIFParameters"><em>LIFParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">CobaLIFCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFCell.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/coba_lif.html#CobaLIFCell.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.CobaLIFCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.coba_lif.html#norse.torch.functional.coba_lif.CobaLIFState" title="norse.torch.functional.coba_lif.CobaLIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">CobaLIFState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFParameters">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">CobaLIFParameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tau_syn_exc_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.2000)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_syn_inh_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.2000)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">c_m_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(5.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">g_l</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.2500)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">e_rev_I</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(-</span> <span class="pre">100)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">e_rev_E</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(60)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_rest</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(-</span> <span class="pre">20)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_reset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(-</span> <span class="pre">70)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_thresh</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(-</span> <span class="pre">10)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><span class="pre">str</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'super'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><span class="pre">float</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">100.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/coba_lif.html#CobaLIFParameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.CobaLIFParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of conductance based LIF neuron.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau_syn_exc_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inverse excitatory synaptic input
time constant</p></li>
<li><p><strong>tau_syn_inh_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inverse inhibitory synaptic input
time constant</p></li>
<li><p><strong>c_m_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inverse membrane capacitance</p></li>
<li><p><strong>g_l</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – leak conductance</p></li>
<li><p><strong>e_rev_I</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inhibitory reversal potential</p></li>
<li><p><strong>e_rev_E</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – excitatory reversal potential</p></li>
<li><p><strong>v_rest</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – rest membrane potential</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – reset membrane potential</p></li>
<li><p><strong>v_thresh</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – threshold membrane potential</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – method to determine the spike threshold
(relevant for surrogate gradients)</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – hyper parameter to use in surrogate gradient computation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of CobaLIFParameters(tau_syn_exc_inv, tau_syn_inh_inv, c_m_inv, g_l, e_rev_I, e_rev_E, v_rest, v_reset, v_thresh, method, alpha)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFParameters.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><span class="pre">float</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 10</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFParameters.c_m_inv">
<span class="sig-name descname"><span class="pre">c_m_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.c_m_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFParameters.e_rev_E">
<span class="sig-name descname"><span class="pre">e_rev_E</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.e_rev_E" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFParameters.e_rev_I">
<span class="sig-name descname"><span class="pre">e_rev_I</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.e_rev_I" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFParameters.g_l">
<span class="sig-name descname"><span class="pre">g_l</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.g_l" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFParameters.method">
<span class="sig-name descname"><span class="pre">method</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><span class="pre">str</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 9</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFParameters.tau_syn_exc_inv">
<span class="sig-name descname"><span class="pre">tau_syn_exc_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.tau_syn_exc_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFParameters.tau_syn_inh_inv">
<span class="sig-name descname"><span class="pre">tau_syn_inh_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.tau_syn_inh_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFParameters.v_reset">
<span class="sig-name descname"><span class="pre">v_reset</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFParameters.v_rest">
<span class="sig-name descname"><span class="pre">v_rest</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.v_rest" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFParameters.v_thresh">
<span class="sig-name descname"><span class="pre">v_thresh</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFParameters.v_thresh" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 8</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">CobaLIFState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">g_e</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">g_i</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/coba_lif.html#CobaLIFState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.CobaLIFState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a conductance based LIF neuron.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>g_e</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – excitatory input conductance</p></li>
<li><p><strong>g_i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inhibitory input conductance</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of CobaLIFState(z, v, g_e, g_i)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFState.g_e">
<span class="sig-name descname"><span class="pre">g_e</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFState.g_e" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFState.g_i">
<span class="sig-name descname"><span class="pre">g_i</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFState.g_i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFState.v">
<span class="sig-name descname"><span class="pre">v</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.CobaLIFState.z">
<span class="sig-name descname"><span class="pre">z</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.CobaLIFState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.ConstantCurrentLIFEncoder">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">ConstantCurrentLIFEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.))</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#ConstantCurrentLIFEncoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.ConstantCurrentLIFEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encodes input currents as fixed (constant) voltage currents, and simulates the spikes that
occur during a number of timesteps/iterations (seq_length).</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq_length</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># Simulate two iterations</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">constant_current_lif_encode</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">)</span>
<span class="go">(tensor([[0.2000, 0.4000, 0.8000, 0.0000],   # State in terms of membrane voltage</span>
<span class="go">        [0.3800, 0.7600, 0.0000, 0.0000]]),</span>
<span class="go">tensor([[0., 0., 0., 1.],                   # Spikes for each iteration</span>
<span class="go">        [0., 0., 1., 1.]]))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>seq_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of iterations to simulate</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFParameters" title="norse.torch.module.LIFParameters"><em>LIFParameters</em></a>) – Initial neuron parameters.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time delta between simulation steps</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.ConstantCurrentLIFEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_currents</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#ConstantCurrentLIFEncoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.ConstantCurrentLIFEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.ConstantCurrentLIFEncoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.ConstantCurrentLIFEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.Izhikevich">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">Izhikevich</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">spiking_method</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/izhikevich.html#Izhikevich"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.Izhikevich" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNN" title="norse.torch.module.snn.SNN"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNN</span></code></a></p>
<p>A neuron layer that wraps a <a class="reference internal" href="#norse.torch.module.IzhikevichCell" title="norse.torch.module.IzhikevichCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">IzhikevichCell</span></code></a> in time such
that the layer keeps track of temporal sequences of spikes.
After application, the layer returns a tuple containing</p>
<blockquote>
<div><p>(spikes from all timesteps, state from the last timestep).</p>
</div></blockquote>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 10 timesteps, 5 batches, 2 neurons</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">Izhikevich</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># Returns tuple of (Tensor(10, 5, 2), IzhikevichState)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.IzhikevichParameters" title="norse.torch.functional.IzhikevichParameters"><em>IzhikevichParameters</em></a>) – The neuron parameters as a torch Module, which allows the module
to configure neuron parameters as optimizable.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use in integration. Defaults to 0.001.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.Izhikevich.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/izhikevich.html#Izhikevich.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.Izhikevich.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.izhikevich.html#norse.torch.functional.izhikevich.IzhikevichState" title="norse.torch.functional.izhikevich.IzhikevichState"><code class="xref py py-class docutils literal notranslate"><span class="pre">IzhikevichState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.Izhikevich.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.Izhikevich.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.IzhikevichCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">IzhikevichCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">spiking_method</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/izhikevich.html#IzhikevichCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.IzhikevichCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNCell" title="norse.torch.module.snn.SNNCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNCell</span></code></a></p>
<p>Module that computes a single Izhikevich neuron-model <em>without</em> recurrence and <em>without</em> time.
More specifically it implements one integration step of the following ODE:</p>
<div class="math notranslate nohighlight">
\[\begin{align*}
    \dot{v} &amp;= 0.04v² + 5v + 140 - u + I
    \dot{u} &amp;= a(bv - u)
\end{align*}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\text{if} v = 30 \text{mV, then} v = c \text{and} u = u + d\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>spiking_method</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.IzhikevichSpikingBehavior" title="norse.torch.functional.IzhikevichSpikingBehavior"><em>IzhikevichSpikingBehavior</em></a>) – parameters and initial state of the neuron</p>
</dd>
</dl>
<dl>
<dt>Example with tonic spiking:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">norse.torch</span> <span class="kn">import</span> <span class="n">IzhikevichCell</span><span class="p">,</span> <span class="n">tonic_spiking</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cell</span> <span class="o">=</span> <span class="n">IzhikevichCell</span><span class="p">(</span><span class="n">tonic_spiking</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">cell</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.IzhikevichCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/izhikevich.html#IzhikevichCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.IzhikevichCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.izhikevich.html#norse.torch.functional.izhikevich.IzhikevichState" title="norse.torch.functional.izhikevich.IzhikevichState"><code class="xref py py-class docutils literal notranslate"><span class="pre">IzhikevichState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.IzhikevichCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.IzhikevichCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.IzhikevichRecurrent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">IzhikevichRecurrent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spiking_method</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/izhikevich.html#IzhikevichRecurrent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.IzhikevichRecurrent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNRecurrent" title="norse.torch.module.snn.SNNRecurrent"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNRecurrent</span></code></a></p>
<p>A neuron layer that wraps a <a class="reference internal" href="#norse.torch.module.IzhikevichRecurrentCell" title="norse.torch.module.IzhikevichRecurrentCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">IzhikevichRecurrentCell</span></code></a> in time such
that the layer keeps track of temporal sequences of spikes.
After application, the layer returns a tuple containing</p>
<blockquote>
<div><p>(spikes from all timesteps, state from the last timestep).</p>
</div></blockquote>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 10 timesteps, 5 batches, 2 neurons</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">Izhikevich</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># Returns tuple of (Tensor(10, 5, 2), IzhikevichState)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.IzhikevichParameters" title="norse.torch.functional.IzhikevichParameters"><em>IzhikevichParameters</em></a>) – The neuron parameters as a torch Module, which allows the module
to configure neuron parameters as optimizable.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use in integration. Defaults to 0.001.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.IzhikevichRecurrent.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/izhikevich.html#IzhikevichRecurrent.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.IzhikevichRecurrent.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.izhikevich.html#norse.torch.functional.izhikevich.IzhikevichRecurrentState" title="norse.torch.functional.izhikevich.IzhikevichRecurrentState"><code class="xref py py-class docutils literal notranslate"><span class="pre">IzhikevichRecurrentState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.IzhikevichRecurrent.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.IzhikevichRecurrent.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.IzhikevichRecurrentCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">IzhikevichRecurrentCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">spiking_method</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/izhikevich.html#IzhikevichRecurrentCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.IzhikevichRecurrentCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNRecurrentCell" title="norse.torch.module.snn.SNNRecurrentCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNRecurrentCell</span></code></a></p>
<p>Module that computes a single euler-integration step of an Izhikevich neuron-model <em>with</em> recurrence but <em>without</em> time.
More specifically it implements one integration step of the following ODE :</p>
<div class="math notranslate nohighlight">
\[\begin{align*}
    \dot{v} &amp;= 0.04v² + 5v + 140 - u + I
    \dot{u} &amp;= a(bv - u)
\end{align*}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\text{if} v = 30 \text{mV, then} v = c \text{and} u = u + d\]</div>
<dl>
<dt>Example with tonic spiking:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">norse.torch</span> <span class="kn">import</span> <span class="n">IzhikevichRecurrentCell</span><span class="p">,</span> <span class="n">tonic_spiking</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 5 batches, 2 neurons</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">IzhikevichRecurrentCell</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># Returns tuple of (Tensor(5, 4), IzhikevichState)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input. Also known as the number of input features. Defaults to None</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state. Also known as the number of input features. Defaults to None</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.IzhikevichParameters" title="norse.torch.functional.IzhikevichParameters"><em>IzhikevichParameters</em></a>) – Parameters of the Izhikevich neuron model.</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – Weights used for input tensors. Defaults to a random
matrix normalized to the number of hidden neurons.</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – Weights used for input tensors. Defaults to a random
matrix normalized to the number of hidden neurons.</p></li>
<li><p><strong>autapses</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Allow self-connections in the recurrence? Defaults to False. Will also
remove autapses in custom recurrent weights, if set above.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use. Defaults to 0.001.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.IzhikevichRecurrentCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/izhikevich.html#IzhikevichRecurrentCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.IzhikevichRecurrentCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.izhikevich.html#norse.torch.functional.izhikevich.IzhikevichRecurrentState" title="norse.torch.functional.izhikevich.IzhikevichRecurrentState"><code class="xref py py-class docutils literal notranslate"><span class="pre">IzhikevichRecurrentState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.IzhikevichRecurrentCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.IzhikevichRecurrentCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LICell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LICell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.))</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/leaky_integrator.html#LICell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LICell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNCell" title="norse.torch.module.snn.SNNCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNCell</span></code></a></p>
<p>Cell for a leaky-integrator <em>without</em> recurrence.
More specifically it implements a discretized version of the ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[i = i + w i_{\text{in}}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIParameters" title="norse.torch.module.LIParameters"><em>LIParameters</em></a>) – parameters of the leaky integrator</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – integration timestep to use</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LICell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/leaky_integrator.html#LICell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LICell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.leaky_integrator.html#norse.torch.functional.leaky_integrator.LIState" title="norse.torch.functional.leaky_integrator.LIState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LICell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LICell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIF">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.))</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIF" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNN" title="norse.torch.module.snn.SNN"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNN</span></code></a></p>
<p>A neuron layer that wraps a <a class="reference internal" href="#norse.torch.module.LIFCell" title="norse.torch.module.LIFCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFCell</span></code></a> in time such
that the layer keeps track of temporal sequences of spikes.
After application, the layer returns a tuple containing</p>
<blockquote>
<div><p>(spikes from all timesteps, state from the last timestep).</p>
</div></blockquote>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 10 timesteps, 5 batches, 2 neurons</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">LIF</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># Returns tuple of (Tensor(10, 5, 2), LIFState)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFParameters" title="norse.torch.module.LIFParameters"><em>LIFParameters</em></a>) – The neuron parameters as a torch Module, which allows the module
to configure neuron parameters as optimizable.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Whether to apply sparse activation functions (True) or not (False). Defaults to False.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use in integration. Defaults to 0.001.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIF.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIF.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIF.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFFeedForwardState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIF.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIF.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdEx">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFAdEx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFAdExParameters(adaptation_current=tensor(4),</span> <span class="pre">adaptation_spike=tensor(0.0200),</span> <span class="pre">delta_T=tensor(0.5000),</span> <span class="pre">tau_ada_inv=tensor(2.),</span> <span class="pre">tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=100.0)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdEx"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFAdEx" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNN" title="norse.torch.module.snn.SNN"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNN</span></code></a></p>
<p>A neuron layer that wraps a recurrent LIFAdExCell in time such
that the layer keeps track of temporal sequences of spikes.
After application, the layer returns a tuple containing</p>
<blockquote>
<div><p>(spikes from all timesteps, state from the last timestep).</p>
</div></blockquote>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 10 timesteps, 5 batches, 2 neurons</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">LIFAdExLayer</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># Returns tuple of (Tensor(10, 5, 4), LIFExState)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFAdExParameters" title="norse.torch.module.LIFAdExParameters"><em>LIFAdExParameters</em></a>) – The neuron parameters as a torch Module, which allows the module
to configure neuron parameters as optimizable.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use in integration. Defaults to 0.001.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdEx.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdEx.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFAdEx.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif_adex.html#norse.torch.functional.lif_adex.LIFAdExFeedForwardState" title="norse.torch.functional.lif_adex.LIFAdExFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFAdExFeedForwardState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdEx.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdEx.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFAdExCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFAdExParameters(adaptation_current=tensor(4),</span> <span class="pre">adaptation_spike=tensor(0.0200),</span> <span class="pre">delta_T=tensor(0.5000),</span> <span class="pre">tau_ada_inv=tensor(2.),</span> <span class="pre">tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=100.0)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFAdExCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNCell" title="norse.torch.module.snn.SNNCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNCell</span></code></a></p>
<p>Computes a single euler-integration step of a feed-forward exponential
LIF neuron-model <em>without</em> recurrence, adapted from
<a class="reference external" href="http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model">http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model</a>.
It takes as input the input current as generated by an arbitrary torch
module or function. More specifically it implements one integration step
of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} \left(v_{\text{leak}} - v + i + \Delta_T exp\left({{v - v_{\text{th}}} \over {\Delta_T}}\right)\right) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{a} &amp;= 1/\tau_{\text{ada}} \left( a_{current} (V - v_{\text{leak}}) - a \right)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[i = i + i_{\text{in}}\]</div>
<p>where <span class="math notranslate nohighlight">\(i_{\text{in}}\)</span> is meant to be the result of applying
an arbitrary pytorch module (such as a convolution) to input spikes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFAdExParameters" title="norse.torch.module.LIFAdExParameters"><em>LIFAdExParameters</em></a>) – Parameters of the LIFEx neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif_ex</span> <span class="o">=</span> <span class="n">LIFAdExCell</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif_ex</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFAdExCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif_adex.html#norse.torch.functional.lif_adex.LIFAdExFeedForwardState" title="norse.torch.functional.lif_adex.LIFAdExFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFAdExFeedForwardState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExFeedForwardState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFAdExFeedForwardState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">v</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#LIFAdExFeedForwardState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFAdExFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a feed forward LIFAdEx neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>a</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – membrane potential adaptation factor</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFAdExFeedForwardState(v, i, a)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExFeedForwardState.a">
<span class="sig-name descname"><span class="pre">a</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExFeedForwardState.a" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExFeedForwardState.i">
<span class="sig-name descname"><span class="pre">i</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExFeedForwardState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExFeedForwardState.v">
<span class="sig-name descname"><span class="pre">v</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExFeedForwardState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExParameters">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFAdExParameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">adaptation_current</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(4)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">adaptation_spike</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.0200)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">delta_T</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.5000)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_ada_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(2.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_syn_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(200.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_mem_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(100.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_leak</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_th</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(1.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_reset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><span class="pre">str</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'super'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><span class="pre">float</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">100.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#LIFAdExParameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFAdExParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parametrization of an Adaptive Exponential Leaky Integrate and Fire neuron</p>
<p>Default values from <a class="reference external" href="https://github.com/NeuralEnsemble/PyNN/blob/d8056fa956998b031a1c3689a528473ed2bc0265/pyNN/standardmodels/cells.py#L416">https://github.com/NeuralEnsemble/PyNN/blob/d8056fa956998b031a1c3689a528473ed2bc0265/pyNN/standardmodels/cells.py#L416</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>adaptation_current</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – adaptation coupling parameter in nS</p></li>
<li><p><strong>adaptation_spike</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – spike triggered adaptation parameter in nA</p></li>
<li><p><strong>delta_T</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – sharpness or speed of the exponential growth in mV</p></li>
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inverse adaptation time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{ada}\)</span>) in 1/ms</p></li>
<li><p><strong>tau_syn_inv</strong> – inverse synaptic time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{syn}\)</span>) in 1/ms</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inverse membrane time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{mem}\)</span>) in 1/ms</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – leak potential in mV</p></li>
<li><p><strong>v_th</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – threshold potential in mV</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – reset potential in mV</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – method to determine the spike threshold
(relevant for surrogate gradients)</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – hyper parameter to use in surrogate gradient computation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFAdExParameters(adaptation_current, adaptation_spike, delta_T, tau_ada_inv, tau_syn_inv, tau_mem_inv, v_leak, v_th, v_reset, method, alpha)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExParameters.adaptation_current">
<span class="sig-name descname"><span class="pre">adaptation_current</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.adaptation_current" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExParameters.adaptation_spike">
<span class="sig-name descname"><span class="pre">adaptation_spike</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.adaptation_spike" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExParameters.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><span class="pre">float</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 10</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExParameters.delta_T">
<span class="sig-name descname"><span class="pre">delta_T</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.delta_T" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExParameters.method">
<span class="sig-name descname"><span class="pre">method</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><span class="pre">str</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 9</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExParameters.tau_ada_inv">
<span class="sig-name descname"><span class="pre">tau_ada_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.tau_ada_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExParameters.tau_mem_inv">
<span class="sig-name descname"><span class="pre">tau_mem_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExParameters.tau_syn_inv">
<span class="sig-name descname"><span class="pre">tau_syn_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExParameters.v_leak">
<span class="sig-name descname"><span class="pre">v_leak</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExParameters.v_reset">
<span class="sig-name descname"><span class="pre">v_reset</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 8</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExParameters.v_th">
<span class="sig-name descname"><span class="pre">v_th</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExParameters.v_th" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExRecurrent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFAdExRecurrent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFAdExParameters(adaptation_current=tensor(4),</span> <span class="pre">adaptation_spike=tensor(0.0200),</span> <span class="pre">delta_T=tensor(0.5000),</span> <span class="pre">tau_ada_inv=tensor(2.),</span> <span class="pre">tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=100.0)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExRecurrent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFAdExRecurrent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNRecurrent" title="norse.torch.module.snn.SNNRecurrent"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNRecurrent</span></code></a></p>
<p>A neuron layer that wraps a recurrent LIFAdExRecurrentCell in time (<em>with</em>
recurrence) such that the layer keeps track of temporal sequences of spikes.
After application, the layer returns a tuple containing</p>
<blockquote>
<div><p>(spikes from all timesteps, state from the last timestep).</p>
</div></blockquote>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 10 timesteps, 5 batches, 2 neurons</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">LIFAdExRecurrent</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># Returns tuple of (Tensor(10, 5, 4), LIFAdExState)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of input neurons</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of hidden neurons</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFAdExParameters" title="norse.torch.module.LIFAdExParameters"><em>LIFAdExParameters</em></a>) – The neuron parameters as a torch Module, which allows the module
to configure neuron parameters as optimizable.</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – Weights used for input tensors. Defaults to a random
matrix normalized to the number of hidden neurons.</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – Weights used for input tensors. Defaults to a random
matrix normalized to the number of hidden neurons.</p></li>
<li><p><strong>autapses</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Allow self-connections in the recurrence? Defaults to False. Will also
remove autapses in custom recurrent weights, if set above.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use in integration. Defaults to 0.001.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExRecurrent.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExRecurrent.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFAdExRecurrent.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif_adex.html#norse.torch.functional.lif_adex.LIFAdExState" title="norse.torch.functional.lif_adex.LIFAdExState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFAdExState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExRecurrent.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExRecurrent.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExRecurrentCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFAdExRecurrentCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFAdExParameters(adaptation_current=tensor(4),</span> <span class="pre">adaptation_spike=tensor(0.0200),</span> <span class="pre">delta_T=tensor(0.5000),</span> <span class="pre">tau_ada_inv=tensor(2.),</span> <span class="pre">tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=100.0)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExRecurrentCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFAdExRecurrentCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNRecurrentCell" title="norse.torch.module.snn.SNNRecurrentCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNRecurrentCell</span></code></a></p>
<p>Computes a single of euler-integration step of a recurrent adaptive exponential
LIF neuron-model <em>with</em> recurrence, adapted from
<a class="reference external" href="http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model">http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model</a>.
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} \left(v_{\text{leak}} - v + i + \Delta_T exp\left({{v - v_{\text{th}}} \over {\Delta_T}}\right)\right) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{a} &amp;= 1/\tau_{\text{ada}} \left( a_{current} (V - v_{\text{leak}}) - a \right)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">LIFAdExRecurrentCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input. Also known as the number of input features.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state. Also known as the number of input features.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFAdExParameters" title="norse.torch.module.LIFAdExParameters"><em>LIFAdExParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – Weights used for input tensors. Defaults to a random
matrix normalized to the number of hidden neurons.</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – Weights used for input tensors. Defaults to a random
matrix normalized to the number of hidden neurons.</p></li>
<li><p><strong>autapses</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Allow self-connections in the recurrence? Defaults to False. Will also
remove autapses in custom recurrent weights, if set above.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExRecurrentCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_adex.html#LIFAdExRecurrentCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFAdExRecurrentCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif_adex.html#norse.torch.functional.lif_adex.LIFAdExState" title="norse.torch.functional.lif_adex.LIFAdExState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFAdExState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExRecurrentCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExRecurrentCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFAdExState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">a</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#LIFAdExState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFAdExState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIFAdEx neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>a</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – membrane potential adaptation factor</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFAdExState(z, v, i, a)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExState.a">
<span class="sig-name descname"><span class="pre">a</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExState.a" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExState.i">
<span class="sig-name descname"><span class="pre">i</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExState.v">
<span class="sig-name descname"><span class="pre">v</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFAdExState.z">
<span class="sig-name descname"><span class="pre">z</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFAdExState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.))</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNCell" title="norse.torch.module.snn.SNNCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNCell</span></code></a></p>
<p>Module that computes a single euler-integration step of a
leaky integrate-and-fire (LIF) neuron-model <em>without</em> recurrence and <em>without</em> time.</p>
<p>More specifically it implements one integration step
of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}}
\end{align*}\]</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 5 batches, 2 neurons</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">LIFCell</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># Returns tuple of (Tensor(5, 4), LIFState)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFParameters" title="norse.torch.module.LIFParameters"><em>LIFParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Whether to apply sparse activation functions (True) or not (False). Defaults to False.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use. Defaults to 0.001.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFFeedForwardState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFCorrelation">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFCorrelation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFCorrelationParameters(lif_parameters=LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.)),</span> <span class="pre">input_correlation_parameters=CorrelationSensorParameters(eta_p=tensor(1.),</span> <span class="pre">eta_m=tensor(1.),</span> <span class="pre">tau_ac_inv=tensor(10.),</span> <span class="pre">tau_c_inv=tensor(10.)),</span> <span class="pre">recurrent_correlation_parameters=CorrelationSensorParameters(eta_p=tensor(1.),</span> <span class="pre">eta_m=tensor(1.),</span> <span class="pre">tau_ac_inv=tensor(10.),</span> <span class="pre">tau_c_inv=tensor(10.)))</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_correlation.html#LIFCorrelation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFCorrelation" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFCorrelation.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurrent_weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_correlation.html#LIFCorrelation.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFCorrelation.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_correlation.html#norse.torch.functional.lif_correlation.LIFCorrelationState" title="norse.torch.functional.lif_correlation.LIFCorrelationState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFCorrelationState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFCorrelation.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFCorrelation.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFCorrelationParameters">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFCorrelationParameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lif_parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_correlation_parameters</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurrent_correlation_parameters</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_correlation.html#LIFCorrelationParameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFCorrelationParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Create new instance of LIFCorrelationParameters(lif_parameters, input_correlation_parameters, recurrent_correlation_parameters)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFCorrelationParameters.input_correlation_parameters">
<span class="sig-name descname"><span class="pre">input_correlation_parameters</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="norse.torch.functional.correlation_sensor.html#norse.torch.functional.correlation_sensor.CorrelationSensorParameters" title="norse.torch.functional.correlation_sensor.CorrelationSensorParameters"><span class="pre">norse.torch.functional.correlation_sensor.CorrelationSensorParameters</span></a></em><a class="headerlink" href="#norse.torch.module.LIFCorrelationParameters.input_correlation_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFCorrelationParameters.lif_parameters">
<span class="sig-name descname"><span class="pre">lif_parameters</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><span class="pre">norse.torch.functional.lif.LIFParameters</span></a></em><a class="headerlink" href="#norse.torch.module.LIFCorrelationParameters.lif_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFCorrelationParameters.recurrent_correlation_parameters">
<span class="sig-name descname"><span class="pre">recurrent_correlation_parameters</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="norse.torch.functional.correlation_sensor.html#norse.torch.functional.correlation_sensor.CorrelationSensorParameters" title="norse.torch.functional.correlation_sensor.CorrelationSensorParameters"><span class="pre">norse.torch.functional.correlation_sensor.CorrelationSensorParameters</span></a></em><a class="headerlink" href="#norse.torch.module.LIFCorrelationParameters.recurrent_correlation_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFCorrelationState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFCorrelationState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lif_state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_correlation_state</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">recurrent_correlation_state</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_correlation.html#LIFCorrelationState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFCorrelationState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Create new instance of LIFCorrelationState(lif_state, input_correlation_state, recurrent_correlation_state)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFCorrelationState.input_correlation_state">
<span class="sig-name descname"><span class="pre">input_correlation_state</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="norse.torch.functional.correlation_sensor.html#norse.torch.functional.correlation_sensor.CorrelationSensorState" title="norse.torch.functional.correlation_sensor.CorrelationSensorState"><span class="pre">norse.torch.functional.correlation_sensor.CorrelationSensorState</span></a></em><a class="headerlink" href="#norse.torch.module.LIFCorrelationState.input_correlation_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFCorrelationState.lif_state">
<span class="sig-name descname"><span class="pre">lif_state</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><span class="pre">norse.torch.functional.lif.LIFState</span></a></em><a class="headerlink" href="#norse.torch.module.LIFCorrelationState.lif_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFCorrelationState.recurrent_correlation_state">
<span class="sig-name descname"><span class="pre">recurrent_correlation_state</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="norse.torch.functional.correlation_sensor.html#norse.torch.functional.correlation_sensor.CorrelationSensorState" title="norse.torch.functional.correlation_sensor.CorrelationSensorState"><span class="pre">norse.torch.functional.correlation_sensor.CorrelationSensorState</span></a></em><a class="headerlink" href="#norse.torch.module.LIFCorrelationState.recurrent_correlation_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFEx">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFEx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFExParameters(delta_T=tensor(0.5000),</span> <span class="pre">tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=100.0)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFEx"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFEx" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNN" title="norse.torch.module.snn.SNN"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNN</span></code></a></p>
<p>A neuron layer that wraps a <a class="reference internal" href="#norse.torch.module.LIFExCell" title="norse.torch.module.LIFExCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFExCell</span></code></a> in time such
that the layer keeps track of temporal sequences of spikes.
After application, the layer returns a tuple containing</p>
<blockquote>
<div><p>(spikes from all timesteps, state from the last timestep).</p>
</div></blockquote>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 10 timesteps, 5 batches, 2 neurons</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">LIFEx</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># Returns tuple of (Tensor(10, 5, 2), LIFExState)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFExParameters" title="norse.torch.module.LIFExParameters"><em>LIFExParameters</em></a>) – The neuron parameters as a torch Module, which allows the module
to configure neuron parameters as optimizable. Defaults to None.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use in integration. Defaults to 0.001.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFEx.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFEx.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFEx.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif_ex.html#norse.torch.functional.lif_ex.LIFExFeedForwardState" title="norse.torch.functional.lif_ex.LIFExFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFExFeedForwardState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFEx.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFEx.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFExCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFExCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFExParameters(delta_T=tensor(0.5000),</span> <span class="pre">tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=100.0)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFExCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNCell" title="norse.torch.module.snn.SNNCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNCell</span></code></a></p>
<p>Computes a single euler-integration step of a recurrent
exponential LIF neuron-model (<em>without</em> recurrence) adapted from
<a class="reference external" href="https://neuronaldynamics.epfl.ch/online/Ch5.S2.html">https://neuronaldynamics.epfl.ch/online/Ch5.S2.html</a>.
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} \left(v_{\text{leak}} - v + i + \Delta_T exp\left({{v - v_{\text{th}}} \over {\Delta_T}}\right)\right) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\\text{reset}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFExParameters" title="norse.torch.module.LIFExParameters"><em>LIFExParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
<li><p><strong>autapses</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Allow self-connections in the recurrence? Defaults to False.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif_ex</span> <span class="o">=</span> <span class="n">LIFExCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif_ex</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFExCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFExCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif_ex.html#norse.torch.functional.lif_ex.LIFExFeedForwardState" title="norse.torch.functional.lif_ex.LIFExFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFExFeedForwardState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFExFeedForwardState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFExFeedForwardState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">v</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_ex.html#LIFExFeedForwardState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFExFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a feed forward LIFEx neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFExFeedForwardState(v, i)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExFeedForwardState.i">
<span class="sig-name descname"><span class="pre">i</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExFeedForwardState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExFeedForwardState.v">
<span class="sig-name descname"><span class="pre">v</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExFeedForwardState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFExParameters">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFExParameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">delta_T</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.5000)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_syn_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(200.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_mem_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(100.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_leak</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_th</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(1.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_reset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><span class="pre">str</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'super'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><span class="pre">float</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">100.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_ex.html#LIFExParameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFExParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parametrization of an Exponential Leaky Integrate and Fire neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>delta_T</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – sharpness or speed of the exponential growth in mV</p></li>
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inverse synaptic time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{syn}\)</span>) in 1/ms</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inverse membrane time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{mem}\)</span>) in 1/ms</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – leak potential in mV</p></li>
<li><p><strong>v_th</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – threshold potential in mV</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – reset potential in mV</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – method to determine the spike threshold
(relevant for surrogate gradients)</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – hyper parameter to use in surrogate gradient computation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFExParameters(delta_T, tau_syn_inv, tau_mem_inv, v_leak, v_th, v_reset, method, alpha)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExParameters.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><span class="pre">float</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExParameters.delta_T">
<span class="sig-name descname"><span class="pre">delta_T</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExParameters.delta_T" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExParameters.method">
<span class="sig-name descname"><span class="pre">method</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><span class="pre">str</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExParameters.tau_mem_inv">
<span class="sig-name descname"><span class="pre">tau_mem_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExParameters.tau_syn_inv">
<span class="sig-name descname"><span class="pre">tau_syn_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExParameters.v_leak">
<span class="sig-name descname"><span class="pre">v_leak</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExParameters.v_reset">
<span class="sig-name descname"><span class="pre">v_reset</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExParameters.v_th">
<span class="sig-name descname"><span class="pre">v_th</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExParameters.v_th" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFExRecurrent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFExRecurrent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFExParameters(delta_T=tensor(0.5000),</span> <span class="pre">tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=100.0)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExRecurrent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFExRecurrent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNRecurrent" title="norse.torch.module.snn.SNNRecurrent"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNRecurrent</span></code></a></p>
<p>A neuron layer that wraps a <a class="reference internal" href="#norse.torch.module.LIFExRecurrentCell" title="norse.torch.module.LIFExRecurrentCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFExRecurrentCell</span></code></a> in time such
that the layer keeps track of temporal sequences of spikes.
After application, the module returns a tuple containing</p>
<blockquote>
<div><p>(spikes from all timesteps, state from the last timestep).</p>
</div></blockquote>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 10 timesteps, 5 batches, 2 neurons</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">LIFExRecurrent</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># Returns tuple of (Tensor(10, 5, 4), LIFExState)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of input neurons</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of hidden neurons</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFExParameters" title="norse.torch.module.LIFExParameters"><em>LIFExParameters</em></a>) – The neuron parameters as a torch Module, which allows the module
to configure neuron parameters as optimizable. Defaults to None.</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – Weights used for input tensors. Defaults to a random
matrix normalized to the number of hidden neurons.</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – Weights used for input tensors. Defaults to a random
matrix normalized to the number of hidden neurons.</p></li>
<li><p><strong>autapses</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Allow self-connections in the recurrence? Defaults to False. Will also
remove autapses in custom recurrent weights, if set above.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use in integration. Defaults to 0.001.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFExRecurrent.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExRecurrent.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFExRecurrent.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif_ex.html#norse.torch.functional.lif_ex.LIFExState" title="norse.torch.functional.lif_ex.LIFExState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFExState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExRecurrent.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExRecurrent.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFExRecurrentCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFExRecurrentCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFExParameters(delta_T=tensor(0.5000),</span> <span class="pre">tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=100.0)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExRecurrentCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFExRecurrentCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNRecurrentCell" title="norse.torch.module.snn.SNNRecurrentCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNRecurrentCell</span></code></a></p>
<p>Computes a single euler-integration step of a recurrent
exponential LIFEx neuron-model (<em>with</em> recurrence) adapted from
<a class="reference external" href="https://neuronaldynamics.epfl.ch/online/Ch5.S2.html">https://neuronaldynamics.epfl.ch/online/Ch5.S2.html</a>.
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} \left(v_{\text{leak}} - v + i + \Delta_T exp\left({{v - v_{\text{th}}} \over {\Delta_T}}\right)\right) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFExParameters" title="norse.torch.module.LIFExParameters"><em>LIFExParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
<li><p><strong>a</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Allow self-connections in the recurrence? Defaults to False.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif_ex</span> <span class="o">=</span> <span class="n">LIFExRecurrentCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif_ex</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFExRecurrentCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_ex.html#LIFExRecurrentCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFExRecurrentCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif_ex.html#norse.torch.functional.lif_ex.LIFExState" title="norse.torch.functional.lif_ex.LIFExState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFExState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExRecurrentCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExRecurrentCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFExState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFExState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_ex.html#LIFExState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFExState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIFEx neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFExState(z, v, i)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExState.i">
<span class="sig-name descname"><span class="pre">i</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExState.v">
<span class="sig-name descname"><span class="pre">v</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFExState.z">
<span class="sig-name descname"><span class="pre">z</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFExState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFFeedForwardState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFFeedForwardState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">v</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif.html#LIFFeedForwardState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a feed forward LIF neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFFeedForwardState(v, i)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFFeedForwardState.i">
<span class="sig-name descname"><span class="pre">i</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFFeedForwardState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFFeedForwardState.v">
<span class="sig-name descname"><span class="pre">v</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFFeedForwardState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFMCRecurrentCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFMCRecurrentCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.))</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">g_coupling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_mc.html#LIFMCRecurrentCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFMCRecurrentCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNRecurrentCell" title="norse.torch.module.snn.SNNRecurrentCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNRecurrentCell</span></code></a></p>
<p>Computes a single euler-integration step of a LIF multi-compartment
neuron-model.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} \
    - g_{\text{coupling}} v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input. Also known as the number of input features.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state. Also known as the number of input features.</p></li>
<li><p><strong>g_coupling</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – conductances between the neuron compartments</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFParameters" title="norse.torch.module.LIFParameters"><em>LIFParameters</em></a>) – neuron parameters</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration timestep to use</p></li>
<li><p><strong>autapses</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Allow self-connections in the recurrence? Defaults to False.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFMCRecurrentCell.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_mc.html#LIFMCRecurrentCell.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFMCRecurrentCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFMCRecurrentCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_mc.html#LIFMCRecurrentCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFMCRecurrentCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFMCRecurrentCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFMCRecurrentCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFMCRefracRecurrentCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFMCRefracRecurrentCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.)),</span> <span class="pre">rho_reset=tensor(5.))</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">g_coupling</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_mc_refrac.html#LIFMCRefracRecurrentCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFMCRefracRecurrentCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNRecurrentCell" title="norse.torch.module.snn.SNNRecurrentCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNRecurrentCell</span></code></a></p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFMCRefracRecurrentCell.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_mc_refrac.html#LIFMCRefracRecurrentCell.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFMCRefracRecurrentCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.lif_refrac.html#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFMCRefracRecurrentCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_mc_refrac.html#LIFMCRefracRecurrentCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFMCRefracRecurrentCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif_refrac.html#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFMCRefracRecurrentCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFMCRefracRecurrentCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFParameters">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFParameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tau_syn_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(200.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_mem_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(100.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_leak</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_th</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(1.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_reset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><span class="pre">str</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'super'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><span class="pre">float</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(100.)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif.html#LIFParameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parametrization of a LIF neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inverse synaptic time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{syn}\)</span>) in 1/ms</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inverse membrane time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{mem}\)</span>) in 1/ms</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – leak potential in mV</p></li>
<li><p><strong>v_th</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – threshold potential in mV</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – reset potential in mV</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – method to determine the spike threshold
(relevant for surrogate gradients)</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – hyper parameter to use in surrogate gradient computation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFParameters(tau_syn_inv, tau_mem_inv, v_leak, v_th, v_reset, method, alpha)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFParameters.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><span class="pre">float</span></a></em><a class="headerlink" href="#norse.torch.module.LIFParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFParameters.method">
<span class="sig-name descname"><span class="pre">method</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><span class="pre">str</span></a></em><a class="headerlink" href="#norse.torch.module.LIFParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFParameters.tau_mem_inv">
<span class="sig-name descname"><span class="pre">tau_mem_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFParameters.tau_syn_inv">
<span class="sig-name descname"><span class="pre">tau_syn_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFParameters.v_leak">
<span class="sig-name descname"><span class="pre">v_leak</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFParameters.v_reset">
<span class="sig-name descname"><span class="pre">v_reset</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFParameters.v_th">
<span class="sig-name descname"><span class="pre">v_th</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFParameters.v_th" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFRecurrent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFRecurrent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.))</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFRecurrent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFRecurrent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNRecurrent" title="norse.torch.module.snn.SNNRecurrent"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNRecurrent</span></code></a></p>
<p>A neuron layer that wraps a <a class="reference internal" href="#norse.torch.module.LIFRecurrentCell" title="norse.torch.module.LIFRecurrentCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRecurrentCell</span></code></a> in time such
that the layer keeps track of temporal sequences of spikes.
After application, the module returns a tuple containing</p>
<blockquote>
<div><p>(spikes from all timesteps, state from the last timestep).</p>
</div></blockquote>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 10 timesteps, 5 batches, 2 neurons</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">LIFRecurrent</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># Returns tuple of (Tensor(10, 5, 4), LIFState)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of input neurons</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of hidden neurons</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFParameters" title="norse.torch.module.LIFParameters"><em>LIFParameters</em></a>) – The neuron parameters as a torch Module, which allows the module
to configure neuron parameters as optimizable.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Whether to apply sparse activation functions (True) or not (False). Defaults to False.</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – Weights used for input tensors. Defaults to a random
matrix normalized to the number of hidden neurons.</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – Weights used for input tensors. Defaults to a random
matrix normalized to the number of hidden neurons.</p></li>
<li><p><strong>autapses</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Allow self-connections in the recurrence? Defaults to False. Will also
remove autapses in custom recurrent weights, if set above.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use in integration. Defaults to 0.001.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFRecurrent.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFRecurrent.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFRecurrent.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFRecurrent.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFRecurrent.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFRecurrentCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFRecurrentCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.))</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sparse</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFRecurrentCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFRecurrentCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNRecurrentCell" title="norse.torch.module.snn.SNNRecurrentCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNRecurrentCell</span></code></a></p>
<p>Module that computes a single euler-integration step of a
leaky integrate-and-fire (LIF) neuron-model <em>with</em> recurrence but <em>without</em> time.
More specifically it implements one integration step
of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \
    i &amp;= i + w_{\text{input}} z_{\text{in}} \
    i &amp;= i + w_{\text{rec}} z_{\text{rec}}
\end{align*}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># 5 batches, 2 neurons</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">LIFRecurrentCell</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">l</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="c1"># Returns tuple of (Tensor(5, 4), LIFState)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input. Also known as the number of input features.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state. Also known as the number of input features.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFParameters" title="norse.torch.module.LIFParameters"><em>LIFParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Whether to apply sparse activation functions (True) or not (False). Defaults to False.</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – Weights used for input tensors. Defaults to a random
matrix normalized to the number of hidden neurons.</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – Weights used for input tensors. Defaults to a random
matrix normalized to the number of hidden neurons.</p></li>
<li><p><strong>autapses</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Allow self-connections in the recurrence? Defaults to False. Will also
remove autapses in custom recurrent weights, if set above.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFRecurrentCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif.html#LIFRecurrentCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFRecurrentCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFRecurrentCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFRecurrentCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFRefracCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.)),</span> <span class="pre">rho_reset=tensor(5.))</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_refrac.html#LIFRefracCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFRefracCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNCell" title="norse.torch.module.snn.SNNCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNCell</span></code></a></p>
<p>Module that computes a single euler-integration step of a
LIF neuron-model with absolute refractory period <em>without</em> recurrence.
More specifically it implements one integration step of the following ODE.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (1-\Theta(\rho))             (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{\rho} &amp;= -1/\tau_{\text{refrac}} \Theta(\rho)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    z &amp;= \Theta(v - v_{\text{th}}) \\
    z_r &amp;= \Theta(-\rho)
\end{align*}\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    \rho &amp;= \rho + z_r \rho_{\text{reset}}
\end{align*}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFRefracParameters" title="norse.torch.module.LIFRefracParameters"><em>LIFRefracParameters</em></a>) – parameters of the lif neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">LIFRefracCell</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_refrac.html#LIFRefracCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFRefracCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif_refrac.html#norse.torch.functional.lif_refrac.LIFRefracFeedForwardState" title="norse.torch.functional.lif_refrac.LIFRefracFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracFeedForwardState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFRefracCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracFeedForwardState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFRefracFeedForwardState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lif</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><span class="pre">norse.torch.functional.lif.LIFFeedForwardState</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">rho</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_refrac.html#LIFRefracFeedForwardState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFRefracFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a feed forward LIF neuron with absolute refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lif</strong> (<a class="reference internal" href="#norse.torch.module.LIFFeedForwardState" title="norse.torch.module.LIFFeedForwardState"><em>LIFFeedForwardState</em></a>) – state of the feed forward LIF
neuron integration</p></li>
<li><p><strong>rho</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – refractory state (count towards zero)</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFRefracFeedForwardState(lif, rho)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracFeedForwardState.lif">
<span class="sig-name descname"><span class="pre">lif</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><span class="pre">norse.torch.functional.lif.LIFFeedForwardState</span></a></em><a class="headerlink" href="#norse.torch.module.LIFRefracFeedForwardState.lif" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracFeedForwardState.rho">
<span class="sig-name descname"><span class="pre">rho</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFRefracFeedForwardState.rho" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracParameters">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFRefracParameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lif</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><span class="pre">norse.torch.functional.lif.LIFParameters</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.))</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rho_reset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(5.)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_refrac.html#LIFRefracParameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFRefracParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of a LIF neuron with absolute refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lif</strong> (<a class="reference internal" href="#norse.torch.module.LIFParameters" title="norse.torch.module.LIFParameters"><em>LIFParameters</em></a>) – parameters of the LIF neuron integration</p></li>
<li><p><strong>rho</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – refractory state (count towards zero)</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFRefracParameters(lif, rho_reset)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracParameters.lif">
<span class="sig-name descname"><span class="pre">lif</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><span class="pre">norse.torch.functional.lif.LIFParameters</span></a></em><a class="headerlink" href="#norse.torch.module.LIFRefracParameters.lif" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracParameters.rho_reset">
<span class="sig-name descname"><span class="pre">rho_reset</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFRefracParameters.rho_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracRecurrentCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFRefracRecurrentCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.)),</span> <span class="pre">rho_reset=tensor(5.))</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_refrac.html#LIFRefracRecurrentCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFRefracRecurrentCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNRecurrentCell" title="norse.torch.module.snn.SNNRecurrentCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNRecurrentCell</span></code></a></p>
<p>Module that computes a single euler-integration step of a LIF
neuron-model with absolute refractory period. More specifically it
implements one integration step of the following ODE.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (1-\Theta(\rho))             (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{\rho} &amp;= -1/\tau_{\text{refrac}} \Theta(\rho)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    z &amp;= \Theta(v - v_{\text{th}}) \\
    z_r &amp;= \Theta(-\rho)
\end{align*}\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}} \\
    \rho &amp;= \rho + z_r \rho_{\text{reset}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input. Also known as the number of input features.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state. Also known as the number of input features.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFRefracParameters" title="norse.torch.module.LIFRefracParameters"><em>LIFRefracParameters</em></a>) – parameters of the lif neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration timestep to use</p></li>
<li><p><strong>autapses</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Allow self-connections in the recurrence? Defaults to False.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">LIFRefracRecurrentCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracRecurrentCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lif_refrac.html#LIFRefracRecurrentCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFRefracRecurrentCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lif_refrac.html#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracRecurrentCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LIFRefracRecurrentCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFRefracState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lif</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><span class="pre">norse.torch.functional.lif.LIFState</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">rho</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_refrac.html#LIFRefracState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFRefracState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIF neuron with absolute refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lif</strong> (<a class="reference internal" href="#norse.torch.module.LIFState" title="norse.torch.module.LIFState"><em>LIFState</em></a>) – state of the LIF neuron integration</p></li>
<li><p><strong>rho</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – refractory state (count towards zero)</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFRefracState(lif, rho)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracState.lif">
<span class="sig-name descname"><span class="pre">lif</span></span><em class="property"><span class="pre">:</span> <a class="reference internal" href="norse.torch.functional.lif.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><span class="pre">norse.torch.functional.lif.LIFState</span></a></em><a class="headerlink" href="#norse.torch.module.LIFRefracState.lif" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFRefracState.rho">
<span class="sig-name descname"><span class="pre">rho</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFRefracState.rho" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIFState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIFState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif.html#LIFState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIFState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIF neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFState(z, v, i)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFState.i">
<span class="sig-name descname"><span class="pre">i</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFState.v">
<span class="sig-name descname"><span class="pre">v</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIFState.z">
<span class="sig-name descname"><span class="pre">z</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIFState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LILinearCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LILinearCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.))</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/leaky_integrator.html#LILinearCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LILinearCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Cell for a leaky-integrator with an additional linear weighting.
More specifically it implements a discretized version of the ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[i = i + w i_{\text{in}}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input. Also known as the number of input features.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state. Also known as the number of input features.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIParameters" title="norse.torch.module.LIParameters"><em>LIParameters</em></a>) – parameters of the leaky integrator</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – integration timestep to use</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LILinearCell.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/leaky_integrator.html#LILinearCell.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LILinearCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.leaky_integrator.html#norse.torch.functional.leaky_integrator.LIState" title="norse.torch.functional.leaky_integrator.LIState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LILinearCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LILinearCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIParameters">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIParameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tau_syn_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(200.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_mem_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(100.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_leak</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.)</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/leaky_integrator.html#LIParameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of a leaky integrator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inverse synaptic time constant</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inverse membrane time constant</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – leak potential</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIParameters(tau_syn_inv, tau_mem_inv, v_leak)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIParameters.tau_mem_inv">
<span class="sig-name descname"><span class="pre">tau_mem_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIParameters.tau_syn_inv">
<span class="sig-name descname"><span class="pre">tau_syn_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIParameters.v_leak">
<span class="sig-name descname"><span class="pre">v_leak</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LIState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LIState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">v</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/leaky_integrator.html#LIState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LIState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a leaky-integrator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – membrane voltage</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – input current</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIState(v, i)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIState.i">
<span class="sig-name descname"><span class="pre">i</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LIState.v">
<span class="sig-name descname"><span class="pre">v</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LIState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LSNN">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LSNN</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LSNNParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">tau_adapt_inv=tensor(0.0012),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">beta=tensor(1.8000),</span> <span class="pre">method='super',</span> <span class="pre">alpha=100.0)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNN"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LSNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNN" title="norse.torch.module.snn.SNN"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNN</span></code></a></p>
<p>A Long short-term memory neuron module <em>without</em> recurrence
adapted from <a class="reference external" href="https://arxiv.org/abs/1803.09574">https://arxiv.org/abs/1803.09574</a></p>
<dl>
<dt>Usage:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">norse.torch</span> <span class="kn">import</span> <span class="n">LSNN</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">layer</span> <span class="o">=</span> <span class="n">LSNN</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LSNNParameters" title="norse.torch.module.LSNNParameters"><em>LSNNParameters</em></a>) – The neuron parameters as a torch Module, which allows the module
to configure neuron parameters as optimizable.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use in integration. Defaults to 0.001.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LSNN.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNN.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LSNN.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lsnn.html#norse.torch.functional.lsnn.LSNNFeedForwardState" title="norse.torch.functional.lsnn.LSNNFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNFeedForwardState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNN.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LSNN.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LSNNCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LSNNCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LSNNParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">tau_adapt_inv=tensor(0.0012),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">beta=tensor(1.8000),</span> <span class="pre">method='super',</span> <span class="pre">alpha=100.0)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNNCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LSNNCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNCell" title="norse.torch.module.snn.SNNCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNCell</span></code></a></p>
<p>Euler integration cell for LIF Neuron with threshold adaptation
<em>without</em> recurrence.
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\\text{syn}} i \\
    \dot{b} &amp;= -1/\tau_{b} b
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}} + b)\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + \text{input} \\
    b &amp;= b + \beta z
\end{align*}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference external" href="https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.nn.Module</em></a>) – parameters of the lsnn unit</p></li>
<li><p><strong>p</strong> – The neuron parameters as a torch Module, which allows the module
to configure neuron parameters as optimizable.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use in integration. Defaults to 0.001.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LSNNCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNNCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LSNNCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lsnn.html#norse.torch.functional.lsnn.LSNNFeedForwardState" title="norse.torch.functional.lsnn.LSNNFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNFeedForwardState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LSNNFeedForwardState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LSNNFeedForwardState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">v</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lsnn.html#LSNNFeedForwardState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LSNNFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Integration state kept for a lsnn module</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>b</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – threshold adaptation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LSNNFeedForwardState(v, i, b)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNFeedForwardState.b">
<span class="sig-name descname"><span class="pre">b</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNFeedForwardState.b" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNFeedForwardState.i">
<span class="sig-name descname"><span class="pre">i</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNFeedForwardState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNFeedForwardState.v">
<span class="sig-name descname"><span class="pre">v</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNFeedForwardState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LSNNParameters">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LSNNParameters</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tau_syn_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(200.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_mem_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(100.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau_adapt_inv</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.0012)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_leak</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_th</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(1.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">v_reset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(0.)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">tensor(1.8000)</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">method</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><span class="pre">str</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">'super'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><span class="pre">float</span></a></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">100.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lsnn.html#LSNNParameters"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LSNNParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of an LSNN neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inverse synaptic time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{syn}\)</span>)</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – inverse membrane time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{mem}\)</span>)</p></li>
<li><p><strong>tau_adapt_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – adaptation time constant (<span class="math notranslate nohighlight">\(\tau_b\)</span>)</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – leak potential</p></li>
<li><p><strong>v_th</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – threshold potential</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – reset potential</p></li>
<li><p><strong>beta</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – adaptation constant</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LSNNParameters(tau_syn_inv, tau_mem_inv, tau_adapt_inv, v_leak, v_th, v_reset, beta, method, alpha)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNParameters.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><span class="pre">float</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 8</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNParameters.beta">
<span class="sig-name descname"><span class="pre">beta</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNParameters.beta" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNParameters.method">
<span class="sig-name descname"><span class="pre">method</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><span class="pre">str</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNParameters.tau_adapt_inv">
<span class="sig-name descname"><span class="pre">tau_adapt_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNParameters.tau_adapt_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNParameters.tau_mem_inv">
<span class="sig-name descname"><span class="pre">tau_mem_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNParameters.tau_syn_inv">
<span class="sig-name descname"><span class="pre">tau_syn_inv</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNParameters.v_leak">
<span class="sig-name descname"><span class="pre">v_leak</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNParameters.v_reset">
<span class="sig-name descname"><span class="pre">v_reset</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNParameters.v_th">
<span class="sig-name descname"><span class="pre">v_th</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNParameters.v_th" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LSNNRecurrent">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LSNNRecurrent</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LSNNParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">tau_adapt_inv=tensor(0.0012),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">beta=tensor(1.8000),</span> <span class="pre">method='super',</span> <span class="pre">alpha=100.0)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNNRecurrent"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LSNNRecurrent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNRecurrent" title="norse.torch.module.snn.SNNRecurrent"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNRecurrent</span></code></a></p>
<p>A Long short-term memory neuron module <em>wit</em> recurrence
adapted from <a class="reference external" href="https://arxiv.org/abs/1803.09574">https://arxiv.org/abs/1803.09574</a></p>
<dl>
<dt>Usage:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">norse.torch.module</span> <span class="kn">import</span> <span class="n">LSNNRecurrent</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">layer</span> <span class="o">=</span> <span class="n">LSNNRecurrent</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>          <span class="o">//</span> <span class="n">Shape</span> <span class="mi">2</span> <span class="o">-&gt;</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>          <span class="o">//</span> <span class="n">Arbitrary</span> <span class="n">data</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>   <span class="o">//</span> <span class="n">Out</span><span class="p">:</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input. Also known as the number of input features.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state. Also known as the number of input features.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LSNNParameters" title="norse.torch.module.LSNNParameters"><em>LSNNParameters</em></a>) – The neuron parameters as a torch Module, which allows the module
to configure neuron parameters as optimizable.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Time step to use in integration. Defaults to 0.001.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LSNNRecurrent.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNNRecurrent.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LSNNRecurrent.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lsnn.html#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNRecurrent.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNRecurrent.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LSNNRecurrentCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LSNNRecurrentCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LSNNParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">tau_adapt_inv=tensor(0.0012),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">beta=tensor(1.8000),</span> <span class="pre">method='super',</span> <span class="pre">alpha=100.0)</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNNRecurrentCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LSNNRecurrentCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="norse.torch.module.snn.html#norse.torch.module.snn.SNNRecurrentCell" title="norse.torch.module.snn.SNNRecurrentCell"><code class="xref py py-class docutils literal notranslate"><span class="pre">norse.torch.module.snn.SNNRecurrentCell</span></code></a></p>
<p>Module that computes a single euler-integration step of a LSNN
neuron-model <em>with</em> recurrence. More specifically it implements one
integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\begin{align*}
    \dot{v} &amp;= 1/\\tau_{\\text{mem}} (v_{\\text{leak}} - v + i) \\\\
    \dot{i} &amp;= -1/\\tau_{\\text{syn}} i \\\\
    \dot{b} &amp;= -1/\\tau_{b} b
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[\begin{split}z = \Theta(v - v_{\\text{th}} + b)\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\begin{align*}
    v &amp;= (1-z) v + z v_{\\text{reset}} \\\\
    i &amp;= i + w_{\\text{input}} z_{\\text{in}} \\\\
    i &amp;= i + w_{\\text{rec}} z_{\\text{rec}} \\\\
    b &amp;= b + \\beta z
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the input. Also known as the number of input features.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Size of the hidden state. Also known as the number of input features.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LSNNParameters" title="norse.torch.module.LSNNParameters"><em>LSNNParameters</em></a>) – parameters of the lsnn unit</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.LSNNRecurrentCell.initial_state">
<span class="sig-name descname"><span class="pre">initial_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lsnn.html#LSNNRecurrentCell.initial_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LSNNRecurrentCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.lsnn.html#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNState</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNRecurrentCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNRecurrentCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.LSNNState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">LSNNState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">v</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">i</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">b</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lsnn.html#LSNNState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.LSNNState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of an LSNN neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>b</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – threshold adaptation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LSNNState(z, v, i, b)</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNState.b">
<span class="sig-name descname"><span class="pre">b</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNState.b" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNState.i">
<span class="sig-name descname"><span class="pre">i</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNState.v">
<span class="sig-name descname"><span class="pre">v</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.LSNNState.z">
<span class="sig-name descname"><span class="pre">z</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><span class="pre">torch.Tensor</span></a></em><a class="headerlink" href="#norse.torch.module.LSNNState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.Lift">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">Lift</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">module</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lift.html#Lift"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.Lift" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="simple">
<dt>Lift applies a given torch.nn.Module over</dt><dd><p>a temporal sequence. In other words this module
applies the given torch.nn.Module N times, where N
is the outer dimension in the provided tensor.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>module</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code>) – Module to apply</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq_length</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">in_channels</span> <span class="o">=</span> <span class="mi">64</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out_channels</span> <span class="o">=</span> <span class="mi">32</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv2d</span> <span class="o">=</span> <span class="n">Lift</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">conv2d</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">Lift</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="n">LIF</span><span class="p">(),</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">module</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.Lift.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/lift.html#Lift.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.Lift.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply the module over the input along the 0-th (time) dimension
and accumulate the outputs in an output tensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Union" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]]) – Union[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the input is a tuple of two tensors, the second tuple entry will be ignored.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.Lift.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.Lift.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.PoissonEncoder">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">PoissonEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#PoissonEncoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.PoissonEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encodes a tensor of input values, which are assumed to be in the
range [0,1] (if not signed, [-1,1] if signed)
into a tensor of one dimension higher of binary values,
which represent input spikes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_values</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – Input data tensor with values assumed to be in the interval [0,1].</p></li>
<li><p><strong>sequence_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of time steps in the resulting spike train.</p></li>
<li><p><strong>f_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Maximal frequency (in Hertz) which will be emitted.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration time step (should coincide with the integration time step used in the model)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.PoissonEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#PoissonEncoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.PoissonEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.PoissonEncoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.PoissonEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.PopulationEncoder">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">PopulationEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">out_features</span></em>, <em class="sig-param"><span class="pre">scale=None</span></em>, <em class="sig-param"><span class="pre">kernel=&lt;function</span> <span class="pre">gaussian_rbf&gt;</span></em>, <em class="sig-param"><span class="pre">distance_function=&lt;function</span> <span class="pre">euclidean_distance&gt;</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#PopulationEncoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.PopulationEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encodes a set of input values into population codes, such that each singular input value is represented by
a list of numbers (typically calculated by a radial basis kernel), whose length is equal to the out_features.</p>
<p>Population encoding can be visualised by imagining a number of neurons in a list, whose activity increases
if a number gets close to its “receptive field”.</p>
<div class="figure align-default" id="id7">
<img alt="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/PopulationCode.svg/1920px-PopulationCode.svg.png" src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/PopulationCode.svg/1920px-PopulationCode.svg.png" />
<p class="caption"><span class="caption-text">Gaussian curves representing different neuron “receptive fields”. Image credit: <a class="reference external" href="https://com">Andrew K. Richardson</a>.</span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</div>
<p>super(PopulationEncoder, self).__init__()mons.wikimedia.org/wiki/<a class="reference external" href="File:PopulationCode.svg">File:PopulationCode.svg</a></p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out_features</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">PopulationEncoder</span><span class="p">(</span><span class="n">out_features</span><span class="p">)</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="go">tensor([[1.0000, 0.8825, 0.6065],</span>
<span class="go">        [0.8825, 1.0000, 0.8825],</span>
<span class="go">        [0.6065, 0.8825, 1.0000]])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>out_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – The number of output <em>per</em> input value</p></li>
<li><p><strong>scale</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><em>torch.Tensor</em></a>) – The scaling factor for the kernels. Defaults to the maximum value of the input.
Can also be set for each individual sample.</p></li>
<li><p><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></a>[[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]) – A function that takes two inputs and returns a tensor. The two inputs represent the center value
(which changes for each index in the output tensor) and the actual data value to encode respectively.z
Defaults to gaussian radial basis kernel function.</p></li>
<li><p><strong>distance_function</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></a>[[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]) – A function that calculates the distance between two numbers. Defaults to euclidean.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.PopulationEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#PopulationEncoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.PopulationEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.PopulationEncoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.PopulationEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.RegularizationCell">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">RegularizationCell</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">accumulator=&lt;function</span> <span class="pre">spike_accumulator&gt;</span></em>, <em class="sig-param"><span class="pre">state=None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/regularization.html#RegularizationCell"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.RegularizationCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A regularisation cell that accumulates some state (for instance number of spikes)
for each forward step, which can later be applied to a loss term.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">norse.torch.module</span> <span class="kn">import</span> <span class="n">lif</span><span class="p">,</span> <span class="n">regularization</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cell</span> <span class="o">=</span> <span class="n">lif</span><span class="o">.</span><span class="n">LIFCell</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="c1"># 2 -&gt; 4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span> <span class="o">=</span> <span class="n">regularization</span><span class="o">.</span><span class="n">RegularizationCell</span><span class="p">()</span> <span class="c1"># Defaults to spike counting</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># Batch size of 5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="n">cell</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">z</span><span class="p">,</span> <span class="n">regularization_term</span> <span class="o">=</span> <span class="n">r</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="o">...</span> <span class="o">+</span> <span class="mf">1e-3</span> <span class="o">*</span> <span class="n">regularization_term</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>accumulator</strong> (<em>Accumulator</em>) – The accumulator that aggregates some data (such as spikes) that can later
be included in an error term.</p></li>
<li><p><strong>state</strong> (<em>Optional</em><em>[</em><em>T</em><em>]</em>) – The regularization state to be aggregated to of any type T. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.RegularizationCell.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">z</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">s</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/regularization.html#RegularizationCell.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.RegularizationCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.RegularizationCell.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.RegularizationCell.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.SequentialState">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">SequentialState</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/sequential.html#SequentialState"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.SequentialState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.container.Sequential</span></code></p>
<p>A sequential model that works like PyTorch’s <code class="docutils literal notranslate"><span class="pre">Sequential</span></code> with the
addition that it handles neuron states.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>args</strong> (<a href="#id1"><span class="problematic" id="id2">*</span></a>torch.nn.Module) – A list of modules to sequentially apply in the forward pass</p>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">norse.torch</span> <span class="k">as</span> <span class="nn">snn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>         <span class="c1"># Single timestep</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">snn</span><span class="o">.</span><span class="n">SequentialState</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>  <span class="n">snn</span><span class="o">.</span><span class="n">Lift</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="c1"># (1, 8, 6, 2)</span>
<span class="gp">&gt;&gt;&gt; </span>  <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>                 <span class="c1"># (1, 8, 12)</span>
<span class="gp">&gt;&gt;&gt; </span>  <span class="n">snn</span><span class="o">.</span><span class="n">LIFRecurrent</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>             <span class="c1"># (1, 8, 6)</span>
<span class="gp">&gt;&gt;&gt; </span>  <span class="n">snn</span><span class="o">.</span><span class="n">LIFRecurrent</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>               <span class="c1"># (1, 8, 1)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<dl>
<dt>Example with recurrent layers:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">norse.torch</span> <span class="k">as</span> <span class="nn">snn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>         <span class="c1"># Single timestep</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">snn</span><span class="o">.</span><span class="n">SequentialState</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>  <span class="n">snn</span><span class="o">.</span><span class="n">Lift</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">3</span><span class="p">)),</span> <span class="c1"># (1, 8, 6, 2)</span>
<span class="gp">&gt;&gt;&gt; </span>  <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Flatten</span><span class="p">(</span><span class="mi">2</span><span class="p">),</span>                 <span class="c1"># (1, 8, 12)</span>
<span class="gp">&gt;&gt;&gt; </span>  <span class="n">snn</span><span class="o">.</span><span class="n">LSNNRecurrent</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>            <span class="c1"># (1, 8, 6)</span>
<span class="gp">&gt;&gt;&gt; </span>  <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>               <span class="c1"># (1, 6, 4) with 2 recurrent layers</span>
<span class="gp">&gt;&gt;&gt; </span>  <span class="n">snn</span><span class="o">.</span><span class="n">LIFRecurrent</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>               <span class="c1"># (1, 4, 1)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.SequentialState.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">state</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/sequential.html#SequentialState.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.SequentialState.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Feeds the input to the modules with the given state-list.
If the state is None, the initial state is set to None for each of the modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_tensor</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.10.0a0+gitb9e662f ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>) – The input tensor too feed into the first module</p></li>
<li><p><strong>state</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Optional" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Optional</span></code></a>[<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">list</span></code></a>]) – Either a list of states for each module or None. If None, the modules
will initialise their own default state</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple of (output tensor, state list)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.SequentialState.register_forward_state_hooks">
<span class="sig-name descname"><span class="pre">register_forward_state_hooks</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">forward_hook</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/sequential.html#SequentialState.register_forward_state_hooks"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.SequentialState.register_forward_state_hooks" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers hooks for all state*ful* layers.</p>
<p>Hooks can be removed by calling <a href="#id3"><span class="problematic" id="id4">:meth:`remove_state_hooks`_</span></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>child_hook</strong> (<em>Callable</em>) – The hook applied to all children everytime they produce an output</p></li>
<li><p><strong>pre_hook</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>]</em>) – An optional hook for the SequentialState module,
executed <em>before</em> the input is propagated to the children.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">norse.torch</span> <span class="k">as</span> <span class="nn">snn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">my_hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span> <span class="o">=</span> <span class="n">snn</span><span class="o">.</span><span class="n">SequentialState</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">register_forward_state_hook</span><span class="p">(</span><span class="n">my_hook</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.SequentialState.remove_forward_state_hooks">
<span class="sig-name descname"><span class="pre">remove_forward_state_hooks</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/sequential.html#SequentialState.remove_forward_state_hooks"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.SequentialState.remove_forward_state_hooks" title="Permalink to this definition">¶</a></dt>
<dd><p>Disables the forward state hooks, registered in <a href="#id5"><span class="problematic" id="id6">:meth:`register_forward_state_hooks`_</span></a>.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.SequentialState.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.SequentialState.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.SignedPoissonEncoder">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">SignedPoissonEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">f_max</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#SignedPoissonEncoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.SignedPoissonEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encodes a tensor of input values, which are assumed to be in the
range [-1,1] (if not signed, [-1,1] if signed)
into a tensor of one dimension higher of binary values,
which represent input spikes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of time steps in the resulting spike train.</p></li>
<li><p><strong>f_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Maximal frequency (in Hertz) which will be emitted.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration time step (should coincide with the integration time step used in the model)</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.SignedPoissonEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#SignedPoissonEncoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.SignedPoissonEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.SignedPoissonEncoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.SignedPoissonEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.SpikeLatencyEncoder">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">SpikeLatencyEncoder</span></span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#SpikeLatencyEncoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.SpikeLatencyEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>For all neurons, remove all but the first spike. This encoding basically measures the time it takes for a
neuron to spike <em>first</em>. Assuming that the inputs are constant, this makes sense in that strong inputs spikes
fast.</p>
<p>See <a class="reference external" href="https://doi.org/10.1162/08997660152002852">R. Van Rullen &amp; S. J. Thorpe (2001): Rate Coding Versus Temporal Order Coding: What the Retinal Ganglion Cells Tell the Visual Cortex</a>.</p>
<p>Spikes are identified by their unique position in the input array.</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoder</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="go">                ConstantCurrentLIFEncoder()</span>
<span class="go">                SpikeLatencyEncoder()</span>
<span class="go">                )</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">encoder</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="go">tensor([[0, 1, 1],</span>
<span class="go">        [1, 0, 0]])</span>
</pre></div>
</div>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.SpikeLatencyEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_spikes</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#SpikeLatencyEncoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.SpikeLatencyEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.SpikeLatencyEncoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.SpikeLatencyEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="norse.torch.module.SpikeLatencyLIFEncoder">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">norse.torch.module.</span></span><span class="sig-name descname"><span class="pre">SpikeLatencyLIFEncoder</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">seq_length</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">LIFParameters(tau_syn_inv=tensor(200.),</span> <span class="pre">tau_mem_inv=tensor(100.),</span> <span class="pre">v_leak=tensor(0.),</span> <span class="pre">v_th=tensor(1.),</span> <span class="pre">v_reset=tensor(0.),</span> <span class="pre">method='super',</span> <span class="pre">alpha=tensor(100.))</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#SpikeLatencyLIFEncoder"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.SpikeLatencyLIFEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Encodes an input value by the time the first spike occurs.
Similar to the ConstantCurrentLIFEncoder, but the LIF can be
thought to have an infinite refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of time steps in the resulting spike train.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.module.LIFParameters" title="norse.torch.module.LIFParameters"><em>LIFParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration time step (should coincide with the integration time step used in the model)</p></li>
</ul>
</dd>
</dl>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>
<dl class="py method">
<dt class="sig sig-object py" id="norse.torch.module.SpikeLatencyLIFEncoder.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_current</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/module/encode.html#SpikeLatencyLIFEncoder.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#norse.torch.module.SpikeLatencyLIFEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="norse.torch.module.SpikeLatencyLIFEncoder.training">
<span class="sig-name descname"><span class="pre">training</span></span><em class="property"><span class="pre">:</span> <a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><span class="pre">bool</span></a></em><a class="headerlink" href="#norse.torch.module.SpikeLatencyLIFEncoder.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.test.html">norse.torch.module.test package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.module.test.html#submodules">Submodules</a><ul>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_coba.html">norse.torch.module.test.test_coba module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_encode.html">norse.torch.module.test.test_encode module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_izhikevich.html">norse.torch.module.test.test_izhikevich module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_leaky_integrator.html">norse.torch.module.test.test_leaky_integrator module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif.html">norse.torch.module.test.test_lif module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif_adex.html">norse.torch.module.test.test_lif_adex module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif_correlation.html">norse.torch.module.test.test_lif_correlation module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif_ex.html">norse.torch.module.test.test_lif_ex module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif_mc.html">norse.torch.module.test.test_lif_mc module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif_mc_refrac.html">norse.torch.module.test.test_lif_mc_refrac module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lif_refrac.html">norse.torch.module.test.test_lif_refrac module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lift.html">norse.torch.module.test.test_lift module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_lsnn.html">norse.torch.module.test.test_lsnn module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_regularization.html">norse.torch.module.test.test_regularization module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_sequential.html">norse.torch.module.test.test_sequential module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_snn.html">norse.torch.module.test.test_snn module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.test_training.html">norse.torch.module.test.test_training module</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.coba_lif.html">norse.torch.module.coba_lif module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.encode.html">norse.torch.module.encode module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.izhikevich.html">norse.torch.module.izhikevich module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.leaky_integrator.html">norse.torch.module.leaky_integrator module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif.html">norse.torch.module.lif module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif_adex.html">norse.torch.module.lif_adex module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif_correlation.html">norse.torch.module.lif_correlation module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif_ex.html">norse.torch.module.lif_ex module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif_mc.html">norse.torch.module.lif_mc module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif_mc_refrac.html">norse.torch.module.lif_mc_refrac module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lif_refrac.html">norse.torch.module.lif_refrac module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lift.html">norse.torch.module.lift module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.lsnn.html">norse.torch.module.lsnn module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.regularization.html">norse.torch.module.regularization module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.sequential.html">norse.torch.module.sequential module</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.snn.html">norse.torch.module.snn module</a></li>
</ul>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/logo.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">A library to do deep learning with spiking neural networks.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=norse&repo=norse&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">First steps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">∇ Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installing.html">1. Installing Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../started.html">2. Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tasks.html">3. Running Tasks</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Usage docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../about.html">1. About Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hardware.html">2. Hardware acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spiking.html">3. Introduction to spikes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../learning.html">4. Learning with spikes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../papers.html">5. Papers citing Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../working.html">6. Working with Norse</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Docs</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="norse.benchmark.html">norse.benchmark package</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.dataset.html">norse.dataset package</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.task.html">norse.task package</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="norse.torch.html">norse.torch package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="norse.torch.functional.html">norse.torch.functional package</a></li>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.models.html">norse.torch.models package</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">norse.torch.module package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.test.html">norse.torch.module.test package</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.coba_lif.html">norse.torch.module.coba_lif module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.encode.html">norse.torch.module.encode module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.izhikevich.html">norse.torch.module.izhikevich module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.leaky_integrator.html">norse.torch.module.leaky_integrator module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.lif.html">norse.torch.module.lif module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.lif_adex.html">norse.torch.module.lif_adex module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.lif_correlation.html">norse.torch.module.lif_correlation module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.lif_ex.html">norse.torch.module.lif_ex module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.lif_mc.html">norse.torch.module.lif_mc module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.lif_mc_refrac.html">norse.torch.module.lif_mc_refrac module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.lif_refrac.html">norse.torch.module.lif_refrac module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.lift.html">norse.torch.module.lift module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.lsnn.html">norse.torch.module.lsnn module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.regularization.html">norse.torch.module.regularization module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.sequential.html">norse.torch.module.sequential module</a></li>
<li class="toctree-l3"><a class="reference internal" href="norse.torch.module.snn.html">norse.torch.module.snn module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.utils.html">norse.torch.utils package</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="norse.torch.html">norse.torch package</a><ul>
      <li>Previous: <a href="norse.torch.models.vgg.html" title="previous chapter">norse.torch.models.vgg module</a></li>
      <li>Next: <a href="norse.torch.module.test.html" title="next chapter">norse.torch.module.test package</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019 - 2021, Norse.ai.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 4.1.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/auto_api/norse.torch.module.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>