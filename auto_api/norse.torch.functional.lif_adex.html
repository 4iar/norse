
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>norse.torch.functional.lif_adex module &#8212; norse 0.0.4 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="norse.torch.functional.lif_correlation module" href="norse.torch.functional.lif_correlation.html" />
    <link rel="prev" title="norse.torch.functional.lif module" href="norse.torch.functional.lif.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="module-norse.torch.functional.lif_adex">
<span id="norse-torch-functional-lif-adex-module"></span><h1>norse.torch.functional.lif_adex module<a class="headerlink" href="#module-norse.torch.functional.lif_adex" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="norse.torch.functional.lif_adex.LIFAdExFeedForwardState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lif_adex.</code><code class="sig-name descname">LIFAdExFeedForwardState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#LIFAdExFeedForwardState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a feed forward LIFAdEx neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>a</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – membrane potential adaptation factor</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFAdExFeedForwardState(v, i, a)</p>
<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExFeedForwardState.a">
<code class="sig-name descname">a</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExFeedForwardState.a" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExFeedForwardState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExFeedForwardState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExFeedForwardState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExFeedForwardState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.lif_adex.LIFAdExParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lif_adex.</code><code class="sig-name descname">LIFAdExParameters</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#LIFAdExParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parametrization of an Adaptive Exponential Leaky Integrate and Fire neuron</p>
<p>Default values from <a class="reference external" href="https://github.com/NeuralEnsemble/PyNN/blob/d8056fa956998b031a1c3689a528473ed2bc0265/pyNN/standardmodels/cells.py#L416">https://github.com/NeuralEnsemble/PyNN/blob/d8056fa956998b031a1c3689a528473ed2bc0265/pyNN/standardmodels/cells.py#L416</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>adaptation_current</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – adaptation coupling parameter in nS</p></li>
<li><p><strong>adaptation_spike</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – spike triggered adaptation parameter in nA</p></li>
<li><p><strong>delta_T</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – sharpness or speed of the exponential growth in mV</p></li>
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – inverse adaptation time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{ada}\)</span>) in 1/ms</p></li>
<li><p><strong>tau_syn_inv</strong> – inverse synaptic time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{syn}\)</span>) in 1/ms</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – inverse membrane time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{mem}\)</span>) in 1/ms</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – leak potential in mV</p></li>
<li><p><strong>v_th</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – threshold potential in mV</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – reset potential in mV</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – method to determine the spike threshold
(relevant for surrogate gradients)</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – hyper parameter to use in surrogate gradient computation</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFAdExParameters(adaptation_current, adaptation_spike, delta_T, tau_ada_inv, tau_syn_inv, tau_mem_inv, v_leak, v_th, v_reset, method, alpha)</p>
<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExParameters.adaptation_current">
<code class="sig-name descname">adaptation_current</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExParameters.adaptation_current" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExParameters.adaptation_spike">
<code class="sig-name descname">adaptation_spike</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExParameters.adaptation_spike" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExParameters.alpha">
<code class="sig-name descname">alpha</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 10</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExParameters.delta_T">
<code class="sig-name descname">delta_T</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExParameters.delta_T" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExParameters.method">
<code class="sig-name descname">method</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 9</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExParameters.tau_ada_inv">
<code class="sig-name descname">tau_ada_inv</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExParameters.tau_ada_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExParameters.tau_mem_inv">
<code class="sig-name descname">tau_mem_inv</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExParameters.tau_syn_inv">
<code class="sig-name descname">tau_syn_inv</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExParameters.v_leak">
<code class="sig-name descname">v_leak</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExParameters.v_reset">
<code class="sig-name descname">v_reset</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 8</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExParameters.v_th">
<code class="sig-name descname">v_th</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExParameters.v_th" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.lif_adex.LIFAdExState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lif_adex.</code><code class="sig-name descname">LIFAdExState</code><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#LIFAdExState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.9)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIFAdEx neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>a</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – membrane potential adaptation factor</p></li>
</ul>
</dd>
</dl>
<p>Create new instance of LIFAdExState(z, v, i, a)</p>
<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExState.a">
<code class="sig-name descname">a</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExState.a" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_adex.LIFAdExState.z">
<code class="sig-name descname">z</code><a class="headerlink" href="#norse.torch.functional.lif_adex.LIFAdExState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lif_adex.lif_adex_current_encoder">
<code class="sig-prename descclassname">norse.torch.functional.lif_adex.</code><code class="sig-name descname">lif_adex_current_encoder</code><span class="sig-paren">(</span><em class="sig-param">input_current</em>, <em class="sig-param">voltage</em>, <em class="sig-param">adaptation</em>, <em class="sig-param">p=LIFAdExParameters(adaptation_current=tensor(4)</em>, <em class="sig-param">adaptation_spike=tensor(0.0200)</em>, <em class="sig-param">delta_T=tensor(0.5000)</em>, <em class="sig-param">tau_ada_inv=tensor(2.)</em>, <em class="sig-param">tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#lif_adex_current_encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_adex.lif_adex_current_encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a single euler-integration step of an adaptive exponential LIF neuron-model
adapted from <a class="reference external" href="http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model">http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model</a>.
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} \left(v_{\text{leak}} - v + i + \Delta_T exp\left({{v - v_{\text{th}}} \over {\Delta_T}}\right)\right) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{a} &amp;= 1/\tau_{\text{ada}} \left( a_{current} (V - v_{\text{leak}}) - a \right)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + i_{\text{in}} \\
    a &amp;= a + a_{\text{spike}} z_{\text{rec}}
\end{align*}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – the input current at the current time step</p></li>
<li><p><strong>voltage</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – current state of the LIFAdEx neuron</p></li>
<li><p><strong>adaptation</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – membrane adaptation parameter in nS</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lif_adex.LIFAdExParameters" title="norse.torch.functional.lif_adex.LIFAdExParameters"><em>LIFAdExParameters</em></a>) – parameters of a leaky integrate and fire neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lif_adex.lif_adex_feed_forward_step">
<code class="sig-prename descclassname">norse.torch.functional.lif_adex.</code><code class="sig-name descname">lif_adex_feed_forward_step</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state=LIFAdExFeedForwardState(v=0</em>, <em class="sig-param">i=0</em>, <em class="sig-param">a=0)</em>, <em class="sig-param">p=LIFAdExParameters(adaptation_current=tensor(4)</em>, <em class="sig-param">adaptation_spike=tensor(0.0200)</em>, <em class="sig-param">delta_T=tensor(0.5000)</em>, <em class="sig-param">tau_ada_inv=tensor(2.)</em>, <em class="sig-param">tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#lif_adex_feed_forward_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_adex.lif_adex_feed_forward_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a single euler-integration step of an adaptive exponential
LIF neuron-model adapted from
<a class="reference external" href="http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model">http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model</a>.
It takes as input the input current as generated by an arbitrary torch
module or function. More specifically it implements one integration step of
the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} \left(v_{\text{leak}} - v + i + \Delta_T exp\left({{v - v_{\text{th}}} \over {\Delta_T}}\right)\right) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{a} &amp;= 1/\tau_{\text{ada}} \left( a_{current} (V - v_{\text{leak}}) - a \right)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + i_{\text{in}} \\
    a &amp;= a + a_{\text{spike}} z_{\text{rec}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(i_{\text{in}}\)</span> is meant to be the result of applying an
arbitrary pytorch module (such as a convolution) to input spikes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_tensor</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>state</strong> (<a class="reference internal" href="#norse.torch.functional.lif_adex.LIFAdExFeedForwardState" title="norse.torch.functional.lif_adex.LIFAdExFeedForwardState"><em>LIFAdExFeedForwardState</em></a>) – current state of the LIF neuron</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lif_adex.LIFAdExParameters" title="norse.torch.functional.lif_adex.LIFAdExParameters"><em>LIFAdExParameters</em></a>) – parameters of a leaky integrate and fire neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lif_adex.LIFAdExFeedForwardState" title="norse.torch.functional.lif_adex.LIFAdExFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFAdExFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lif_adex.lif_adex_step">
<code class="sig-prename descclassname">norse.torch.functional.lif_adex.</code><code class="sig-name descname">lif_adex_step</code><span class="sig-paren">(</span><em class="sig-param">input_tensor</em>, <em class="sig-param">state</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">recurrent_weights</em>, <em class="sig-param">p=LIFAdExParameters(adaptation_current=tensor(4)</em>, <em class="sig-param">adaptation_spike=tensor(0.0200)</em>, <em class="sig-param">delta_T=tensor(0.5000)</em>, <em class="sig-param">tau_ada_inv=tensor(2.)</em>, <em class="sig-param">tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/lif_adex.html#lif_adex_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_adex.lif_adex_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a single euler-integration step of an adaptive exponential LIF neuron-model
adapted from <a class="reference external" href="http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model">http://www.scholarpedia.org/article/Adaptive_exponential_integrate-and-fire_model</a>.
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} \left(v_{\text{leak}} - v + i + \Delta_T exp\left({{v - v_{\text{th}}} \over {\Delta_T}}\right)\right) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{a} &amp;= 1/\tau_{\text{ada}} \left( a_{current} (V - v_{\text{leak}}) - a \right)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}} \\
    a &amp;= a + a_{\text{spike}} z_{\text{rec}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the recurrent
and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_tensor</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lif_adex.LIFAdExState" title="norse.torch.functional.lif_adex.LIFAdExState"><em>LIFAdExState</em></a>) – current state of the LIF neuron</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – synaptic weights for incoming spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lif_adex.LIFAdExParameters" title="norse.torch.functional.lif_adex.LIFAdExParameters"><em>LIFAdExParameters</em></a>) – parameters of a leaky integrate and fire neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.9)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.9)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.8.0a0+11c8a58 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lif_adex.LIFAdExState" title="norse.torch.functional.lif_adex.LIFAdExState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFAdExState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/logo.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">A library to do deep learning with spiking neural networks.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=norse&repo=norse&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Usage Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../about.html">1. About Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installing.html">2. Installing Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hardware.html">3. Hardware acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spiking.html">4. Introduction to spiking neural networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../learning.html">5. Learning with spikes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../working.html">6. Working with Norse</a></li>
</ul>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">1. Beginner tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experiments.html">2. Running Experiments</a></li>
</ul>
<p class="caption"><span class="caption-text">API Docs</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="norse.benchmark.html">norse.benchmark package</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.task.html">norse.task package</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="norse.torch.html">norse.torch package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="norse.torch.functional.html">norse.torch.functional package</a></li>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.models.html">norse.torch.models package</a></li>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.module.html">norse.torch.module package</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="norse.torch.html">norse.torch package</a><ul>
  <li><a href="norse.torch.functional.html">norse.torch.functional package</a><ul>
      <li>Previous: <a href="norse.torch.functional.lif.html" title="previous chapter">norse.torch.functional.lif module</a></li>
      <li>Next: <a href="norse.torch.functional.lif_correlation.html" title="next chapter">norse.torch.functional.lif_correlation module</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Norse.ai.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.4.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/auto_api/norse.torch.functional.lif_adex.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>