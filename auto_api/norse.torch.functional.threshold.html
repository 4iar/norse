
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>norse.torch.functional.threshold module &#8212; norse 0.0.2 documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="norse.torch.functional.tsodyks_makram module" href="norse.torch.functional.tsodyks_makram.html" />
    <link rel="prev" title="norse.torch.functional.test_tsodyks_makram module" href="norse.torch.functional.test_tsodyks_makram.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="module-norse.torch.functional.threshold">
<span id="norse-torch-functional-threshold-module"></span><h1>norse.torch.functional.threshold module<a class="headerlink" href="#module-norse.torch.functional.threshold" title="Permalink to this headline">¶</a></h1>
<dl class="class">
<dt id="norse.torch.functional.threshold.CircDist">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">CircDist</code><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#CircDist"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.CircDist" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<dl class="method">
<dt id="norse.torch.functional.threshold.CircDist.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">dy</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#CircDist.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.CircDist.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs did <a class="reference internal" href="#norse.torch.functional.threshold.CircDist.forward" title="norse.torch.functional.threshold.CircDist.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> return, and it should return as many
tensors, as there were inputs to <a class="reference internal" href="#norse.torch.functional.threshold.CircDist.forward" title="norse.torch.functional.threshold.CircDist.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the
gradient w.r.t the given output, and each returned value should be the
gradient w.r.t. the corresponding input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#norse.torch.functional.threshold.CircDist.backward" title="norse.torch.functional.threshold.CircDist.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#norse.torch.functional.threshold.CircDist.forward" title="norse.torch.functional.threshold.CircDist.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.functional.threshold.CircDist.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#CircDist.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.CircDist.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store tensors that can be then retrieved
during the backward pass.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.threshold.HeaviCirc">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">HeaviCirc</code><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#HeaviCirc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviCirc" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Approximation of the heaviside step function as</p>
<div class="math notranslate nohighlight">
\[h(x,\alpha) = \frac{1}{2} + \frac{1}{2} \
\frac{x}{(x^2 + \alpha^2)^{1/2}}\]</div>
<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviCirc.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">dy</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#HeaviCirc.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviCirc.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs did <a class="reference internal" href="#norse.torch.functional.threshold.HeaviCirc.forward" title="norse.torch.functional.threshold.HeaviCirc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> return, and it should return as many
tensors, as there were inputs to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviCirc.forward" title="norse.torch.functional.threshold.HeaviCirc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the
gradient w.r.t the given output, and each returned value should be the
gradient w.r.t. the corresponding input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#norse.torch.functional.threshold.HeaviCirc.backward" title="norse.torch.functional.threshold.HeaviCirc.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviCirc.forward" title="norse.torch.functional.threshold.HeaviCirc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviCirc.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#HeaviCirc.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviCirc.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store tensors that can be then retrieved
during the backward pass.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.threshold.HeaviErfc">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">HeaviErfc</code><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#HeaviErfc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviErfc" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Approximation of the heaviside step function as</p>
<div class="math notranslate nohighlight">
\[h(x,k) = \frac{1}{2} + \frac{1}{2} \text{erfc}(k x)\]</div>
<p>where erfc is the error function.</p>
<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviErfc.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">dy</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#HeaviErfc.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviErfc.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs did <a class="reference internal" href="#norse.torch.functional.threshold.HeaviErfc.forward" title="norse.torch.functional.threshold.HeaviErfc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> return, and it should return as many
tensors, as there were inputs to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviErfc.forward" title="norse.torch.functional.threshold.HeaviErfc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the
gradient w.r.t the given output, and each returned value should be the
gradient w.r.t. the corresponding input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#norse.torch.functional.threshold.HeaviErfc.backward" title="norse.torch.functional.threshold.HeaviErfc.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviErfc.forward" title="norse.torch.functional.threshold.HeaviErfc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviErfc.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">k</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#HeaviErfc.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviErfc.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store tensors that can be then retrieved
during the backward pass.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.threshold.HeaviTanh">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">HeaviTanh</code><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#HeaviTanh"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviTanh" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Approximation of the heaviside step function as</p>
<div class="math notranslate nohighlight">
\[h(x,k) = \frac{1}{2} + \frac{1}{2} \text{tanh}(k x)\]</div>
<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviTanh.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">dy</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#HeaviTanh.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviTanh.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs did <a class="reference internal" href="#norse.torch.functional.threshold.HeaviTanh.forward" title="norse.torch.functional.threshold.HeaviTanh.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> return, and it should return as many
tensors, as there were inputs to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviTanh.forward" title="norse.torch.functional.threshold.HeaviTanh.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the
gradient w.r.t the given output, and each returned value should be the
gradient w.r.t. the corresponding input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#norse.torch.functional.threshold.HeaviTanh.backward" title="norse.torch.functional.threshold.HeaviTanh.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviTanh.forward" title="norse.torch.functional.threshold.HeaviTanh.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviTanh.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">k</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#HeaviTanh.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviTanh.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store tensors that can be then retrieved
during the backward pass.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.threshold.HeaviTent">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">HeaviTent</code><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#HeaviTent"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviTent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviTent.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">dy</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#HeaviTent.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviTent.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs did <a class="reference internal" href="#norse.torch.functional.threshold.HeaviTent.forward" title="norse.torch.functional.threshold.HeaviTent.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> return, and it should return as many
tensors, as there were inputs to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviTent.forward" title="norse.torch.functional.threshold.HeaviTent.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the
gradient w.r.t the given output, and each returned value should be the
gradient w.r.t. the corresponding input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#norse.torch.functional.threshold.HeaviTent.backward" title="norse.torch.functional.threshold.HeaviTent.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviTent.forward" title="norse.torch.functional.threshold.HeaviTent.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviTent.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#HeaviTent.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviTent.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store tensors that can be then retrieved
during the backward pass.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.threshold.Logistic">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">Logistic</code><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#Logistic"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.Logistic" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Probalistic approximation of the heaviside step function as</p>
<div class="math notranslate nohighlight">
\[z \sim p(\frac{1}{2} + \frac{1}{2} \text{tanh}(k x))\]</div>
<dl class="method">
<dt id="norse.torch.functional.threshold.Logistic.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">dy</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#Logistic.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.Logistic.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs did <a class="reference internal" href="#norse.torch.functional.threshold.Logistic.forward" title="norse.torch.functional.threshold.Logistic.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> return, and it should return as many
tensors, as there were inputs to <a class="reference internal" href="#norse.torch.functional.threshold.Logistic.forward" title="norse.torch.functional.threshold.Logistic.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the
gradient w.r.t the given output, and each returned value should be the
gradient w.r.t. the corresponding input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#norse.torch.functional.threshold.Logistic.backward" title="norse.torch.functional.threshold.Logistic.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#norse.torch.functional.threshold.Logistic.forward" title="norse.torch.functional.threshold.Logistic.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.functional.threshold.Logistic.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">k</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#Logistic.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.Logistic.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store tensors that can be then retrieved
during the backward pass.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.circ_dist_fn">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">circ_dist_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#norse.torch.functional.threshold.circ_dist_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.heavi_circ_fn">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">heavi_circ_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#norse.torch.functional.threshold.heavi_circ_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.heavi_erfc_fn">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">heavi_erfc_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#norse.torch.functional.threshold.heavi_erfc_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.heavi_tanh_fn">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">heavi_tanh_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#norse.torch.functional.threshold.heavi_tanh_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.heavi_tent_fn">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">heavi_tent_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#norse.torch.functional.threshold.heavi_tent_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.logistic_fn">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">logistic_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#norse.torch.functional.threshold.logistic_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.sign">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">sign</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">method</em>, <em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#sign"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.sign" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+461aa8a ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.threshold">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">threshold</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">method</em>, <em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/norse/torch/functional/threshold.html#threshold"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.threshold" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+461aa8a ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../index.html">norse</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Beginner tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../experiments.html">Running Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../spiking.html">Introduction to spikes</a></li>
</ul>
<p class="caption"><span class="caption-text">API Docs</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="norse.torch.html">norse.torch package</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="norse.torch.functional.html">norse.torch.functional package</a></li>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.models.html">norse.torch.models package</a></li>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.module.html">norse.torch.module package</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
  <li><a href="norse.torch.html">norse.torch package</a><ul>
  <li><a href="norse.torch.functional.html">norse.torch.functional package</a><ul>
      <li>Previous: <a href="norse.torch.functional.test_tsodyks_makram.html" title="previous chapter">norse.torch.functional.test_tsodyks_makram module</a></li>
      <li>Next: <a href="norse.torch.functional.tsodyks_makram.html" title="next chapter">norse.torch.functional.tsodyks_makram module</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Norse.ai.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.4.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/auto_api/norse.torch.functional.threshold.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>