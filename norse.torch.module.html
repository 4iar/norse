
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>norse.torch.module package &#8212; norse 0.0.2 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-dataframe.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="norse.torch.module.test package" href="norse.torch.module.test.html" />
    <link rel="prev" title="norse.torch.models package" href="norse.torch.models.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="norse-torch-module-package">
<h1>norse.torch.module package<a class="headerlink" href="#norse-torch-module-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.test.html">norse.torch.module.test package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.module.test.html#submodules">Submodules</a></li>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.module.test.html#norse-torch-module-test-test-lsnn-module">norse.torch.module.test.test_lsnn module</a></li>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.module.test.html#module-norse.torch.module.test">Module contents</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-norse.torch.module.coba_lif">
<span id="norse-torch-module-coba-lif-module"></span><h2>norse.torch.module.coba_lif module<a class="headerlink" href="#module-norse.torch.module.coba_lif" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.module.coba_lif.CobaLIFCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.coba_lif.</code><code class="sig-name descname">CobaLIFCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=CobaLIFParameters(tau_syn_exc_inv=tensor(0.2000)</em>, <em class="sig-param">tau_syn_inh_inv=tensor(0.2000)</em>, <em class="sig-param">c_m_inv=tensor(5.)</em>, <em class="sig-param">g_l=tensor(0.2500)</em>, <em class="sig-param">e_rev_I=tensor(-100)</em>, <em class="sig-param">e_rev_E=tensor(60)</em>, <em class="sig-param">v_rest=tensor(-20)</em>, <em class="sig-param">v_reset=tensor(-70)</em>, <em class="sig-param">v_thresh=tensor(-10)</em>, <em class="sig-param">method='heaviside'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/coba_lif.html#CobaLIFCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.coba_lif.CobaLIFCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module that computes a single euler-integration step of a conductance based
LIF neuron-model. More specifically it implements one integration step of
the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/c_{\text{mem}} (g_l (v_{\text{leak}} - v)               + g_e (E_{\text{rev_e}} - v) + g_i (E_{\text{rev_i}} - v)) \\
    \dot{g_e} &amp;= -1/\tau_{\text{syn}} g_e \\
    \dot{g_i} &amp;= -1/\tau_{\text{syn}} g_i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    g_e &amp;= g_e + \text{relu}(w_{\text{input}}) z_{\text{in}} \\
    g_e &amp;= g_e + \text{relu}(w_{\text{rec}}) z_{\text{rec}} \\
    g_i &amp;= g_i + \text{relu}(-w_{\text{input}}) z_{\text{in}} \\
    g_i &amp;= g_i + \text{relu}(-w_{\text{rec}}) z_{\text{rec}} \\
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the recurrent
and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of the input.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of the hidden state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">CobaLIFCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="o">.</span><span class="n">initial_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">s0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="norse.torch.module.coba_lif.CobaLIFCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/coba_lif.html#CobaLIFCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.coba_lif.CobaLIFCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.coba_lif.CobaLIFState" title="norse.torch.functional.coba_lif.CobaLIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">CobaLIFState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.coba_lif.CobaLIFCell.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype=torch.float32</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/coba_lif.html#CobaLIFCell.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.coba_lif.CobaLIFCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.coba_lif.CobaLIFState" title="norse.torch.functional.coba_lif.CobaLIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">CobaLIFState</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-norse.torch.module.if_current_encoder">
<span id="norse-torch-module-if-current-encoder-module"></span><h2>norse.torch.module.if_current_encoder module<a class="headerlink" href="#module-norse.torch.module.if_current_encoder" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.module.if_current_encoder.IFConstantCurrentEncoder">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.if_current_encoder.</code><code class="sig-name descname">IFConstantCurrentEncoder</code><span class="sig-paren">(</span><em class="sig-param">seq_length</em>, <em class="sig-param">tau_mem_inv=100.0</em>, <em class="sig-param">v_th=1.0</em>, <em class="sig-param">v_reset=0.0</em>, <em class="sig-param">dt=0.001</em>, <em class="sig-param">device='cpu'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/if_current_encoder.html#IFConstantCurrentEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.if_current_encoder.IFConstantCurrentEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="norse.torch.module.if_current_encoder.IFConstantCurrentEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/if_current_encoder.html#IFConstantCurrentEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.if_current_encoder.IFConstantCurrentEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-norse.torch.module.leaky_integrator">
<span id="norse-torch-module-leaky-integrator-module"></span><h2>norse.torch.module.leaky_integrator module<a class="headerlink" href="#module-norse.torch.module.leaky_integrator" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.module.leaky_integrator.LICell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.leaky_integrator.</code><code class="sig-name descname">LICell</code><span class="sig-paren">(</span><em class="sig-param">input_features</em>, <em class="sig-param">output_features</em>, <em class="sig-param">p=LIParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_reset=tensor(0.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/leaky_integrator.html#LICell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.leaky_integrator.LICell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Cell for a leaky-integrator.
More specifically it implements a discretized version of the ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[i = i + w i_{\text{in}}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – </p></li>
<li><p><strong>output_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Output feature dimension</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.leaky_integrator.LIParameters" title="norse.torch.functional.leaky_integrator.LIParameters"><em>LIParameters</em></a>) – parameters of the leaky integrator</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – integration timestep to use</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="norse.torch.module.leaky_integrator.LICell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/leaky_integrator.html#LICell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.leaky_integrator.LICell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.leaky_integrator.LIState" title="norse.torch.functional.leaky_integrator.LIState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.leaky_integrator.LICell.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype=torch.float32</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/leaky_integrator.html#LICell.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.leaky_integrator.LICell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.leaky_integrator.LIState" title="norse.torch.functional.leaky_integrator.LIState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIState</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.leaky_integrator.LIFeedForwardCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.leaky_integrator.</code><code class="sig-name descname">LIFeedForwardCell</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">p=LIParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_reset=tensor(0.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/leaky_integrator.html#LIFeedForwardCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.leaky_integrator.LIFeedForwardCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Cell for a leaky-integrator.
More specifically it implements a discretized version of the ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[i = i + w i_{\text{in}}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> – Shape of the preprocessed input spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.leaky_integrator.LIParameters" title="norse.torch.functional.leaky_integrator.LIParameters"><em>LIParameters</em></a>) – parameters of the leaky integrator</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – integration timestep to use</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="norse.torch.module.leaky_integrator.LIFeedForwardCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/leaky_integrator.html#LIFeedForwardCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.leaky_integrator.LIFeedForwardCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.leaky_integrator.LIState" title="norse.torch.functional.leaky_integrator.LIState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.leaky_integrator.LIFeedForwardCell.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype=torch.float32</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/leaky_integrator.html#LIFeedForwardCell.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.leaky_integrator.LIFeedForwardCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="module-norse.torch.module.lif">
<span id="norse-torch-module-lif-module"></span><h2>norse.torch.module.lif module<a class="headerlink" href="#module-norse.torch.module.lif" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.module.lif.LIFCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.lif.</code><code class="sig-name descname">LIFCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif.html#LIFCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif.LIFCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module that computes a single euler-integration step of a LIF
neuron-model. More specifically it implements one integration step
of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of the input.</p></li>
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Size of the hidden state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">LIFCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="o">.</span><span class="n">initial_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">s0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="norse.torch.module.lif.LIFCell.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif.html#LIFCell.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif.LIFCell.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should reimplement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.lif.LIFCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif.html#LIFCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif.LIFCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.lif.LIFCell.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype=torch.float32</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif.html#LIFCell.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif.LIFCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.lif.LIFConstantCurrentEncoder">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.lif.</code><code class="sig-name descname">LIFConstantCurrentEncoder</code><span class="sig-paren">(</span><em class="sig-param">seq_length</em>, <em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em>, <em class="sig-param">device='cpu'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif.html#LIFConstantCurrentEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif.LIFConstantCurrentEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="norse.torch.module.lif.LIFConstantCurrentEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif.html#LIFConstantCurrentEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif.LIFConstantCurrentEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.lif.LIFFeedForwardCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.lif.</code><code class="sig-name descname">LIFFeedForwardCell</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif.html#LIFFeedForwardCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif.LIFFeedForwardCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module that computes a single euler-integration step of a LIF neuron.
It takes as input the input current as generated by an arbitrary torch
module or function. More specifically it implements one integration step
of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[i = i + i_{\text{in}}\]</div>
<p>where <span class="math notranslate nohighlight">\(i_{\text{in}}\)</span> is meant to be the result of applying
an arbitrary pytorch module (such as a convolution) to input spikes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> – Shape of the feedforward state.</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – Parameters of the LIF neuron model.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Time step to use.</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">LIFFeedForwardCell</span><span class="p">((</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="o">.</span><span class="n">initial_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">s0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="norse.torch.module.lif.LIFFeedForwardCell.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif.html#LIFFeedForwardCell.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif.LIFFeedForwardCell.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should reimplement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.lif.LIFFeedForwardCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif.html#LIFFeedForwardCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif.LIFFeedForwardCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.lif.LIFFeedForwardCell.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif.html#LIFFeedForwardCell.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif.LIFFeedForwardCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFFeedForwardState</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.lif.LIFLayer">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.lif.</code><code class="sig-name descname">LIFLayer</code><span class="sig-paren">(</span><em class="sig-param">*cell_args</em>, <em class="sig-param">**kw_args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif.html#LIFLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif.LIFLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="norse.torch.module.lif.LIFLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif.html#LIFLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif.LIFLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-norse.torch.module.lif_correlation">
<span id="norse-torch-module-lif-correlation-module"></span><h2>norse.torch.module.lif_correlation module<a class="headerlink" href="#module-norse.torch.module.lif_correlation" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.module.lif_correlation.LIFCorrelation">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.lif_correlation.</code><code class="sig-name descname">LIFCorrelation</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFCorrelationParameters(lif_parameters=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">input_correlation_parameters=CorrelationSensorParameters(eta_p=tensor(1.)</em>, <em class="sig-param">eta_m=tensor(1.)</em>, <em class="sig-param">tau_ac_inv=tensor(10.)</em>, <em class="sig-param">tau_c_inv=tensor(10.))</em>, <em class="sig-param">recurrent_correlation_parameters=CorrelationSensorParameters(eta_p=tensor(1.)</em>, <em class="sig-param">eta_m=tensor(1.)</em>, <em class="sig-param">tau_ac_inv=tensor(10.)</em>, <em class="sig-param">tau_c_inv=tensor(10.)))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_correlation.html#LIFCorrelation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_correlation.LIFCorrelation" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="norse.torch.module.lif_correlation.LIFCorrelation.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">recurrent_weights</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_correlation.html#LIFCorrelation.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_correlation.LIFCorrelation.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif_correlation.LIFCorrelationState" title="norse.torch.functional.lif_correlation.LIFCorrelationState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFCorrelationState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.lif_correlation.LIFCorrelation.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype=torch.float32</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_correlation.html#LIFCorrelation.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_correlation.LIFCorrelation.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif_correlation.LIFCorrelationState" title="norse.torch.functional.lif_correlation.LIFCorrelationState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFCorrelationState</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-norse.torch.module.lif_mc">
<span id="norse-torch-module-lif-mc-module"></span><h2>norse.torch.module.lif_mc module<a class="headerlink" href="#module-norse.torch.module.lif_mc" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.module.lif_mc.LIFMCCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.lif_mc.</code><code class="sig-name descname">LIFMCCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_mc.html#LIFMCCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_mc.LIFMCCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Computes a single euler-integration step of a LIF multi-compartment
neuron-model.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}}             - g_{\text{coupling}} v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><em>LIFState</em></a>) – current state of the neuron</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for incoming spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>g_coupling</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – conductances between the neuron compartments</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – neuron parameters</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="norse.torch.module.lif_mc.LIFMCCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_mc.html#LIFMCCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_mc.LIFMCCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.lif_mc.LIFMCCell.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype=torch.float32</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_mc.html#LIFMCCell.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_mc.LIFMCCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-norse.torch.module.lif_mc_refrac">
<span id="norse-torch-module-lif-mc-refrac-module"></span><h2>norse.torch.module.lif_mc_refrac module<a class="headerlink" href="#module-norse.torch.module.lif_mc_refrac" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.module.lif_mc_refrac.LIFMCRefracCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.lif_mc_refrac.</code><code class="sig-name descname">LIFMCRefracCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">rho_reset=tensor(5.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_mc_refrac.html#LIFMCRefracCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_mc_refrac.LIFMCRefracCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="norse.torch.module.lif_mc_refrac.LIFMCRefracCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_mc_refrac.html#LIFMCRefracCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_mc_refrac.LIFMCRefracCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.lif_mc_refrac.LIFMCRefracCell.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype=torch.float32</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_mc_refrac.html#LIFMCRefracCell.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_mc_refrac.LIFMCRefracCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracState</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-norse.torch.module.lif_refrac">
<span id="norse-torch-module-lif-refrac-module"></span><h2>norse.torch.module.lif_refrac module<a class="headerlink" href="#module-norse.torch.module.lif_refrac" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.module.lif_refrac.LIFRefracCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.lif_refrac.</code><code class="sig-name descname">LIFRefracCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">p=LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">rho_reset=tensor(5.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_refrac.html#LIFRefracCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_refrac.LIFRefracCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module that computes a single euler-integration step of a LIF
neuron-model with absolute refractory period. More specifically it
implements one integration step of the following ODE.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (1-\Theta(\rho))             (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{\rho} &amp;= -1/\tau_{\text{refrac}} \Theta(\rho)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    z &amp;= \Theta(v - v_{\text{th}}) \\
    z_r &amp;= \Theta(-\rho)
\end{align*}\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}} \\
    \rho &amp;= \rho + z_r \rho_{\text{reset}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><em>LIFRefracState</em></a>) – state at the current time step</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for incoming spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif_refrac.LIFRefracParameters" title="norse.torch.functional.lif_refrac.LIFRefracParameters"><em>LIFRefracParameters</em></a>) – parameters of the lif neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">LIFRefracCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="o">.</span><span class="n">initial_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">s0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="norse.torch.module.lif_refrac.LIFRefracCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_refrac.html#LIFRefracCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_refrac.LIFRefracCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.lif_refrac.LIFRefracCell.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype=torch.float32</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_refrac.html#LIFRefracCell.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_refrac.LIFRefracCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracState</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.lif_refrac.LIFRefracFeedForwardCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.lif_refrac.</code><code class="sig-name descname">LIFRefracFeedForwardCell</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">p=LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">rho_reset=tensor(5.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_refrac.html#LIFRefracFeedForwardCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_refrac.LIFRefracFeedForwardCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module that computes a single euler-integration step of a
LIF neuron-model with absolute refractory period. More specifically
it implements one integration step of the following ODE.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (1-\Theta(\rho))             (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{\rho} &amp;= -1/\tau_{\text{refrac}} \Theta(\rho)
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    z &amp;= \Theta(v - v_{\text{th}}) \\
    z_r &amp;= \Theta(-\rho)
\end{align*}\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    \rho &amp;= \rho + z_r \rho_{\text{reset}}
\end{align*}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>shape</strong> – Shape of the processed spike input</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif_refrac.LIFRefracParameters" title="norse.torch.functional.lif_refrac.LIFRefracParameters"><em>LIFRefracParameters</em></a>) – parameters of the lif neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lif</span> <span class="o">=</span> <span class="n">LIFRefracFeedForwardCell</span><span class="p">((</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="o">.</span><span class="n">initial_state</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">s0</span> <span class="o">=</span> <span class="n">lif</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">s0</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="norse.torch.module.lif_refrac.LIFRefracFeedForwardCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_refrac.html#LIFRefracFeedForwardCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_refrac.LIFRefracFeedForwardCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif_refrac.LIFRefracFeedForwardState" title="norse.torch.functional.lif_refrac.LIFRefracFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.lif_refrac.LIFRefracFeedForwardCell.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lif_refrac.html#LIFRefracFeedForwardCell.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lif_refrac.LIFRefracFeedForwardCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFFeedForwardState</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-norse.torch.module.lsnn">
<span id="norse-torch-module-lsnn-module"></span><h2>norse.torch.module.lsnn module<a class="headerlink" href="#module-norse.torch.module.lsnn" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.module.lsnn.LSNNCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.lsnn.</code><code class="sig-name descname">LSNNCell</code><span class="sig-paren">(</span><em class="sig-param">input_features</em>, <em class="sig-param">output_features</em>, <em class="sig-param">p=LSNNParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">tau_adapt_inv=tensor(0.0014)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">beta=tensor(1.8000)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=100.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lsnn.html#LSNNCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lsnn.LSNNCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module that computes a single euler-integration step of a LSNN
neuron-model. More specifically it implements one integration step of
the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\begin{align*}
    \dot{v} &amp;= 1/\\tau_{\\text{mem}} (v_{\\text{leak}} - v + i) \\\\
    \dot{i} &amp;= -1/\\tau_{\\text{syn}} i \\\\
    \dot{b} &amp;= -1/\\tau_{b} b
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[\begin{split}z = \Theta(v - v_{\\text{th}} + b)\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\begin{align*}
    v &amp;= (1-z) v + z v_{\\text{reset}} \\\\
    i &amp;= i + w_{\\text{input}} z_{\\text{in}} \\\\
    i &amp;= i + w_{\\text{rec}} z_{\\text{rec}} \\\\
    b &amp;= b + \\beta z
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\\text{in}}\)</span> are the
recurrent and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><em>LSNNState</em></a>) – current state of the lsnn unit</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for input spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lsnn.LSNNParameters" title="norse.torch.functional.lsnn.LSNNParameters"><em>LSNNParameters</em></a>) – parameters of the lsnn unit</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="norse.torch.module.lsnn.LSNNCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lsnn.html#LSNNCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lsnn.LSNNCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.lsnn.LSNNCell.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype=torch.float32</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lsnn.html#LSNNCell.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lsnn.LSNNCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><p>return the initial state of an LSNN neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNState</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.lsnn.LSNNFeedForwardCell">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.lsnn.</code><code class="sig-name descname">LSNNFeedForwardCell</code><span class="sig-paren">(</span><em class="sig-param">shape</em>, <em class="sig-param">p=LSNNParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">tau_adapt_inv=tensor(0.0014)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">beta=tensor(1.8000)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=100.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lsnn.html#LSNNFeedForwardCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lsnn.LSNNFeedForwardCell" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Euler integration cell for LIF Neuron with threshold adaptation.
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\\text{syn}} i \\
    \dot{b} &amp;= -1/\tau_{b} b
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}} + b)\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + \text{input} \\
    b &amp;= b + \beta z
\end{align*}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lsnn.LSNNFeedForwardState" title="norse.torch.functional.lsnn.LSNNFeedForwardState"><em>LSNNFeedForwardState</em></a>) – current state of the lsnn unit</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lsnn.LSNNParameters" title="norse.torch.functional.lsnn.LSNNParameters"><em>LSNNParameters</em></a>) – parameters of the lsnn unit</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="norse.torch.module.lsnn.LSNNFeedForwardCell.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lsnn.html#LSNNFeedForwardCell.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lsnn.LSNNFeedForwardCell.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lsnn.LSNNFeedForwardState" title="norse.torch.functional.lsnn.LSNNFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.lsnn.LSNNFeedForwardCell.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype=torch.float32</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lsnn.html#LSNNFeedForwardCell.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lsnn.LSNNFeedForwardCell.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><p>return the initial state of an LSNN neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lsnn.LSNNFeedForwardState" title="norse.torch.functional.lsnn.LSNNFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNFeedForwardState</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.module.lsnn.LSNNLayer">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.module.lsnn.</code><code class="sig-name descname">LSNNLayer</code><span class="sig-paren">(</span><em class="sig-param">cell</em>, <em class="sig-param">*cell_args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lsnn.html#LSNNLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lsnn.LSNNLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl>
<dt>A Long short-term memory neuron module adapted from</dt><dd><p><a class="reference external" href="https://arxiv.org/abs/1803.09574">https://arxiv.org/abs/1803.09574</a></p>
</dd>
<dt>Usage:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">norse.torch.module</span> <span class="kn">import</span> <span class="n">LSNNLayer</span><span class="p">,</span> <span class="n">LSNNCell</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">layer</span> <span class="o">=</span> <span class="n">LSNNLayer</span><span class="p">(</span><span class="n">LSNNCell</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>    <span class="o">//</span> <span class="n">LSNNCell</span> <span class="n">of</span> <span class="n">shape</span> <span class="mi">2</span> <span class="o">-&gt;</span> <span class="mi">10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">state</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">initial_state</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span> <span class="o">//</span> <span class="mi">5</span> <span class="n">batch</span> <span class="n">size</span> <span class="n">running</span> <span class="n">on</span> <span class="n">CPU</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>          <span class="o">//</span> <span class="n">Data</span> <span class="n">of</span> <span class="n">shape</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">new_state</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>cell</strong> (<a class="reference external" href="https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.nn.Module</em></a>) – the underling neuron module, uninitialized</p></li>
<li><p><strong>*cell_args</strong> – variable length input arguments for the underlying cell
constructor</p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="norse.torch.module.lsnn.LSNNLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lsnn.html#LSNNLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lsnn.LSNNLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="norse.torch.module.lsnn.LSNNLayer.initial_state">
<code class="sig-name descname">initial_state</code><span class="sig-paren">(</span><em class="sig-param">batch_size</em>, <em class="sig-param">device</em>, <em class="sig-param">dtype=torch.float32</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/module/lsnn.html#LSNNLayer.initial_state"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.module.lsnn.LSNNLayer.initial_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the initial state of the LSNN layer, as given by the
internal LSNNCell</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="norse.torch.functional.html#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNState</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="module-norse.torch.module">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-norse.torch.module" title="Permalink to this headline">¶</a></h2>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">norse</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_examples/index.html">Beginner tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="experiments.html">Running Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="spiking.html">Introduction to spikes</a></li>
</ul>
<p class="caption"><span class="caption-text">API Docs</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="norse.html">norse package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="norse.task.html">norse.task package</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="norse.torch.html">norse.torch package</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="norse.task.html">norse.task package</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.benchmark.html">norse.torch.benchmark package</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.functional.html">norse.torch.functional package</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.models.html">norse.torch.models package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">norse.torch.module package</a><ul>
<li class="toctree-l2"><a class="reference internal" href="norse.torch.module.test.html">norse.torch.module.test package</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  <li><a href="norse.html">norse package</a><ul>
  <li><a href="norse.torch.html">norse.torch package</a><ul>
      <li>Previous: <a href="norse.torch.models.html" title="previous chapter">norse.torch.models package</a></li>
      <li>Next: <a href="norse.torch.module.test.html" title="next chapter">norse.torch.module.test package</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Norse.ai.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.4.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/norse.torch.module.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>