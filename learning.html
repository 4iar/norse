
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4. Learning with spikes &#8212; norse 0.0.6 documentation</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="5. Papers citing Norse" href="papers.html" />
    <link rel="prev" title="3. Introduction to spikes" href="spiking.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="learning-with-spikes">
<span id="page-spike-learning"></span><h1><span class="section-number">4. </span>Learning with spikes<a class="headerlink" href="#learning-with-spikes" title="Permalink to this headline">¶</a></h1>
<p>To be able to learn in spiking neural networks (SNN) one needs to
update the weights between neurons, as in all types of neural networks.
As you probably know, you need smooth, differentiable functions to
apply popular algorithms like gradient descent and backpropagation.</p>
<p>However, spiking neurons do not have smooth activation functions
(a spike either happens or doesn’t).
This page aims to explain - in an informan manner - how we can train
SNNs in Norse irregardless of their non-differentiable nature.
The general approach is described in better detail by
<a class="reference external" href="https://arxiv.org/abs/1901.09948">Emre O. Neftci, Hesham Mostafa, and Friedemann Zenke</a>.</p>
<p>Before you read further though, make sure you are familiar
with how PyTorch
<a class="reference external" href="https://pytorch.org/tutorials/beginner/pytorch_with_examples.html#autograd">works with Autograd and backpropagation</a>.
Norse is basically applying the same principle.</p>
<div class="section" id="training-spiking-neural-networks">
<h2><span class="section-number">4.1. </span>Training Spiking Neural Networks<a class="headerlink" href="#training-spiking-neural-networks" title="Permalink to this headline">¶</a></h2>
<p>Many solutions have been attempted to solve this problem with varying
success.
Here we will only cover the <em>surrogate gradient</em> approach, and
illustrate how  it is implement in norse.</p>
<p>Our approach builds on the SuperSpike method proposed by
<a href="#id1"><span class="problematic" id="id2">`Steven K. Esser et al. (Convolutional networks for fast, energy-efficient neuromorphic computing)&lt;https://www.pnas.org/content/113/41/11441&gt;`_</span></a> and
further elaborated in
<a class="reference external" href="https://www.mitpressjournals.org/doi/pdf/10.1162/neco_a_01086">Friedemann Zenke and Surya Ganguli</a>.</p>
<p>Neurons work in the way that they update their membrane equations with
incoming currents from pre-synaptic neurons.
If the incoming currents exceed a threshold, the post-synaptic
neuron releases a spike.
Hhis can easily be expressed in code:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>if membrane &gt; threshold: spike!
</pre></div>
</div>
<p>However, what happens when you take the gradient of that? It will be
zero for the most part because <code class="docutils literal notranslate"><span class="pre">membrane</span> <span class="pre">&lt;</span> <span class="pre">threshold</span></code>, meaning that
the neuron does not influence the output at all.
But sometimes the current goes above the threshold, you get an
activation, and the gradient changes!
To account for that, we can “pretend” that the gradient doesn’t
have this awkward sudden shift.
Instead, we can look at the numerical state of the neuron and then
use that as an indicator for how much the neuron influenced the
output.</p>
<p>Given the neuron membrane potential (<span class="math notranslate nohighlight">\(U\)</span>) and the neuron firing
threshold (<span class="math notranslate nohighlight">\(v\)</span>), then this is a simplified version of the
SuperSpike surrogate partial derivative for some activation
function (<span class="math notranslate nohighlight">\(\sigma\)</span>):</p>
<div class="math notranslate nohighlight">
\[\sigma '(U_i) = \left(1 + |U_i - v| \right)^{-2}\]</div>
<p>In the SuperSpike algorithm, we look at the <em>difference</em> between the
neuron membrane and the firing threshold.
If, say, the neuron membrane voltage is much higher than the
firing threshold, we know that the neuron <cite>will</cite> fire.
But too far away from that threshold indicates that the contribution
of the neuron is unimportant because it would require a large
modification to that particular neuron to <em>not</em> impact the output.</p>
<p>Conversely, if the the neuron membrane voltage is much lower
than the threshold, the neuron is probably not
going to fire, and the gradient contribution is equally low.</p>
<p>And that’s it! SuperSpike permits the calculation of gradients for
non-differentiable functions.
Which, in turn, permits us to use the native autograd properties
of PyTorch.</p>
<p>An implementation of the SuperSpike algorithm in Norse can be found
in the
<a class="reference external" href="https://github.com/norse/norse/blob/master/norse/torch/functional/threshold.py">threshold.py</a>
module.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="index.html">
    <img class="logo" src="_static/logo.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">A library to do deep learning with spiking neural networks.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=norse&repo=norse&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<p class="caption"><span class="caption-text">First steps</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">∇ Home</a></li>
<li class="toctree-l1"><a class="reference internal" href="installing.html">1. Installing Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="started.html">2. Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks.html">3. Running Tasks</a></li>
</ul>
<p class="caption"><span class="caption-text">Usage docs</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="about.html">1. About Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware.html">2. Hardware acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="spiking.html">3. Introduction to spikes</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">4. Learning with spikes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#training-spiking-neural-networks">4.1. Training Spiking Neural Networks</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="papers.html">5. Papers citing Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="working.html">6. Working with Norse</a></li>
</ul>
<p class="caption"><span class="caption-text">API Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_api/norse.benchmark.html">norse.benchmark package</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_api/norse.task.html">norse.task package</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_api/norse.torch.html">norse.torch package</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="spiking.html" title="previous chapter"><span class="section-number">3. </span>Introduction to spikes</a></li>
      <li>Next: <a href="papers.html" title="next chapter"><span class="section-number">5. </span>Papers citing Norse</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019 - 2021, Norse.ai.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.5.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/learning.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>