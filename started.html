
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Getting started &#8212; norse 0.0.6 documentation</title>
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/custom.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="author" title="About these documents" href="about.html" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="2. Installing Norse" href="installing.html" />
    <link rel="prev" title="Norse" href="index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="getting-started">
<span id="page-started"></span><h1><span class="section-number">1. </span>Getting started<a class="headerlink" href="#getting-started" title="Permalink to this headline">¶</a></h1>
<p>This page walks you through the initial steps to becoming productive with Norse.
We will cover how to</p>
<ul class="simple">
<li><p>Work with neuron state</p></li>
<li><p>Work with Norse without time</p></li>
<li><p>Work with Norse with time</p></li>
<li><p>Work with Norse with recurrence</p></li>
</ul>
<p>If you are entirely unfamiliar with <a class="reference external" href="https://en.wikipedia.org/wiki/Spiking_neural_network">spiking neural networks (SNNs)</a>
we recommend you skim our page that introduces the topic: <a class="reference internal" href="spiking.html#page-spiking"><span class="std std-ref">Introduction to spikes</span></a>.</p>
<div class="section" id="running-off-the-shelf-code">
<h2><span class="section-number">1.1. </span>Running off-the-shelf code<a class="headerlink" href="#running-off-the-shelf-code" title="Permalink to this headline">¶</a></h2>
<p>If you just want to get started we recommend our <a class="reference external" href="https://github.com/norse/notebooks/">collection of Jupyter Notebook Tutorials</a>.
They can be run online on Google Colab.</p>
<p>Additionally, we provide a set of tasks that you can run right after installing Norse.
One of the most common experiments is the <a class="reference external" href="https://en.wikipedia.org/wiki/MNIST_database">MNIST</a>
classification task.
Norse achieve on-par performance with modern non-spiking networks:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python -m norse.task.mnist
</pre></div>
</div>
<p>Please refer to <a class="reference internal" href="tasks.html#page-tasks"><span class="std std-ref">Running Tasks</span></a> for more tasks and detailed information on how to
run them.</p>
</div>
<div class="section" id="building-neural-networks-with-state">
<h2><span class="section-number">1.2. </span>Building neural networks with state<a class="headerlink" href="#building-neural-networks-with-state" title="Permalink to this headline">¶</a></h2>
<p>If you would like to build your own models with Norse you need to know that <strong>neurons contain state</strong>.
In practice, that meant that <strong>neurons in Norse outputs two things</strong>: a spike tensor and the neuron state.
Norse initialises all the necessary state for you <em>in the beginning</em>, but you need
to carry the state onwards.
If you do not, the state will always be zero, the neuron will never spike and your neurons will be
forever dead!</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">norse.torch</span> <span class="k">as</span> <span class="nn">norse</span>

<span class="n">cell</span> <span class="o">=</span> <span class="n">norse</span><span class="o">.</span><span class="n">LIFCell</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">norse</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">spikes</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">cell</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>The <em>next</em> time you call the cell, you need to pass in that state.
Otherwise you will get the exact same output</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spikes</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">cell</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</pre></div>
</div>
<p><em>Note</em>: This is similar to PyTorch’s <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.RNN.html#torch.nn.RNN">RNN module</a>
if you are looking for inspiration.</p>
</div>
<div class="section" id="using-norse-neurons-with-time">
<h2><span class="section-number">1.3. </span>Using Norse neurons with time<a class="headerlink" href="#using-norse-neurons-with-time" title="Permalink to this headline">¶</a></h2>
<p>Similar to PyTorch’s <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html">Sequential</a>,
Norse’s neuron models can be chained in a network.
Unfortunately, this does not work with neurons for the same reason that it does
not work with PyTorch’s own RNNs: state.
Instead, Norse offers a <a class="reference external" href="https://norse.github.io/norse/auto_api/norse.torch.module.sequential.html">SequentialState</a>
module that ties stateful modules together:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">norse.torch</span> <span class="k">as</span> <span class="nn">norse</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SequentialState</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="n">norse</span><span class="o">.</span><span class="n">LIFCell</span><span class="p">(),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># (batch, input)</span>

<span class="n">out</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>You can do the same for other neuron types like the
<a class="reference external" href="https://norse.github.io/norse/auto_api/norse.torch.module.lsnn.html">LSNN</a>,
<a class="reference external" href="https://norse.github.io/norse/auto_api/norse.torch.module.lif_adex.html">LIFAdEx</a>, etc.</p>
</div>
<div class="section" id="using-norse-in-time">
<h2><span class="section-number">1.4. </span>Using Norse in time<a class="headerlink" href="#using-norse-in-time" title="Permalink to this headline">¶</a></h2>
<p>The above <a href="#id1"><span class="problematic" id="id2">``</span></a>XCell``s follow the abstraction from PyTorch where the cells are “simple”
activation functions that is applied once.
However, neurons exist in time and will need to be given at least a few timesteps of
input before something interesting happens (like a spike).</p>
<p>The network above (the one without time) works perfectly well with time, and you can
easily wrap it with a for loop. However, it’s also possible to run each module
individually in time.</p>
<p>For LSNNs, the simplest way to go about this is to use the
<a class="reference external" href="https://norse.github.io/norse/auto_api/norse.torch.module.lsnn.html">LSNN module</a>.
You can then <strong>lift</strong> the regular
PyTorch modules into the time domain (that is, simply run them once for every
timestep):</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">norse.torch</span> <span class="k">as</span> <span class="nn">norse</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SequentialState</span><span class="p">(</span>
    <span class="n">norse</span><span class="o">.</span><span class="n">Lift</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span>
    <span class="n">norse</span><span class="o">.</span><span class="n">LSNNRecurrent</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="n">norse</span><span class="o">.</span><span class="n">Lift</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># (time, batch, input)</span>
<span class="n">out</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="using-norse-neurons-with-recurrence">
<h2><span class="section-number">1.5. </span>Using Norse neurons with recurrence<a class="headerlink" href="#using-norse-neurons-with-recurrence" title="Permalink to this headline">¶</a></h2>
<p>Finally, neurons are known to be recurrent. Meaning, one population <em>can</em> connect
to themselves. In the <code class="docutils literal notranslate"><span class="pre">Cell</span></code> example (without time) we simply suffix the neuron
with the word <code class="docutils literal notranslate"><span class="pre">Recurrent</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">norse.torch</span> <span class="k">as</span> <span class="nn">norse</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SequentialState</span><span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="n">norse</span><span class="o">.</span><span class="n">LIFRecurrentCell</span><span class="p">(),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># (batch, input)</span>

<span class="n">out</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>In the example with time, the same logic applies:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">norse.torch</span> <span class="k">as</span> <span class="nn">norse</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">SequentialState</span><span class="p">(</span>
    <span class="n">norse</span><span class="o">.</span><span class="n">Lift</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">)),</span>
    <span class="n">norse</span><span class="o">.</span><span class="n">LSNNRecurrent</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span>
    <span class="n">norse</span><span class="o">.</span><span class="n">Lift</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="c1"># (time, batch, input)</span>
<span class="n">out</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
<p>This covers the most basic way to apply Norse. More information can be found
in <a class="reference internal" href="spiking.html#page-spiking"><span class="std std-ref">Introduction to spikes</span></a>, <a class="reference internal" href="working.html#page-working"><span class="std std-ref">Working with Norse</span></a> and <a class="reference internal" href="learning.html#page-spike-learning"><span class="std std-ref">Learning with spikes</span></a>.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="index.html">
    <img class="logo" src="_static/logo.png" alt="Logo"/>
    
  </a>
</p>



<p class="blurb">A library to do deep learning with spiking neural networks.</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=norse&repo=norse&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<p class="caption"><span class="caption-text">First steps</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">∇ Home</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#getting-started">Getting started</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#installing-norse">Installing Norse</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#running-tasks">Running Tasks</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#advanced-uses-and-opimizations">Advanced uses and opimizations</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#about-norse">About Norse</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html#table-of-contents">Table of contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#indices-and-tables">Indices and tables</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">1. Getting started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#running-off-the-shelf-code">1.1. Running off-the-shelf code</a></li>
<li class="toctree-l2"><a class="reference internal" href="#building-neural-networks-with-state">1.2. Building neural networks with state</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-norse-neurons-with-time">1.3. Using Norse neurons with time</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-norse-in-time">1.4. Using Norse in time</a></li>
<li class="toctree-l2"><a class="reference internal" href="#using-norse-neurons-with-recurrence">1.5. Using Norse neurons with recurrence</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installing.html">2. Installing Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="tasks.html">3. Running Tasks</a></li>
</ul>
<p class="caption"><span class="caption-text">Usage docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="about.html">1. About Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="hardware.html">2. Hardware acceleration</a></li>
<li class="toctree-l1"><a class="reference internal" href="spiking.html">3. Introduction to spikes</a></li>
<li class="toctree-l1"><a class="reference internal" href="learning.html">4. Learning with spikes</a></li>
<li class="toctree-l1"><a class="reference internal" href="papers.html">5. Papers citing Norse</a></li>
<li class="toctree-l1"><a class="reference internal" href="working.html">6. Working with Norse</a></li>
</ul>
<p class="caption"><span class="caption-text">API Docs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_api/norse.benchmark.html">norse.benchmark package</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_api/norse.task.html">norse.task package</a></li>
<li class="toctree-l1"><a class="reference internal" href="auto_api/norse.torch.html">norse.torch package</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
      <li>Previous: <a href="index.html" title="previous chapter">Norse</a></li>
      <li>Next: <a href="installing.html" title="next chapter"><span class="section-number">2. </span>Installing Norse</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Norse.ai.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.5.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/started.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>