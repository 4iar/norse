
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>norse.torch.functional package &#8212; norse 0.0.2 documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="_static/gallery-dataframe.css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="norse.torch.models package" href="norse.torch.models.html" />
    <link rel="prev" title="norse.torch.benchmark package" href="norse.torch.benchmark.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="norse-torch-functional-package">
<h1>norse.torch.functional package<a class="headerlink" href="#norse-torch-functional-package" title="Permalink to this headline">¶</a></h1>
<div class="section" id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="module-norse.torch.functional.coba_lif">
<span id="norse-torch-functional-coba-lif-module"></span><h2>norse.torch.functional.coba_lif module<a class="headerlink" href="#module-norse.torch.functional.coba_lif" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.functional.coba_lif.CobaLIFFeedForwardState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.coba_lif.</code><code class="sig-name descname">CobaLIFFeedForwardState</code><a class="reference internal" href="_modules/norse/torch/functional/coba_lif.html#CobaLIFFeedForwardState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a conductance based feed forward LIF neuron.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>g_e</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – excitatory input conductance</p></li>
<li><p><strong>g_i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – inhibitory input conductance</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFFeedForwardState.g_e">
<code class="sig-name descname">g_e</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFFeedForwardState.g_e" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFFeedForwardState.g_i">
<code class="sig-name descname">g_i</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFFeedForwardState.g_i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFFeedForwardState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFFeedForwardState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.coba_lif.CobaLIFParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.coba_lif.</code><code class="sig-name descname">CobaLIFParameters</code><a class="reference internal" href="_modules/norse/torch/functional/coba_lif.html#CobaLIFParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of conductance based LIF neuron.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau_syn_exc_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – inverse excitatory synaptic input
time constant</p></li>
<li><p><strong>tau_syn_inh_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – inverse inhibitory synaptic input
time constant</p></li>
<li><p><strong>c_m_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – inverse membrane capacitance</p></li>
<li><p><strong>g_l</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – leak conductance</p></li>
<li><p><strong>e_rev_I</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – inhibitory reversal potential</p></li>
<li><p><strong>e_rev_E</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – excitatory reversal potential</p></li>
<li><p><strong>v_rest</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – rest membrane potential</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – reset membrane potential</p></li>
<li><p><strong>v_thresh</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – threshold membrane potential</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – method to determine the spike threshold
(relevant for surrogate gradients)</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – hyper parameter to use in surrogate gradient computation</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFParameters.alpha">
<code class="sig-name descname">alpha</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 10</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFParameters.c_m_inv">
<code class="sig-name descname">c_m_inv</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFParameters.c_m_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFParameters.e_rev_E">
<code class="sig-name descname">e_rev_E</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFParameters.e_rev_E" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFParameters.e_rev_I">
<code class="sig-name descname">e_rev_I</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFParameters.e_rev_I" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFParameters.g_l">
<code class="sig-name descname">g_l</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFParameters.g_l" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFParameters.method">
<code class="sig-name descname">method</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 9</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFParameters.tau_syn_exc_inv">
<code class="sig-name descname">tau_syn_exc_inv</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFParameters.tau_syn_exc_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFParameters.tau_syn_inh_inv">
<code class="sig-name descname">tau_syn_inh_inv</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFParameters.tau_syn_inh_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFParameters.v_reset">
<code class="sig-name descname">v_reset</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFParameters.v_rest">
<code class="sig-name descname">v_rest</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFParameters.v_rest" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFParameters.v_thresh">
<code class="sig-name descname">v_thresh</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFParameters.v_thresh" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 8</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.coba_lif.CobaLIFState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.coba_lif.</code><code class="sig-name descname">CobaLIFState</code><a class="reference internal" href="_modules/norse/torch/functional/coba_lif.html#CobaLIFState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a conductance based LIF neuron.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>g_e</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – excitatory input conductance</p></li>
<li><p><strong>g_i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – inhibitory input conductance</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFState.g_e">
<code class="sig-name descname">g_e</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFState.g_e" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFState.g_i">
<code class="sig-name descname">g_i</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFState.g_i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.coba_lif.CobaLIFState.z">
<code class="sig-name descname">z</code><a class="headerlink" href="#norse.torch.functional.coba_lif.CobaLIFState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.coba_lif.coba_lif_feed_forward_step">
<code class="sig-prename descclassname">norse.torch.functional.coba_lif.</code><code class="sig-name descname">coba_lif_feed_forward_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">p=CobaLIFParameters(tau_syn_exc_inv=tensor(0.2000)</em>, <em class="sig-param">tau_syn_inh_inv=tensor(0.2000)</em>, <em class="sig-param">c_m_inv=tensor(5.)</em>, <em class="sig-param">g_l=tensor(0.2500)</em>, <em class="sig-param">e_rev_I=tensor(-100)</em>, <em class="sig-param">e_rev_E=tensor(60)</em>, <em class="sig-param">v_rest=tensor(-20)</em>, <em class="sig-param">v_reset=tensor(-70)</em>, <em class="sig-param">v_thresh=tensor(-10)</em>, <em class="sig-param">method='heaviside'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/coba_lif.html#coba_lif_feed_forward_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.coba_lif.coba_lif_feed_forward_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Euler integration step for a conductance based LIF neuron.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic input</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.coba_lif.CobaLIFFeedForwardState" title="norse.torch.functional.coba_lif.CobaLIFFeedForwardState"><em>CobaLIFFeedForwardState</em></a>) – current state of the neuron</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.coba_lif.CobaLIFParameters" title="norse.torch.functional.coba_lif.CobaLIFParameters"><em>CobaLIFParameters</em></a>) – parameters of the neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration time step</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.coba_lif.CobaLIFFeedForwardState" title="norse.torch.functional.coba_lif.CobaLIFFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">CobaLIFFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.coba_lif.coba_lif_step">
<code class="sig-prename descclassname">norse.torch.functional.coba_lif.</code><code class="sig-name descname">coba_lif_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">recurrent_weights</em>, <em class="sig-param">p=CobaLIFParameters(tau_syn_exc_inv=tensor(0.2000)</em>, <em class="sig-param">tau_syn_inh_inv=tensor(0.2000)</em>, <em class="sig-param">c_m_inv=tensor(5.)</em>, <em class="sig-param">g_l=tensor(0.2500)</em>, <em class="sig-param">e_rev_I=tensor(-100)</em>, <em class="sig-param">e_rev_E=tensor(60)</em>, <em class="sig-param">v_rest=tensor(-20)</em>, <em class="sig-param">v_reset=tensor(-70)</em>, <em class="sig-param">v_thresh=tensor(-10)</em>, <em class="sig-param">method='heaviside'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/coba_lif.html#coba_lif_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.coba_lif.coba_lif_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Euler integration step for a conductance based LIF neuron.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.coba_lif.CobaLIFState" title="norse.torch.functional.coba_lif.CobaLIFState"><em>CobaLIFState</em></a>) – current state of the neuron</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – input weights
(sign determines  contribution to inhibitory / excitatory input)</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – recurrent weights
(sign determines contribution to inhibitory / excitatory input)</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.coba_lif.CobaLIFParameters" title="norse.torch.functional.coba_lif.CobaLIFParameters"><em>CobaLIFParameters</em></a>) – parameters of the neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration time step</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.coba_lif.CobaLIFState" title="norse.torch.functional.coba_lif.CobaLIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">CobaLIFState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.correlation_sensor">
<span id="norse-torch-functional-correlation-sensor-module"></span><h2>norse.torch.functional.correlation_sensor module<a class="headerlink" href="#module-norse.torch.functional.correlation_sensor" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.functional.correlation_sensor.CorrelationSensorParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.correlation_sensor.</code><code class="sig-name descname">CorrelationSensorParameters</code><span class="sig-paren">(</span><em class="sig-param">eta_p</em>, <em class="sig-param">eta_m</em>, <em class="sig-param">tau_ac_inv</em>, <em class="sig-param">tau_c_inv</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/correlation_sensor.html#CorrelationSensorParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.correlation_sensor.CorrelationSensorParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<dl class="attribute">
<dt id="norse.torch.functional.correlation_sensor.CorrelationSensorParameters.eta_m">
<code class="sig-name descname">eta_m</code><a class="headerlink" href="#norse.torch.functional.correlation_sensor.CorrelationSensorParameters.eta_m" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.correlation_sensor.CorrelationSensorParameters.eta_p">
<code class="sig-name descname">eta_p</code><a class="headerlink" href="#norse.torch.functional.correlation_sensor.CorrelationSensorParameters.eta_p" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.correlation_sensor.CorrelationSensorParameters.tau_ac_inv">
<code class="sig-name descname">tau_ac_inv</code><a class="headerlink" href="#norse.torch.functional.correlation_sensor.CorrelationSensorParameters.tau_ac_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.correlation_sensor.CorrelationSensorParameters.tau_c_inv">
<code class="sig-name descname">tau_c_inv</code><a class="headerlink" href="#norse.torch.functional.correlation_sensor.CorrelationSensorParameters.tau_c_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.correlation_sensor.CorrelationSensorState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.correlation_sensor.</code><code class="sig-name descname">CorrelationSensorState</code><span class="sig-paren">(</span><em class="sig-param">post_pre</em>, <em class="sig-param">correlation_trace</em>, <em class="sig-param">anti_correlation_trace</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/correlation_sensor.html#CorrelationSensorState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.correlation_sensor.CorrelationSensorState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<dl class="attribute">
<dt id="norse.torch.functional.correlation_sensor.CorrelationSensorState.anti_correlation_trace">
<code class="sig-name descname">anti_correlation_trace</code><a class="headerlink" href="#norse.torch.functional.correlation_sensor.CorrelationSensorState.anti_correlation_trace" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.correlation_sensor.CorrelationSensorState.correlation_trace">
<code class="sig-name descname">correlation_trace</code><a class="headerlink" href="#norse.torch.functional.correlation_sensor.CorrelationSensorState.correlation_trace" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.correlation_sensor.CorrelationSensorState.post_pre">
<code class="sig-name descname">post_pre</code><a class="headerlink" href="#norse.torch.functional.correlation_sensor.CorrelationSensorState.post_pre" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.correlation_sensor.correlation_based_update">
<code class="sig-prename descclassname">norse.torch.functional.correlation_sensor.</code><code class="sig-name descname">correlation_based_update</code><span class="sig-paren">(</span><em class="sig-param">ts</em>, <em class="sig-param">linear_update</em>, <em class="sig-param">weights</em>, <em class="sig-param">correlation_state</em>, <em class="sig-param">learning_rate</em>, <em class="sig-param">ts_frequency</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/correlation_sensor.html#correlation_based_update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.correlation_sensor.correlation_based_update" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.correlation_sensor.correlation_sensor_step">
<code class="sig-prename descclassname">norse.torch.functional.correlation_sensor.</code><code class="sig-name descname">correlation_sensor_step</code><span class="sig-paren">(</span><em class="sig-param">z_pre</em>, <em class="sig-param">z_post</em>, <em class="sig-param">s</em>, <em class="sig-param">p=CorrelationSensorParameters(eta_p=tensor(1.)</em>, <em class="sig-param">eta_m=tensor(1.)</em>, <em class="sig-param">tau_ac_inv=tensor(10.)</em>, <em class="sig-param">tau_c_inv=tensor(10.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/correlation_sensor.html#correlation_sensor_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.correlation_sensor.correlation_sensor_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Euler integration step of an idealized version of the correlation sensor
as it is present on the BrainScaleS 2 chips.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#norse.torch.functional.correlation_sensor.CorrelationSensorState" title="norse.torch.functional.correlation_sensor.CorrelationSensorState"><code class="xref py py-class docutils literal notranslate"><span class="pre">CorrelationSensorState</span></code></a></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.encode">
<span id="norse-torch-functional-encode-module"></span><h2>norse.torch.functional.encode module<a class="headerlink" href="#module-norse.torch.functional.encode" title="Permalink to this headline">¶</a></h2>
<p>Stateless encoding functionality for Norse, offering different ways to convert numerical
inputs to the spiking domain. Note that some functions, like <cite>population_encode</cite> does not return spikes,
but rather numerical values that will have to be converted into spikes via, for instance, the poisson encoder.</p>
<p>The probability models builds on top of the PyTorch distributions package: <a class="reference external" href="https://arxiv.org/abs/1711.10604">https://arxiv.org/abs/1711.10604</a></p>
<dl class="function">
<dt id="norse.torch.functional.encode.constant_current_lif_encode">
<code class="sig-prename descclassname">norse.torch.functional.encode.</code><code class="sig-name descname">constant_current_lif_encode</code><span class="sig-paren">(</span><em class="sig-param">input_current</em>, <em class="sig-param">seq_length</em>, <em class="sig-param">parameters=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/encode.html#constant_current_lif_encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.encode.constant_current_lif_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes input currents as fixed (constant) voltage currents, and simulates the spikes that
occur during a number of timesteps/iterations (seq_length).</p>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">seq_length</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># Simulate two iterations</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">constant_current_lif_encode</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">seq_length</span><span class="p">)</span>
<span class="go">(tensor([[0.2000, 0.4000, 0.8000, 0.0000],   # State in terms of membrane voltage</span>
<span class="go">         [0.3800, 0.7600, 0.0000, 0.0000]]),</span>
<span class="go"> tensor([[0., 0., 0., 1.],                   # Spikes for each iteration</span>
<span class="go">         [0., 0., 1., 1.]]))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_current</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – The input tensor, representing LIF current</p></li>
<li><p><strong>seq_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of iterations to simulate</p></li>
<li><p><strong>parameters</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – Initial neuron parameters. Defaults to zero.</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – </p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Time delta between simulation steps</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.encode.euclidean_distance">
<code class="sig-prename descclassname">norse.torch.functional.encode.</code><code class="sig-name descname">euclidean_distance</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/encode.html#euclidean_distance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.encode.euclidean_distance" title="Permalink to this definition">¶</a></dt>
<dd><p>Simple euclidean distance metric.</p>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.encode.gaussian_rbf">
<code class="sig-prename descclassname">norse.torch.functional.encode.</code><code class="sig-name descname">gaussian_rbf</code><span class="sig-paren">(</span><em class="sig-param">tensor</em>, <em class="sig-param">sigma=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/encode.html#gaussian_rbf"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.encode.gaussian_rbf" title="Permalink to this definition">¶</a></dt>
<dd><blockquote>
<div><p>A <a class="reference external" href="https://en.wikipedia.org/wiki/Radial_basis_function_kernel">gaussian radial basis kernel</a>
that calculates the radial basis given a distance value (distance between <span class="math notranslate nohighlight">\(x\)</span> and a data
value <span class="math notranslate nohighlight">\(x'\)</span>, or <span class="math notranslate nohighlight">\(\|\mathbf{x} - \mathbf{x'}\|^2\)</span> below).</p>
<div class="math notranslate nohighlight">
\[K(\mathbf{x}, \mathbf{x'}) = \exp\left(-\]</div>
</div></blockquote>
<p>rac{|mathbf{x} - mathbf{x’}|^2}{2sigma^2}
ight)</p>
<blockquote>
<div><dl class="simple">
<dt>Parameters:</dt><dd><p>tensor (torch.Tensor): The tensor containing distance values to convert to radial bases
sigma (float): The spread of the gaussian distribution. Defaults to 1.</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.encode.poisson_encode">
<code class="sig-prename descclassname">norse.torch.functional.encode.</code><code class="sig-name descname">poisson_encode</code><span class="sig-paren">(</span><em class="sig-param">input_values</em>, <em class="sig-param">seq_length</em>, <em class="sig-param">f_max=100</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/encode.html#poisson_encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.encode.poisson_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes a tensor of input values, which are assumed to be in the
range [0,1] into a tensor of one dimension higher of binary values,
which represent input spikes.</p>
<p>See for example <a class="reference external" href="https://www.cns.nyu.edu/~david/handouts/poisson.pdf">https://www.cns.nyu.edu/~david/handouts/poisson.pdf</a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_values</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – Input data tensor with values assumed to be in the interval [0,1].</p></li>
<li><p><strong>sequence_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – Number of time steps in the resulting spike train.</p></li>
<li><p><strong>f_max</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Maximal frequency (in Hertz) which will be emitted.</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration time step (should coincide with the integration time step used in the model)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.encode.population_encode">
<code class="sig-prename descclassname">norse.torch.functional.encode.</code><code class="sig-name descname">population_encode</code><span class="sig-paren">(</span><em class="sig-param">input_values</em>, <em class="sig-param">out_features</em>, <em class="sig-param">scale=None</em>, <em class="sig-param">kernel=&lt;function gaussian_rbf&gt;</em>, <em class="sig-param">distance_function=&lt;function euclidean_distance&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/encode.html#population_encode"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.encode.population_encode" title="Permalink to this definition">¶</a></dt>
<dd><p>Encodes a set of input values into population codes, such that each singular input value is represented by
a list of numbers (typically calculated by a radial basis kernel), whose length is equal to the out_features.</p>
<p>Population encoding can be visualised by imagining a number of neurons in a list, whose activity increases
if a number gets close to its “receptive field”.</p>
<div class="figure align-default" id="id1">
<img alt="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/PopulationCode.svg/1920px-PopulationCode.svg.png" src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/PopulationCode.svg/1920px-PopulationCode.svg.png" />
<p class="caption"><span class="caption-text">Gaussian curves representing different neuron “receptive fields”. Image credit: <a class="reference external" href="https://commons.wikimedia.org/wiki/File:PopulationCode.svg">Andrew K. Richardson</a>.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
<p class="rubric">Example</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out_features</span> <span class="o">=</span> <span class="mi">3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">population_encode</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>
<span class="go">tensor([[1.0000, 0.8825, 0.6065],</span>
<span class="go">        [0.8825, 1.0000, 0.8825],</span>
<span class="go">        [0.6065, 0.8825, 1.0000]])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_values</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – The input data as numerical values to be encoded to population codes</p></li>
<li><p><strong>out_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.8)"><em>int</em></a>) – The number of output <em>per</em> input value</p></li>
<li><p><strong>scale</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – The scaling factor for the kernels. Defaults to the maximum value of the input.
Can also be set for each individual sample.</p></li>
<li><p><strong>kernel</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></a>[[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]) – A function that takes two inputs and returns a tensor. The two inputs represent the center value
(which changes for each index in the output tensor) and the actual data value to encode respectively.z
Defaults to gaussian radial basis kernel function.</p></li>
<li><p><strong>distance_function</strong> (<a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Callable" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Callable</span></code></a>[[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>], <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]) – A function that calculates the distance between two numbers. Defaults to euclidean.</p></li>
</ul>
</dd>
</dl>
<p>Returns:</p>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.heaviside">
<span id="norse-torch-functional-heaviside-module"></span><h2>norse.torch.functional.heaviside module<a class="headerlink" href="#module-norse.torch.functional.heaviside" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.heaviside.heaviside">
<code class="sig-prename descclassname">norse.torch.functional.heaviside.</code><code class="sig-name descname">heaviside</code><span class="sig-paren">(</span><em class="sig-param">data</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/heaviside.html#heaviside"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.heaviside.heaviside" title="Permalink to this definition">¶</a></dt>
<dd><p>A <a class="reference external" href="https://en.wikipedia.org/wiki/Heaviside_step_function">heaviside step function</a>
that truncates numbers &lt;= 0 to 0 and everything else to 1.</p>
<div class="math notranslate nohighlight">
\[H[n]=egin{cases} 0, &amp; n &lt;= 0, \ 1, &amp; n \g 0, \end{cases}\]</div>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.leaky_integrator">
<span id="norse-torch-functional-leaky-integrator-module"></span><h2>norse.torch.functional.leaky_integrator module<a class="headerlink" href="#module-norse.torch.functional.leaky_integrator" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.functional.leaky_integrator.LIParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.leaky_integrator.</code><code class="sig-name descname">LIParameters</code><a class="reference internal" href="_modules/norse/torch/functional/leaky_integrator.html#LIParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.leaky_integrator.LIParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of a leaky integrator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – inverse synaptic time constant</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – inverse membrane time constant</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – leak potential</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – reset potential</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.leaky_integrator.LIParameters.tau_mem_inv">
<code class="sig-name descname">tau_mem_inv</code><a class="headerlink" href="#norse.torch.functional.leaky_integrator.LIParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.leaky_integrator.LIParameters.tau_syn_inv">
<code class="sig-name descname">tau_syn_inv</code><a class="headerlink" href="#norse.torch.functional.leaky_integrator.LIParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.leaky_integrator.LIParameters.v_leak">
<code class="sig-name descname">v_leak</code><a class="headerlink" href="#norse.torch.functional.leaky_integrator.LIParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.leaky_integrator.LIParameters.v_reset">
<code class="sig-name descname">v_reset</code><a class="headerlink" href="#norse.torch.functional.leaky_integrator.LIParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.leaky_integrator.LIState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.leaky_integrator.</code><code class="sig-name descname">LIState</code><a class="reference internal" href="_modules/norse/torch/functional/leaky_integrator.html#LIState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.leaky_integrator.LIState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a leaky-integrator</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – membrane voltage</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – input current</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.leaky_integrator.LIState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.functional.leaky_integrator.LIState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.leaky_integrator.LIState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.functional.leaky_integrator.LIState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.leaky_integrator.li_feed_forward_step">
<code class="sig-prename descclassname">norse.torch.functional.leaky_integrator.</code><code class="sig-name descname">li_feed_forward_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">p=LIParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_reset=tensor(0.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/leaky_integrator.html#li_feed_forward_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.leaky_integrator.li_feed_forward_step" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.leaky_integrator.LIState" title="norse.torch.functional.leaky_integrator.LIState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.leaky_integrator.li_step">
<code class="sig-prename descclassname">norse.torch.functional.leaky_integrator.</code><code class="sig-name descname">li_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">p=LIParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_reset=tensor(0.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/leaky_integrator.html#li_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.leaky_integrator.li_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Single euler integration step of a leaky-integrator.
More specifically it implements a discretized version of the ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[i = i + w i_{\text{in}}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – </p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.leaky_integrator.LIState" title="norse.torch.functional.leaky_integrator.LIState"><em>LIState</em></a>) – state of the leaky integrator</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – weights for incoming spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.leaky_integrator.LIParameters" title="norse.torch.functional.leaky_integrator.LIParameters"><em>LIParameters</em></a>) – parameters of the leaky integrator</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.leaky_integrator.LIState" title="norse.torch.functional.leaky_integrator.LIState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.lif">
<span id="norse-torch-functional-lif-module"></span><h2>norse.torch.functional.lif module<a class="headerlink" href="#module-norse.torch.functional.lif" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.functional.lif.LIFFeedForwardState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lif.</code><code class="sig-name descname">LIFFeedForwardState</code><a class="reference internal" href="_modules/norse/torch/functional/lif.html#LIFFeedForwardState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif.LIFFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a feed forward LIF neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.lif.LIFFeedForwardState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.functional.lif.LIFFeedForwardState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif.LIFFeedForwardState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.functional.lif.LIFFeedForwardState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.lif.LIFParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lif.</code><code class="sig-name descname">LIFParameters</code><a class="reference internal" href="_modules/norse/torch/functional/lif.html#LIFParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif.LIFParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parametrization of a LIF neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – inverse synaptic time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{syn}\)</span>)</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – inverse membrane time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{mem}\)</span>)</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – leak potential</p></li>
<li><p><strong>v_th</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – threshold potential</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – reset potential</p></li>
<li><p><strong>method</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.8)"><em>str</em></a>) – method to determine the spike threshold
(relevant for surrogate gradients)</p></li>
<li><p><strong>alpha</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – hyper parameter to use in surrogate gradient computation</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.lif.LIFParameters.alpha">
<code class="sig-name descname">alpha</code><a class="headerlink" href="#norse.torch.functional.lif.LIFParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif.LIFParameters.method">
<code class="sig-name descname">method</code><a class="headerlink" href="#norse.torch.functional.lif.LIFParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif.LIFParameters.tau_mem_inv">
<code class="sig-name descname">tau_mem_inv</code><a class="headerlink" href="#norse.torch.functional.lif.LIFParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif.LIFParameters.tau_syn_inv">
<code class="sig-name descname">tau_syn_inv</code><a class="headerlink" href="#norse.torch.functional.lif.LIFParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif.LIFParameters.v_leak">
<code class="sig-name descname">v_leak</code><a class="headerlink" href="#norse.torch.functional.lif.LIFParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif.LIFParameters.v_reset">
<code class="sig-name descname">v_reset</code><a class="headerlink" href="#norse.torch.functional.lif.LIFParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif.LIFParameters.v_th">
<code class="sig-name descname">v_th</code><a class="headerlink" href="#norse.torch.functional.lif.LIFParameters.v_th" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.lif.LIFState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lif.</code><code class="sig-name descname">LIFState</code><a class="reference internal" href="_modules/norse/torch/functional/lif.html#LIFState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif.LIFState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIF neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.lif.LIFState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.functional.lif.LIFState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif.LIFState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.functional.lif.LIFState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif.LIFState.z">
<code class="sig-name descname">z</code><a class="headerlink" href="#norse.torch.functional.lif.LIFState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lif.lif_current_encoder">
<code class="sig-prename descclassname">norse.torch.functional.lif.</code><code class="sig-name descname">lif_current_encoder</code><span class="sig-paren">(</span><em class="sig-param">input_current</em>, <em class="sig-param">v</em>, <em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lif.html#lif_current_encoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif.lif_current_encoder" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a single euler-integration step of a leaky integrator. More
specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input current at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><em>LIFState</em></a>) – current state of the LIF neuron</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – parameters of a leaky integrate and fire neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lif.lif_feed_forward_step">
<code class="sig-prename descclassname">norse.torch.functional.lif.</code><code class="sig-name descname">lif_feed_forward_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s=LIFFeedForwardState(v=0</em>, <em class="sig-param">i=0)</em>, <em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lif.html#lif_feed_forward_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif.lif_feed_forward_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a single euler-integration step for a lif neuron-model.
It takes as input the input current as generated by an arbitrary torch
module or function. More specifically it implements one integration
step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + i_{\text{in}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(i_{\text{in}}\)</span> is meant to be the result of applying an
arbitrary pytorch module (such as a convolution) to input spikes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><em>LIFFeedForwardState</em></a>) – current state of the LIF neuron</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – parameters of a leaky integrate and fire neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lif.lif_step">
<code class="sig-prename descclassname">norse.torch.functional.lif.</code><code class="sig-name descname">lif_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">recurrent_weights</em>, <em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lif.html#lif_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif.lif_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a single euler-integration step of a LIF neuron-model. More
specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}}
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the recurrent
and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><em>LIFState</em></a>) – current state of the LIF neuron</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for incoming spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – parameters of a leaky integrate and fire neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.lif_correlation">
<span id="norse-torch-functional-lif-correlation-module"></span><h2>norse.torch.functional.lif_correlation module<a class="headerlink" href="#module-norse.torch.functional.lif_correlation" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.functional.lif_correlation.LIFCorrelationParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lif_correlation.</code><code class="sig-name descname">LIFCorrelationParameters</code><span class="sig-paren">(</span><em class="sig-param">lif_parameters</em>, <em class="sig-param">input_correlation_parameters</em>, <em class="sig-param">recurrent_correlation_parameters</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lif_correlation.html#LIFCorrelationParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_correlation.LIFCorrelationParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<dl class="attribute">
<dt id="norse.torch.functional.lif_correlation.LIFCorrelationParameters.input_correlation_parameters">
<code class="sig-name descname">input_correlation_parameters</code><a class="headerlink" href="#norse.torch.functional.lif_correlation.LIFCorrelationParameters.input_correlation_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_correlation.LIFCorrelationParameters.lif_parameters">
<code class="sig-name descname">lif_parameters</code><a class="headerlink" href="#norse.torch.functional.lif_correlation.LIFCorrelationParameters.lif_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_correlation.LIFCorrelationParameters.recurrent_correlation_parameters">
<code class="sig-name descname">recurrent_correlation_parameters</code><a class="headerlink" href="#norse.torch.functional.lif_correlation.LIFCorrelationParameters.recurrent_correlation_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.lif_correlation.LIFCorrelationState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lif_correlation.</code><code class="sig-name descname">LIFCorrelationState</code><span class="sig-paren">(</span><em class="sig-param">lif_state</em>, <em class="sig-param">input_correlation_state</em>, <em class="sig-param">recurrent_correlation_state</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lif_correlation.html#LIFCorrelationState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_correlation.LIFCorrelationState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<dl class="attribute">
<dt id="norse.torch.functional.lif_correlation.LIFCorrelationState.input_correlation_state">
<code class="sig-name descname">input_correlation_state</code><a class="headerlink" href="#norse.torch.functional.lif_correlation.LIFCorrelationState.input_correlation_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_correlation.LIFCorrelationState.lif_state">
<code class="sig-name descname">lif_state</code><a class="headerlink" href="#norse.torch.functional.lif_correlation.LIFCorrelationState.lif_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_correlation.LIFCorrelationState.recurrent_correlation_state">
<code class="sig-name descname">recurrent_correlation_state</code><a class="headerlink" href="#norse.torch.functional.lif_correlation.LIFCorrelationState.recurrent_correlation_state" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lif_correlation.lif_correlation_step">
<code class="sig-prename descclassname">norse.torch.functional.lif_correlation.</code><code class="sig-name descname">lif_correlation_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">recurrent_weights</em>, <em class="sig-param">p=LIFCorrelationParameters(lif_parameters=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">input_correlation_parameters=CorrelationSensorParameters(eta_p=tensor(1.)</em>, <em class="sig-param">eta_m=tensor(1.)</em>, <em class="sig-param">tau_ac_inv=tensor(10.)</em>, <em class="sig-param">tau_c_inv=tensor(10.))</em>, <em class="sig-param">recurrent_correlation_parameters=CorrelationSensorParameters(eta_p=tensor(1.)</em>, <em class="sig-param">eta_m=tensor(1.)</em>, <em class="sig-param">tau_ac_inv=tensor(10.)</em>, <em class="sig-param">tau_c_inv=tensor(10.)))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lif_correlation.html#lif_correlation_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_correlation.lif_correlation_step" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lif_correlation.LIFCorrelationState" title="norse.torch.functional.lif_correlation.LIFCorrelationState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFCorrelationState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.lif_mc">
<span id="norse-torch-functional-lif-mc-module"></span><h2>norse.torch.functional.lif_mc module<a class="headerlink" href="#module-norse.torch.functional.lif_mc" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.lif_mc.lif_mc_feed_forward_step">
<code class="sig-prename descclassname">norse.torch.functional.lif_mc.</code><code class="sig-name descname">lif_mc_feed_forward_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">g_coupling</em>, <em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lif_mc.html#lif_mc_feed_forward_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_mc.lif_mc_feed_forward_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a single euler-integration feed forward step of a LIF
multi-compartment neuron-model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the (weighted) input spikes at the
current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><em>LIFFeedForwardState</em></a>) – current state of the neuron</p></li>
<li><p><strong>g_coupling</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – conductances between the neuron compartments</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – neuron parameters</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lif_mc.lif_mc_step">
<code class="sig-prename descclassname">norse.torch.functional.lif_mc.</code><code class="sig-name descname">lif_mc_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">recurrent_weights</em>, <em class="sig-param">g_coupling</em>, <em class="sig-param">p=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lif_mc.html#lif_mc_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_mc.lif_mc_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a single euler-integration step of a LIF multi-compartment
neuron-model.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><em>LIFState</em></a>) – current state of the neuron</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for incoming spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>g_coupling</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – conductances between the neuron compartments</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – neuron parameters</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.lif_mc_refrac">
<span id="norse-torch-functional-lif-mc-refrac-module"></span><h2>norse.torch.functional.lif_mc_refrac module<a class="headerlink" href="#module-norse.torch.functional.lif_mc_refrac" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.lif_mc_refrac.lif_mc_refrac_feed_forward_step">
<code class="sig-prename descclassname">norse.torch.functional.lif_mc_refrac.</code><code class="sig-name descname">lif_mc_refrac_feed_forward_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">g_coupling</em>, <em class="sig-param">p=LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">rho_reset=tensor(5.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lif_mc_refrac.html#lif_mc_refrac_feed_forward_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_mc_refrac.lif_mc_refrac_feed_forward_step" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lif_mc_refrac.lif_mc_refrac_step">
<code class="sig-prename descclassname">norse.torch.functional.lif_mc_refrac.</code><code class="sig-name descname">lif_mc_refrac_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">recurrent_weights</em>, <em class="sig-param">g_coupling</em>, <em class="sig-param">p=LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">rho_reset=tensor(5.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lif_mc_refrac.html#lif_mc_refrac_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_mc_refrac.lif_mc_refrac_step" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.lif_refrac">
<span id="norse-torch-functional-lif-refrac-module"></span><h2>norse.torch.functional.lif_refrac module<a class="headerlink" href="#module-norse.torch.functional.lif_refrac" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.functional.lif_refrac.LIFRefracFeedForwardState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lif_refrac.</code><code class="sig-name descname">LIFRefracFeedForwardState</code><a class="reference internal" href="_modules/norse/torch/functional/lif_refrac.html#LIFRefracFeedForwardState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_refrac.LIFRefracFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a feed forward LIF neuron with absolute refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lif</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFFeedForwardState" title="norse.torch.functional.lif.LIFFeedForwardState"><em>LIFFeedForwardState</em></a>) – state of the feed forward LIF
neuron integration</p></li>
<li><p><strong>rho</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – refractory state (count towards zero)</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.lif_refrac.LIFRefracFeedForwardState.lif">
<code class="sig-name descname">lif</code><a class="headerlink" href="#norse.torch.functional.lif_refrac.LIFRefracFeedForwardState.lif" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_refrac.LIFRefracFeedForwardState.rho">
<code class="sig-name descname">rho</code><a class="headerlink" href="#norse.torch.functional.lif_refrac.LIFRefracFeedForwardState.rho" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.lif_refrac.LIFRefracParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lif_refrac.</code><code class="sig-name descname">LIFRefracParameters</code><a class="reference internal" href="_modules/norse/torch/functional/lif_refrac.html#LIFRefracParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_refrac.LIFRefracParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of a LIF neuron with absolute refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lif</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFParameters" title="norse.torch.functional.lif.LIFParameters"><em>LIFParameters</em></a>) – parameters of the LIF neuron integration</p></li>
<li><p><strong>rho</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – refractory state (count towards zero)</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.lif_refrac.LIFRefracParameters.lif">
<code class="sig-name descname">lif</code><a class="headerlink" href="#norse.torch.functional.lif_refrac.LIFRefracParameters.lif" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_refrac.LIFRefracParameters.rho_reset">
<code class="sig-name descname">rho_reset</code><a class="headerlink" href="#norse.torch.functional.lif_refrac.LIFRefracParameters.rho_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.lif_refrac.LIFRefracState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lif_refrac.</code><code class="sig-name descname">LIFRefracState</code><a class="reference internal" href="_modules/norse/torch/functional/lif_refrac.html#LIFRefracState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_refrac.LIFRefracState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of a LIF neuron with absolute refractory period.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lif</strong> (<a class="reference internal" href="#norse.torch.functional.lif.LIFState" title="norse.torch.functional.lif.LIFState"><em>LIFState</em></a>) – state of the LIF neuron integration</p></li>
<li><p><strong>rho</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – refractory state (count towards zero)</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.lif_refrac.LIFRefracState.lif">
<code class="sig-name descname">lif</code><a class="headerlink" href="#norse.torch.functional.lif_refrac.LIFRefracState.lif" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lif_refrac.LIFRefracState.rho">
<code class="sig-name descname">rho</code><a class="headerlink" href="#norse.torch.functional.lif_refrac.LIFRefracState.rho" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lif_refrac.lif_refrac_feed_forward_step">
<code class="sig-prename descclassname">norse.torch.functional.lif_refrac.</code><code class="sig-name descname">lif_refrac_feed_forward_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">p=LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">rho_reset=tensor(5.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lif_refrac.html#lif_refrac_feed_forward_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_refrac.lif_refrac_feed_forward_step" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Computes a single euler-integration step of a feed forward</dt><dd><p>LIF neuron-model with a refractory period.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lif_refrac.LIFRefracFeedForwardState" title="norse.torch.functional.lif_refrac.LIFRefracFeedForwardState"><em>LIFRefracFeedForwardState</em></a>) – state at the current time step</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lif_refrac.LIFRefracParameters" title="norse.torch.functional.lif_refrac.LIFRefracParameters"><em>LIFRefracParameters</em></a>) – parameters of the lif neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lif_refrac.LIFRefracFeedForwardState" title="norse.torch.functional.lif_refrac.LIFRefracFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lif_refrac.lif_refrac_step">
<code class="sig-prename descclassname">norse.torch.functional.lif_refrac.</code><code class="sig-name descname">lif_refrac_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">recurrent_weights</em>, <em class="sig-param">p=LIFRefracParameters(lif=LIFParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=0.0)</em>, <em class="sig-param">rho_reset=tensor(5.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lif_refrac.html#lif_refrac_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lif_refrac.lif_refrac_step" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Computes a single euler-integration step of a recurrently connected</dt><dd><p>LIF neuron-model with a refractory period.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><em>LIFRefracState</em></a>) – state at the current time step</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for incoming spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lif_refrac.LIFRefracParameters" title="norse.torch.functional.lif_refrac.LIFRefracParameters"><em>LIFRefracParameters</em></a>) – parameters of the lif neuron</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lif_refrac.LIFRefracState" title="norse.torch.functional.lif_refrac.LIFRefracState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LIFRefracState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.logical">
<span id="norse-torch-functional-logical-module"></span><h2>norse.torch.functional.logical module<a class="headerlink" href="#module-norse.torch.functional.logical" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.logical.logical_and">
<code class="sig-prename descclassname">norse.torch.functional.logical.</code><code class="sig-name descname">logical_and</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/logical.html#logical_and"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.logical.logical_and" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a logical and provided x and y are bitvectors.</p>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.logical.logical_or">
<code class="sig-prename descclassname">norse.torch.functional.logical.</code><code class="sig-name descname">logical_or</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/logical.html#logical_or"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.logical.logical_or" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a logical or provided x and y are bitvectors.</p>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.logical.logical_xor">
<code class="sig-prename descclassname">norse.torch.functional.logical.</code><code class="sig-name descname">logical_xor</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/logical.html#logical_xor"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.logical.logical_xor" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a logical xor provided x and y are bitvectors.</p>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.logical.muller_c">
<code class="sig-prename descclassname">norse.torch.functional.logical.</code><code class="sig-name descname">muller_c</code><span class="sig-paren">(</span><em class="sig-param">y_prev</em>, <em class="sig-param">x_1</em>, <em class="sig-param">x_2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/logical.html#muller_c"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.logical.muller_c" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the muller-c element next state provided x_1 and x_2 are bitvectors
and y_prev is the previous state.</p>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.logical.posedge_detector">
<code class="sig-prename descclassname">norse.torch.functional.logical.</code><code class="sig-name descname">posedge_detector</code><span class="sig-paren">(</span><em class="sig-param">z</em>, <em class="sig-param">z_prev</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/logical.html#posedge_detector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.logical.posedge_detector" title="Permalink to this definition">¶</a></dt>
<dd><p>Determines whether a transition from 0 to 1 has occured
providing that z and z_prev are bitvectors</p>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.lsnn">
<span id="norse-torch-functional-lsnn-module"></span><h2>norse.torch.functional.lsnn module<a class="headerlink" href="#module-norse.torch.functional.lsnn" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.functional.lsnn.LSNNFeedForwardState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lsnn.</code><code class="sig-name descname">LSNNFeedForwardState</code><a class="reference internal" href="_modules/norse/torch/functional/lsnn.html#LSNNFeedForwardState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNFeedForwardState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Integration state kept for a lsnn module</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>b</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – threshold adaptation</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNFeedForwardState.b">
<code class="sig-name descname">b</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNFeedForwardState.b" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNFeedForwardState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNFeedForwardState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNFeedForwardState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNFeedForwardState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.lsnn.LSNNParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lsnn.</code><code class="sig-name descname">LSNNParameters</code><a class="reference internal" href="_modules/norse/torch/functional/lsnn.html#LSNNParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of an LSNN neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tau_syn_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – inverse synaptic time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{syn}\)</span>)</p></li>
<li><p><strong>tau_mem_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – inverse membrane time
constant (<span class="math notranslate nohighlight">\(1/\tau_\text{mem}\)</span>)</p></li>
<li><p><strong>tau_adapt_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – inverse adaptation time
constant (<span class="math notranslate nohighlight">\(1/\tau_b\)</span>)</p></li>
<li><p><strong>v_leak</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – leak potential</p></li>
<li><p><strong>v_th</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – threshold potential</p></li>
<li><p><strong>v_reset</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – reset potential</p></li>
<li><p><strong>beta</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – adaptation constant</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.alpha">
<code class="sig-name descname">alpha</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.alpha" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 8</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.beta">
<code class="sig-name descname">beta</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.beta" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 6</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.method">
<code class="sig-name descname">method</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.method" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 7</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.tau_adapt_inv">
<code class="sig-name descname">tau_adapt_inv</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.tau_adapt_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.tau_mem_inv">
<code class="sig-name descname">tau_mem_inv</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.tau_mem_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.tau_syn_inv">
<code class="sig-name descname">tau_syn_inv</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.tau_syn_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.v_leak">
<code class="sig-name descname">v_leak</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.v_leak" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.v_reset">
<code class="sig-name descname">v_reset</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.v_reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 5</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNParameters.v_th">
<code class="sig-name descname">v_th</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNParameters.v_th" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 4</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.lsnn.LSNNState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.lsnn.</code><code class="sig-name descname">LSNNState</code><a class="reference internal" href="_modules/norse/torch/functional/lsnn.html#LSNNState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of an LSNN neuron</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – recurrent spikes</p></li>
<li><p><strong>v</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – membrane potential</p></li>
<li><p><strong>i</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic input current</p></li>
<li><p><strong>b</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – threshold adaptation</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNState.b">
<code class="sig-name descname">b</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNState.b" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNState.i">
<code class="sig-name descname">i</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNState.i" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNState.v">
<code class="sig-name descname">v</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNState.v" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.lsnn.LSNNState.z">
<code class="sig-name descname">z</code><a class="headerlink" href="#norse.torch.functional.lsnn.LSNNState.z" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lsnn.ada_lif_step">
<code class="sig-prename descclassname">norse.torch.functional.lsnn.</code><code class="sig-name descname">ada_lif_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">recurrent_weights</em>, <em class="sig-param">p=LSNNParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">tau_adapt_inv=tensor(0.0014)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">beta=tensor(1.8000)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=100.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lsnn.html#ada_lif_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lsnn.ada_lif_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Euler integration step for LIF Neuron with adaptation. More specifically
it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + b + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{b} &amp;= -1/\tau_{b} b
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}})\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\\text{rec}} \\
    b &amp;= b + \beta z
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the recurrent
and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><em>LSNNState</em></a>) – current state of the lsnn unit</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for input spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lsnn.LSNNParameters" title="norse.torch.functional.lsnn.LSNNParameters"><em>LSNNParameters</em></a>) – parameters of the lsnn unit</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lsnn.lsnn_feed_forward_step">
<code class="sig-prename descclassname">norse.torch.functional.lsnn.</code><code class="sig-name descname">lsnn_feed_forward_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">p=LSNNParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">tau_adapt_inv=tensor(0.0014)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">beta=tensor(1.8000)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=100.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lsnn.html#lsnn_feed_forward_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lsnn.lsnn_feed_forward_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Euler integration step for LIF Neuron with threshold adaptation.
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{b} &amp;= -1/\tau_{b} b
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}} + b)\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + \text{input} \\
    b &amp;= b + \beta z
\end{align*}\end{split}\]</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lsnn.LSNNFeedForwardState" title="norse.torch.functional.lsnn.LSNNFeedForwardState"><em>LSNNFeedForwardState</em></a>) – current state of the lsnn unit</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lsnn.LSNNParameters" title="norse.torch.functional.lsnn.LSNNParameters"><em>LSNNParameters</em></a>) – parameters of the lsnn unit</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lsnn.LSNNFeedForwardState" title="norse.torch.functional.lsnn.LSNNFeedForwardState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNFeedForwardState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.lsnn.lsnn_step">
<code class="sig-prename descclassname">norse.torch.functional.lsnn.</code><code class="sig-name descname">lsnn_step</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">s</em>, <em class="sig-param">input_weights</em>, <em class="sig-param">recurrent_weights</em>, <em class="sig-param">p=LSNNParameters(tau_syn_inv=tensor(200.)</em>, <em class="sig-param">tau_mem_inv=tensor(100.)</em>, <em class="sig-param">tau_adapt_inv=tensor(0.0014)</em>, <em class="sig-param">v_leak=tensor(0.)</em>, <em class="sig-param">v_th=tensor(1.)</em>, <em class="sig-param">v_reset=tensor(0.)</em>, <em class="sig-param">beta=tensor(1.8000)</em>, <em class="sig-param">method='super'</em>, <em class="sig-param">alpha=100.0)</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/lsnn.html#lsnn_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.lsnn.lsnn_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Euler integration step for LIF Neuron with threshold adaptation
More specifically it implements one integration step of the following ODE</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    \dot{v} &amp;= 1/\tau_{\text{mem}} (v_{\text{leak}} - v + i) \\
    \dot{i} &amp;= -1/\tau_{\text{syn}} i \\
    \dot{b} &amp;= -1/\tau_{b} b
\end{align*}\end{split}\]</div>
<p>together with the jump condition</p>
<div class="math notranslate nohighlight">
\[z = \Theta(v - v_{\text{th}} + b)\]</div>
<p>and transition equations</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align*}
    v &amp;= (1-z) v + z v_{\text{reset}} \\
    i &amp;= i + w_{\text{input}} z_{\text{in}} \\
    i &amp;= i + w_{\text{rec}} z_{\text{rec}} \\
    b &amp;= b + \beta z
\end{align*}\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(z_{\text{rec}}\)</span> and <span class="math notranslate nohighlight">\(z_{\text{in}}\)</span> are the recurrent
and input spikes respectively.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – the input spikes at the current time step</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><em>LSNNState</em></a>) – current state of the lsnn unit</p></li>
<li><p><strong>input_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for input spikes</p></li>
<li><p><strong>recurrent_weights</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – synaptic weights for recurrent spikes</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.lsnn.LSNNParameters" title="norse.torch.functional.lsnn.LSNNParameters"><em>LSNNParameters</em></a>) – parameters of the lsnn unit</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – Integration timestep to use</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.lsnn.LSNNState" title="norse.torch.functional.lsnn.LSNNState"><code class="xref py py-class docutils literal notranslate"><span class="pre">LSNNState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.spiking_vector_quantization">
<span id="norse-torch-functional-spiking-vector-quantization-module"></span><h2>norse.torch.functional.spiking_vector_quantization module<a class="headerlink" href="#module-norse.torch.functional.spiking_vector_quantization" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.spiking_vector_quantization.constant_spiking_vector_quantization">
<code class="sig-prename descclassname">norse.torch.functional.spiking_vector_quantization.</code><code class="sig-name descname">constant_spiking_vector_quantization</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">T</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/spiking_vector_quantization.html#constant_spiking_vector_quantization"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.spiking_vector_quantization.constant_spiking_vector_quantization" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.spiking_vector_quantization.spiking_vector_quantization_step">
<code class="sig-prename descclassname">norse.torch.functional.spiking_vector_quantization.</code><code class="sig-name descname">spiking_vector_quantization_step</code><span class="sig-paren">(</span><em class="sig-param">v</em>, <em class="sig-param">phi</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/spiking_vector_quantization.html#spiking_vector_quantization_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.spiking_vector_quantization.spiking_vector_quantization_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the quantization method explained in</p>
<p>“Deep Spiking Neural Networks”, P. O’Connor and Max Welling
<a class="reference external" href="https://arxiv.org/pdf/1602.08323.pdf">https://arxiv.org/pdf/1602.08323.pdf</a></p>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.stdp_sensor">
<span id="norse-torch-functional-stdp-sensor-module"></span><h2>norse.torch.functional.stdp_sensor module<a class="headerlink" href="#module-norse.torch.functional.stdp_sensor" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.functional.stdp_sensor.STDPSensorParameters">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.stdp_sensor.</code><code class="sig-name descname">STDPSensorParameters</code><a class="reference internal" href="_modules/norse/torch/functional/stdp_sensor.html#STDPSensorParameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.stdp_sensor.STDPSensorParameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>Parameters of an STDP sensor as it is used for event driven
plasticity rules.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>eta_p</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – correlation state</p></li>
<li><p><strong>eta_m</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – anti correlation state</p></li>
<li><p><strong>tau_ac_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – anti-correlation sensor time constant</p></li>
<li><p><strong>tau_c_inv</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – correlation sensor time constant</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.stdp_sensor.STDPSensorParameters.eta_m">
<code class="sig-name descname">eta_m</code><a class="headerlink" href="#norse.torch.functional.stdp_sensor.STDPSensorParameters.eta_m" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.stdp_sensor.STDPSensorParameters.eta_p">
<code class="sig-name descname">eta_p</code><a class="headerlink" href="#norse.torch.functional.stdp_sensor.STDPSensorParameters.eta_p" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.stdp_sensor.STDPSensorParameters.tau_ac_inv">
<code class="sig-name descname">tau_ac_inv</code><a class="headerlink" href="#norse.torch.functional.stdp_sensor.STDPSensorParameters.tau_ac_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 2</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.stdp_sensor.STDPSensorParameters.tau_c_inv">
<code class="sig-name descname">tau_c_inv</code><a class="headerlink" href="#norse.torch.functional.stdp_sensor.STDPSensorParameters.tau_c_inv" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 3</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.stdp_sensor.STDPSensorState">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.stdp_sensor.</code><code class="sig-name descname">STDPSensorState</code><a class="reference internal" href="_modules/norse/torch/functional/stdp_sensor.html#STDPSensorState"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.stdp_sensor.STDPSensorState" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.8)"><code class="xref py py-class docutils literal notranslate"><span class="pre">tuple</span></code></a></p>
<p>State of an event driven STDP sensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>a_pre</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – presynaptic STDP sensor state.</p></li>
<li><p><strong>a_post</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – postsynaptic STDP sensor state.</p></li>
</ul>
</dd>
</dl>
<dl class="attribute">
<dt id="norse.torch.functional.stdp_sensor.STDPSensorState.a_post">
<code class="sig-name descname">a_post</code><a class="headerlink" href="#norse.torch.functional.stdp_sensor.STDPSensorState.a_post" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 1</p>
</dd></dl>

<dl class="attribute">
<dt id="norse.torch.functional.stdp_sensor.STDPSensorState.a_pre">
<code class="sig-name descname">a_pre</code><a class="headerlink" href="#norse.torch.functional.stdp_sensor.STDPSensorState.a_pre" title="Permalink to this definition">¶</a></dt>
<dd><p>Alias for field number 0</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.stdp_sensor.stdp_sensor_step">
<code class="sig-prename descclassname">norse.torch.functional.stdp_sensor.</code><code class="sig-name descname">stdp_sensor_step</code><span class="sig-paren">(</span><em class="sig-param">z_pre</em>, <em class="sig-param">z_post</em>, <em class="sig-param">s</em>, <em class="sig-param">p=STDPSensorParameters(eta_p=tensor(1.)</em>, <em class="sig-param">eta_m=tensor(1.)</em>, <em class="sig-param">tau_ac_inv=tensor(10.)</em>, <em class="sig-param">tau_c_inv=tensor(10.))</em>, <em class="sig-param">dt=0.001</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/stdp_sensor.html#stdp_sensor_step"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.stdp_sensor.stdp_sensor_step" title="Permalink to this definition">¶</a></dt>
<dd><p>Event driven STDP rule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>z_pre</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – pre-synaptic spikes</p></li>
<li><p><strong>z_post</strong> (<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><em>torch.Tensor</em></a>) – post-synaptic spikes</p></li>
<li><p><strong>s</strong> (<a class="reference internal" href="#norse.torch.functional.stdp_sensor.STDPSensorState" title="norse.torch.functional.stdp_sensor.STDPSensorState"><em>STDPSensorState</em></a>) – state of the STDP sensor</p></li>
<li><p><strong>p</strong> (<a class="reference internal" href="#norse.torch.functional.stdp_sensor.STDPSensorParameters" title="norse.torch.functional.stdp_sensor.STDPSensorParameters"><em>STDPSensorParameters</em></a>) – STDP sensor parameters</p></li>
<li><p><strong>dt</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.8)"><em>float</em></a>) – integration time step</p></li>
</ul>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/typing.html#typing.Tuple" title="(in Python v3.8)"><code class="xref py py-data docutils literal notranslate"><span class="pre">Tuple</span></code></a>[<a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a>, <a class="reference internal" href="#norse.torch.functional.stdp_sensor.STDPSensorState" title="norse.torch.functional.stdp_sensor.STDPSensorState"><code class="xref py py-class docutils literal notranslate"><span class="pre">STDPSensorState</span></code></a>]</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.superspike">
<span id="norse-torch-functional-superspike-module"></span><h2>norse.torch.functional.superspike module<a class="headerlink" href="#module-norse.torch.functional.superspike" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.functional.superspike.SuperSpike">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.superspike.</code><code class="sig-name descname">SuperSpike</code><a class="reference internal" href="_modules/norse/torch/functional/superspike.html#SuperSpike"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.superspike.SuperSpike" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>SuperSpike surrogate gradient as described in Section 3.3.2 of</p>
<ol class="upperalpha simple" start="6">
<li><dl class="simple">
<dt>Zenke, S. Ganguli, “SuperSpike: Supervised Learning in</dt><dd><p>Multilayer Spiking Neural Networks”,</p>
</dd>
</dl>
</li>
</ol>
<p>Neural Computation 30, 1514–1541 (2018),
doi:10.1162/neco_a_01086</p>
<dl class="method">
<dt id="norse.torch.functional.superspike.SuperSpike.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">grad_output</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/superspike.html#SuperSpike.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.superspike.SuperSpike.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs did <a class="reference internal" href="#norse.torch.functional.superspike.SuperSpike.forward" title="norse.torch.functional.superspike.SuperSpike.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> return, and it should return as many
tensors, as there were inputs to <a class="reference internal" href="#norse.torch.functional.superspike.SuperSpike.forward" title="norse.torch.functional.superspike.SuperSpike.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the
gradient w.r.t the given output, and each returned value should be the
gradient w.r.t. the corresponding input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#norse.torch.functional.superspike.SuperSpike.backward" title="norse.torch.functional.superspike.SuperSpike.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#norse.torch.functional.superspike.SuperSpike.forward" title="norse.torch.functional.superspike.SuperSpike.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.functional.superspike.SuperSpike.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">input</em>, <em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/superspike.html#SuperSpike.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.superspike.SuperSpike.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store tensors that can be then retrieved
during the backward pass.</p>
<dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.superspike.super_fn">
<code class="sig-prename descclassname">norse.torch.functional.superspike.</code><code class="sig-name descname">super_fn</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">alpha=100.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/superspike.html#super_fn"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.superspike.super_fn" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.test_coba_lif">
<span id="norse-torch-functional-test-coba-lif-module"></span><h2>norse.torch.functional.test_coba_lif module<a class="headerlink" href="#module-norse.torch.functional.test_coba_lif" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.test_coba_lif.coba_lif_feed_forward_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_coba_lif.</code><code class="sig-name descname">coba_lif_feed_forward_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_coba_lif.html#coba_lif_feed_forward_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_coba_lif.coba_lif_feed_forward_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_coba_lif.coba_lif_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_coba_lif.</code><code class="sig-name descname">coba_lif_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_coba_lif.html#coba_lif_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_coba_lif.coba_lif_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.test_encode">
<span id="norse-torch-functional-test-encode-module"></span><h2>norse.torch.functional.test_encode module<a class="headerlink" href="#module-norse.torch.functional.test_encode" title="Permalink to this headline">¶</a></h2>
<p>Test for the encoder module</p>
<dl class="function">
<dt id="norse.torch.functional.test_encode.constant_current_lif_encode_test">
<code class="sig-prename descclassname">norse.torch.functional.test_encode.</code><code class="sig-name descname">constant_current_lif_encode_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_encode.html#constant_current_lif_encode_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_encode.constant_current_lif_encode_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_encode.encode_population_batch_test">
<code class="sig-prename descclassname">norse.torch.functional.test_encode.</code><code class="sig-name descname">encode_population_batch_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_encode.html#encode_population_batch_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_encode.encode_population_batch_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_encode.encode_population_test">
<code class="sig-prename descclassname">norse.torch.functional.test_encode.</code><code class="sig-name descname">encode_population_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_encode.html#encode_population_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_encode.encode_population_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.test_heaviside">
<span id="norse-torch-functional-test-heaviside-module"></span><h2>norse.torch.functional.test_heaviside module<a class="headerlink" href="#module-norse.torch.functional.test_heaviside" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.test_heaviside.heaviside_test">
<code class="sig-prename descclassname">norse.torch.functional.test_heaviside.</code><code class="sig-name descname">heaviside_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_heaviside.html#heaviside_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_heaviside.heaviside_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.test_leaky_integrator">
<span id="norse-torch-functional-test-leaky-integrator-module"></span><h2>norse.torch.functional.test_leaky_integrator module<a class="headerlink" href="#module-norse.torch.functional.test_leaky_integrator" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.test_leaky_integrator.lif_feed_forward_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_leaky_integrator.</code><code class="sig-name descname">lif_feed_forward_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_leaky_integrator.html#lif_feed_forward_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_leaky_integrator.lif_feed_forward_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_leaky_integrator.lif_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_leaky_integrator.</code><code class="sig-name descname">lif_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_leaky_integrator.html#lif_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_leaky_integrator.lif_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.test_lif">
<span id="norse-torch-functional-test-lif-module"></span><h2>norse.torch.functional.test_lif module<a class="headerlink" href="#module-norse.torch.functional.test_lif" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.test_lif.lif_current_encoder_test">
<code class="sig-prename descclassname">norse.torch.functional.test_lif.</code><code class="sig-name descname">lif_current_encoder_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_lif.html#lif_current_encoder_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_lif.lif_current_encoder_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_lif.lif_feed_forward_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_lif.</code><code class="sig-name descname">lif_feed_forward_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_lif.html#lif_feed_forward_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_lif.lif_feed_forward_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_lif.lif_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_lif.</code><code class="sig-name descname">lif_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_lif.html#lif_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_lif.lif_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.test_lif_mc">
<span id="norse-torch-functional-test-lif-mc-module"></span><h2>norse.torch.functional.test_lif_mc module<a class="headerlink" href="#module-norse.torch.functional.test_lif_mc" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.test_lif_mc.lif_mc_feed_forward_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_lif_mc.</code><code class="sig-name descname">lif_mc_feed_forward_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_lif_mc.html#lif_mc_feed_forward_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_lif_mc.lif_mc_feed_forward_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_lif_mc.lif_mc_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_lif_mc.</code><code class="sig-name descname">lif_mc_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_lif_mc.html#lif_mc_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_lif_mc.lif_mc_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.test_lif_mc_refrac">
<span id="norse-torch-functional-test-lif-mc-refrac-module"></span><h2>norse.torch.functional.test_lif_mc_refrac module<a class="headerlink" href="#module-norse.torch.functional.test_lif_mc_refrac" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.test_lif_mc_refrac.lif_refrac_feed_forward_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_lif_mc_refrac.</code><code class="sig-name descname">lif_refrac_feed_forward_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_lif_mc_refrac.html#lif_refrac_feed_forward_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_lif_mc_refrac.lif_refrac_feed_forward_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_lif_mc_refrac.lif_refrac_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_lif_mc_refrac.</code><code class="sig-name descname">lif_refrac_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_lif_mc_refrac.html#lif_refrac_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_lif_mc_refrac.lif_refrac_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.test_lif_refrac">
<span id="norse-torch-functional-test-lif-refrac-module"></span><h2>norse.torch.functional.test_lif_refrac module<a class="headerlink" href="#module-norse.torch.functional.test_lif_refrac" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.test_lif_refrac.lif_refrac_feed_forward_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_lif_refrac.</code><code class="sig-name descname">lif_refrac_feed_forward_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_lif_refrac.html#lif_refrac_feed_forward_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_lif_refrac.lif_refrac_feed_forward_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_lif_refrac.lif_refrac_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_lif_refrac.</code><code class="sig-name descname">lif_refrac_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_lif_refrac.html#lif_refrac_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_lif_refrac.lif_refrac_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.test_logical">
<span id="norse-torch-functional-test-logical-module"></span><h2>norse.torch.functional.test_logical module<a class="headerlink" href="#module-norse.torch.functional.test_logical" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.test_logical.logical_and_test">
<code class="sig-prename descclassname">norse.torch.functional.test_logical.</code><code class="sig-name descname">logical_and_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_logical.html#logical_and_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_logical.logical_and_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_logical.logical_or_test">
<code class="sig-prename descclassname">norse.torch.functional.test_logical.</code><code class="sig-name descname">logical_or_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_logical.html#logical_or_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_logical.logical_or_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_logical.logical_xor_test">
<code class="sig-prename descclassname">norse.torch.functional.test_logical.</code><code class="sig-name descname">logical_xor_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_logical.html#logical_xor_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_logical.logical_xor_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_logical.posedge_detector_test">
<code class="sig-prename descclassname">norse.torch.functional.test_logical.</code><code class="sig-name descname">posedge_detector_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_logical.html#posedge_detector_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_logical.posedge_detector_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.test_lsnn">
<span id="norse-torch-functional-test-lsnn-module"></span><h2>norse.torch.functional.test_lsnn module<a class="headerlink" href="#module-norse.torch.functional.test_lsnn" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="norse.torch.functional.test_lsnn.ada_lif_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_lsnn.</code><code class="sig-name descname">ada_lif_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_lsnn.html#ada_lif_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_lsnn.ada_lif_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_lsnn.lsnn_feed_forward_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_lsnn.</code><code class="sig-name descname">lsnn_feed_forward_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_lsnn.html#lsnn_feed_forward_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_lsnn.lsnn_feed_forward_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_lsnn.lsnn_step_test">
<code class="sig-prename descclassname">norse.torch.functional.test_lsnn.</code><code class="sig-name descname">lsnn_step_test</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_lsnn.html#lsnn_step_test"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_lsnn.lsnn_step_test" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.test_lsnn.lsnn_step_test_batch">
<code class="sig-prename descclassname">norse.torch.functional.test_lsnn.</code><code class="sig-name descname">lsnn_step_test_batch</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/test_lsnn.html#lsnn_step_test_batch"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.test_lsnn.lsnn_step_test_batch" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</div>
<div class="section" id="module-norse.torch.functional.threshold">
<span id="norse-torch-functional-threshold-module"></span><h2>norse.torch.functional.threshold module<a class="headerlink" href="#module-norse.torch.functional.threshold" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="norse.torch.functional.threshold.CircDist">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">CircDist</code><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#CircDist"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.CircDist" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<dl class="method">
<dt id="norse.torch.functional.threshold.CircDist.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">dy</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#CircDist.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.CircDist.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs did <a class="reference internal" href="#norse.torch.functional.threshold.CircDist.forward" title="norse.torch.functional.threshold.CircDist.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> return, and it should return as many
tensors, as there were inputs to <a class="reference internal" href="#norse.torch.functional.threshold.CircDist.forward" title="norse.torch.functional.threshold.CircDist.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the
gradient w.r.t the given output, and each returned value should be the
gradient w.r.t. the corresponding input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#norse.torch.functional.threshold.CircDist.backward" title="norse.torch.functional.threshold.CircDist.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#norse.torch.functional.threshold.CircDist.forward" title="norse.torch.functional.threshold.CircDist.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.functional.threshold.CircDist.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#CircDist.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.CircDist.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store tensors that can be then retrieved
during the backward pass.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.threshold.HeaviCirc">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">HeaviCirc</code><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#HeaviCirc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviCirc" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Approximation of the heaviside step function as</p>
<div class="math notranslate nohighlight">
\[h(x,\alpha) = \frac{1}{2} + \frac{1}{2} \
\frac{x}{(x^2 + \alpha^2)^{1/2}}\]</div>
<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviCirc.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">dy</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#HeaviCirc.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviCirc.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs did <a class="reference internal" href="#norse.torch.functional.threshold.HeaviCirc.forward" title="norse.torch.functional.threshold.HeaviCirc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> return, and it should return as many
tensors, as there were inputs to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviCirc.forward" title="norse.torch.functional.threshold.HeaviCirc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the
gradient w.r.t the given output, and each returned value should be the
gradient w.r.t. the corresponding input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#norse.torch.functional.threshold.HeaviCirc.backward" title="norse.torch.functional.threshold.HeaviCirc.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviCirc.forward" title="norse.torch.functional.threshold.HeaviCirc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviCirc.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#HeaviCirc.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviCirc.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store tensors that can be then retrieved
during the backward pass.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.threshold.HeaviErfc">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">HeaviErfc</code><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#HeaviErfc"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviErfc" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Approximation of the heaviside step function as</p>
<div class="math notranslate nohighlight">
\[h(x,k) = \frac{1}{2} + \frac{1}{2} \text{erfc}(k x)\]</div>
<p>where erfc is the error function.</p>
<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviErfc.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">dy</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#HeaviErfc.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviErfc.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs did <a class="reference internal" href="#norse.torch.functional.threshold.HeaviErfc.forward" title="norse.torch.functional.threshold.HeaviErfc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> return, and it should return as many
tensors, as there were inputs to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviErfc.forward" title="norse.torch.functional.threshold.HeaviErfc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the
gradient w.r.t the given output, and each returned value should be the
gradient w.r.t. the corresponding input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#norse.torch.functional.threshold.HeaviErfc.backward" title="norse.torch.functional.threshold.HeaviErfc.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviErfc.forward" title="norse.torch.functional.threshold.HeaviErfc.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviErfc.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">k</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#HeaviErfc.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviErfc.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store tensors that can be then retrieved
during the backward pass.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.threshold.HeaviTanh">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">HeaviTanh</code><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#HeaviTanh"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviTanh" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Approximation of the heaviside step function as</p>
<div class="math notranslate nohighlight">
\[h(x,k) = \frac{1}{2} + \frac{1}{2} \text{tanh}(k x)\]</div>
<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviTanh.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">dy</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#HeaviTanh.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviTanh.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs did <a class="reference internal" href="#norse.torch.functional.threshold.HeaviTanh.forward" title="norse.torch.functional.threshold.HeaviTanh.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> return, and it should return as many
tensors, as there were inputs to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviTanh.forward" title="norse.torch.functional.threshold.HeaviTanh.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the
gradient w.r.t the given output, and each returned value should be the
gradient w.r.t. the corresponding input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#norse.torch.functional.threshold.HeaviTanh.backward" title="norse.torch.functional.threshold.HeaviTanh.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviTanh.forward" title="norse.torch.functional.threshold.HeaviTanh.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviTanh.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">k</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#HeaviTanh.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviTanh.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store tensors that can be then retrieved
during the backward pass.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.threshold.HeaviTent">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">HeaviTent</code><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#HeaviTent"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviTent" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviTent.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">dy</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#HeaviTent.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviTent.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs did <a class="reference internal" href="#norse.torch.functional.threshold.HeaviTent.forward" title="norse.torch.functional.threshold.HeaviTent.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> return, and it should return as many
tensors, as there were inputs to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviTent.forward" title="norse.torch.functional.threshold.HeaviTent.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the
gradient w.r.t the given output, and each returned value should be the
gradient w.r.t. the corresponding input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#norse.torch.functional.threshold.HeaviTent.backward" title="norse.torch.functional.threshold.HeaviTent.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#norse.torch.functional.threshold.HeaviTent.forward" title="norse.torch.functional.threshold.HeaviTent.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.functional.threshold.HeaviTent.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#HeaviTent.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.HeaviTent.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store tensors that can be then retrieved
during the backward pass.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="norse.torch.functional.threshold.Logistic">
<em class="property">class </em><code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">Logistic</code><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#Logistic"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.Logistic" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.autograd.function.Function</span></code></p>
<p>Probalistic approximation of the heaviside step function as</p>
<div class="math notranslate nohighlight">
\[z \sim p(\frac{1}{2} + \frac{1}{2} \text{tanh}(k x))\]</div>
<dl class="method">
<dt id="norse.torch.functional.threshold.Logistic.backward">
<em class="property">static </em><code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">dy</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#Logistic.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.Logistic.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines a formula for differentiating the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs did <a class="reference internal" href="#norse.torch.functional.threshold.Logistic.forward" title="norse.torch.functional.threshold.Logistic.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> return, and it should return as many
tensors, as there were inputs to <a class="reference internal" href="#norse.torch.functional.threshold.Logistic.forward" title="norse.torch.functional.threshold.Logistic.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the
gradient w.r.t the given output, and each returned value should be the
gradient w.r.t. the corresponding input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#norse.torch.functional.threshold.Logistic.backward" title="norse.torch.functional.threshold.Logistic.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#norse.torch.functional.threshold.Logistic.forward" title="norse.torch.functional.threshold.Logistic.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computated w.r.t. the
output.</p>
</dd></dl>

<dl class="method">
<dt id="norse.torch.functional.threshold.Logistic.forward">
<em class="property">static </em><code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">ctx</em>, <em class="sig-param">x</em>, <em class="sig-param">k</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#Logistic.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.Logistic.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Performs the operation.</p>
<p>This function is to be overridden by all subclasses.</p>
<p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p>
<p>The context can be used to store tensors that can be then retrieved
during the backward pass.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.circ_dist_fn">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">circ_dist_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#norse.torch.functional.threshold.circ_dist_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.heavi_circ_fn">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">heavi_circ_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#norse.torch.functional.threshold.heavi_circ_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.heavi_erfc_fn">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">heavi_erfc_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#norse.torch.functional.threshold.heavi_erfc_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.heavi_tanh_fn">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">heavi_tanh_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#norse.torch.functional.threshold.heavi_tanh_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.heavi_tent_fn">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">heavi_tent_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#norse.torch.functional.threshold.heavi_tent_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.logistic_fn">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">logistic_fn</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#norse.torch.functional.threshold.logistic_fn" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.sign">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">sign</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">method</em>, <em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#sign"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.sign" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

<dl class="function">
<dt id="norse.torch.functional.threshold.threshold">
<code class="sig-prename descclassname">norse.torch.functional.threshold.</code><code class="sig-name descname">threshold</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">method</em>, <em class="sig-param">alpha</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/norse/torch/functional/threshold.html#threshold"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#norse.torch.functional.threshold.threshold" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference external" href="https://pytorch.org/docs/master/tensors.html#torch.Tensor" title="(in PyTorch vmaster (1.6.0a0+0c936f9 ))"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a></p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-norse.torch.functional">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-norse.torch.functional" title="Permalink to this headline">¶</a></h2>
<p>Stateless spiking neural network components.</p>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">norse</a></h1>








<h3>Navigation</h3>
<p class="caption"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_examples/index.html">Beginner tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="experiments.html">Running Experiments</a></li>
<li class="toctree-l1"><a class="reference internal" href="spiking.html">Introduction to spikes</a></li>
</ul>
<p class="caption"><span class="caption-text">API Docs</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="norse.html">norse package</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="norse.task.html">norse.task package</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="norse.torch.html">norse.torch package</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="norse.task.html">norse.task package</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.benchmark.html">norse.torch.benchmark package</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">norse.torch.functional package</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.models.html">norse.torch.models package</a></li>
<li class="toctree-l1"><a class="reference internal" href="norse.torch.module.html">norse.torch.module package</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  <li><a href="norse.html">norse package</a><ul>
  <li><a href="norse.torch.html">norse.torch package</a><ul>
      <li>Previous: <a href="norse.torch.benchmark.html" title="previous chapter">norse.torch.benchmark package</a></li>
      <li>Next: <a href="norse.torch.models.html" title="next chapter">norse.torch.models package</a></li>
  </ul></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, Norse.ai.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.4.4</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/norse.torch.functional.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>